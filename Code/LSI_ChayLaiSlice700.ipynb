{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhYKMT4YWZ-z",
        "outputId": "ba4cccee-1539-44d2-c782-c251cdaef418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1D48c_crSg6ia_OqZ5HoJmVmDLgn-iqq5\n",
            "To: /content/Cranfield.zip\n",
            "100% 851k/851k [00:00<00:00, 135MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1g0JYIiu-l6dSo5BpOuAeem2rVCkxNHjE\n",
            "To: /content/TEST.zip\n",
            "100% 49.9k/49.9k [00:00<00:00, 122MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Cranfiel\n",
        "import gdown\n",
        "!gdown 1D48c_crSg6ia_OqZ5HoJmVmDLgn-iqq5\n",
        "!gdown 1g0JYIiu-l6dSo5BpOuAeem2rVCkxNHjE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_Xkh5kNacebz"
      },
      "outputs": [],
      "source": [
        "# Mô hình vector + Latent Semantic Index (LSI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw52xXrOceb1"
      },
      "source": [
        "# Import cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5d6cwN9ceb3",
        "outputId": "75a62772-c5ac-4b73-a4be-738ca12cec43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDGxDOp2OoEk"
      },
      "source": [
        "# Cranfield - Reading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aXEf_-o8islO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7871845d-6b4f-4601-8a5b-71cf153a6a5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Cranfield.zip\n",
            "   creating: Cranfield/\n",
            "  inflating: Cranfield/1.txt         \n",
            "  inflating: Cranfield/10.txt        \n",
            "  inflating: Cranfield/100.txt       \n",
            "  inflating: Cranfield/1000.txt      \n",
            "  inflating: Cranfield/1001.txt      \n",
            "  inflating: Cranfield/1002.txt      \n",
            "  inflating: Cranfield/1003.txt      \n",
            "  inflating: Cranfield/1004.txt      \n",
            "  inflating: Cranfield/1005.txt      \n",
            "  inflating: Cranfield/1006.txt      \n",
            "  inflating: Cranfield/1007.txt      \n",
            "  inflating: Cranfield/1008.txt      \n",
            "  inflating: Cranfield/1009.txt      \n",
            "  inflating: Cranfield/101.txt       \n",
            "  inflating: Cranfield/1010.txt      \n",
            "  inflating: Cranfield/1011.txt      \n",
            "  inflating: Cranfield/1012.txt      \n",
            "  inflating: Cranfield/1013.txt      \n",
            "  inflating: Cranfield/1014.txt      \n",
            "  inflating: Cranfield/1015.txt      \n",
            "  inflating: Cranfield/1016.txt      \n",
            "  inflating: Cranfield/1017.txt      \n",
            "  inflating: Cranfield/1018.txt      \n",
            "  inflating: Cranfield/1019.txt      \n",
            "  inflating: Cranfield/102.txt       \n",
            "  inflating: Cranfield/1020.txt      \n",
            "  inflating: Cranfield/1021.txt      \n",
            "  inflating: Cranfield/1022.txt      \n",
            "  inflating: Cranfield/1023.txt      \n",
            "  inflating: Cranfield/1024.txt      \n",
            "  inflating: Cranfield/1025.txt      \n",
            "  inflating: Cranfield/1026.txt      \n",
            "  inflating: Cranfield/1027.txt      \n",
            "  inflating: Cranfield/1028.txt      \n",
            "  inflating: Cranfield/1029.txt      \n",
            "  inflating: Cranfield/103.txt       \n",
            "  inflating: Cranfield/1030.txt      \n",
            "  inflating: Cranfield/1031.txt      \n",
            "  inflating: Cranfield/1032.txt      \n",
            "  inflating: Cranfield/1033.txt      \n",
            "  inflating: Cranfield/1034.txt      \n",
            "  inflating: Cranfield/1035.txt      \n",
            "  inflating: Cranfield/1036.txt      \n",
            "  inflating: Cranfield/1037.txt      \n",
            "  inflating: Cranfield/1038.txt      \n",
            "  inflating: Cranfield/1039.txt      \n",
            "  inflating: Cranfield/104.txt       \n",
            "  inflating: Cranfield/1040.txt      \n",
            "  inflating: Cranfield/1041.txt      \n",
            "  inflating: Cranfield/1042.txt      \n",
            "  inflating: Cranfield/1043.txt      \n",
            "  inflating: Cranfield/1044.txt      \n",
            "  inflating: Cranfield/1045.txt      \n",
            "  inflating: Cranfield/1046.txt      \n",
            "  inflating: Cranfield/1047.txt      \n",
            "  inflating: Cranfield/1048.txt      \n",
            "  inflating: Cranfield/1049.txt      \n",
            "  inflating: Cranfield/105.txt       \n",
            "  inflating: Cranfield/1050.txt      \n",
            "  inflating: Cranfield/1051.txt      \n",
            "  inflating: Cranfield/1052.txt      \n",
            "  inflating: Cranfield/1053.txt      \n",
            "  inflating: Cranfield/1054.txt      \n",
            "  inflating: Cranfield/1055.txt      \n",
            "  inflating: Cranfield/1056.txt      \n",
            "  inflating: Cranfield/1057.txt      \n",
            "  inflating: Cranfield/1058.txt      \n",
            "  inflating: Cranfield/1059.txt      \n",
            "  inflating: Cranfield/106.txt       \n",
            "  inflating: Cranfield/1060.txt      \n",
            "  inflating: Cranfield/1061.txt      \n",
            "  inflating: Cranfield/1062.txt      \n",
            "  inflating: Cranfield/1063.txt      \n",
            "  inflating: Cranfield/1064.txt      \n",
            "  inflating: Cranfield/1065.txt      \n",
            "  inflating: Cranfield/1066.txt      \n",
            "  inflating: Cranfield/1067.txt      \n",
            "  inflating: Cranfield/1068.txt      \n",
            "  inflating: Cranfield/1069.txt      \n",
            "  inflating: Cranfield/107.txt       \n",
            "  inflating: Cranfield/1070.txt      \n",
            "  inflating: Cranfield/1071.txt      \n",
            "  inflating: Cranfield/1072.txt      \n",
            "  inflating: Cranfield/1073.txt      \n",
            "  inflating: Cranfield/1074.txt      \n",
            "  inflating: Cranfield/1075.txt      \n",
            "  inflating: Cranfield/1076.txt      \n",
            "  inflating: Cranfield/1077.txt      \n",
            "  inflating: Cranfield/1078.txt      \n",
            "  inflating: Cranfield/1079.txt      \n",
            "  inflating: Cranfield/108.txt       \n",
            "  inflating: Cranfield/1080.txt      \n",
            "  inflating: Cranfield/1081.txt      \n",
            "  inflating: Cranfield/1082.txt      \n",
            "  inflating: Cranfield/1083.txt      \n",
            "  inflating: Cranfield/1084.txt      \n",
            "  inflating: Cranfield/1085.txt      \n",
            "  inflating: Cranfield/1086.txt      \n",
            "  inflating: Cranfield/1087.txt      \n",
            "  inflating: Cranfield/1088.txt      \n",
            "  inflating: Cranfield/1089.txt      \n",
            "  inflating: Cranfield/109.txt       \n",
            "  inflating: Cranfield/1090.txt      \n",
            "  inflating: Cranfield/1091.txt      \n",
            "  inflating: Cranfield/1092.txt      \n",
            "  inflating: Cranfield/1093.txt      \n",
            "  inflating: Cranfield/1094.txt      \n",
            "  inflating: Cranfield/1095.txt      \n",
            "  inflating: Cranfield/1096.txt      \n",
            "  inflating: Cranfield/1097.txt      \n",
            "  inflating: Cranfield/1098.txt      \n",
            "  inflating: Cranfield/1099.txt      \n",
            "  inflating: Cranfield/11.txt        \n",
            "  inflating: Cranfield/110.txt       \n",
            "  inflating: Cranfield/1100.txt      \n",
            "  inflating: Cranfield/1101.txt      \n",
            "  inflating: Cranfield/1102.txt      \n",
            "  inflating: Cranfield/1103.txt      \n",
            "  inflating: Cranfield/1104.txt      \n",
            "  inflating: Cranfield/1105.txt      \n",
            "  inflating: Cranfield/1106.txt      \n",
            "  inflating: Cranfield/1107.txt      \n",
            "  inflating: Cranfield/1108.txt      \n",
            "  inflating: Cranfield/1109.txt      \n",
            "  inflating: Cranfield/111.txt       \n",
            "  inflating: Cranfield/1110.txt      \n",
            "  inflating: Cranfield/1111.txt      \n",
            "  inflating: Cranfield/1112.txt      \n",
            "  inflating: Cranfield/1113.txt      \n",
            "  inflating: Cranfield/1114.txt      \n",
            "  inflating: Cranfield/1115.txt      \n",
            "  inflating: Cranfield/1116.txt      \n",
            "  inflating: Cranfield/1117.txt      \n",
            "  inflating: Cranfield/1118.txt      \n",
            "  inflating: Cranfield/1119.txt      \n",
            "  inflating: Cranfield/112.txt       \n",
            "  inflating: Cranfield/1120.txt      \n",
            "  inflating: Cranfield/1121.txt      \n",
            "  inflating: Cranfield/1122.txt      \n",
            "  inflating: Cranfield/1123.txt      \n",
            "  inflating: Cranfield/1124.txt      \n",
            "  inflating: Cranfield/1125.txt      \n",
            "  inflating: Cranfield/1126.txt      \n",
            "  inflating: Cranfield/1127.txt      \n",
            "  inflating: Cranfield/1128.txt      \n",
            "  inflating: Cranfield/1129.txt      \n",
            "  inflating: Cranfield/113.txt       \n",
            "  inflating: Cranfield/1130.txt      \n",
            "  inflating: Cranfield/1131.txt      \n",
            "  inflating: Cranfield/1132.txt      \n",
            "  inflating: Cranfield/1133.txt      \n",
            "  inflating: Cranfield/1134.txt      \n",
            "  inflating: Cranfield/1135.txt      \n",
            "  inflating: Cranfield/1136.txt      \n",
            "  inflating: Cranfield/1137.txt      \n",
            "  inflating: Cranfield/1138.txt      \n",
            "  inflating: Cranfield/1139.txt      \n",
            "  inflating: Cranfield/114.txt       \n",
            "  inflating: Cranfield/1140.txt      \n",
            "  inflating: Cranfield/1141.txt      \n",
            "  inflating: Cranfield/1142.txt      \n",
            "  inflating: Cranfield/1143.txt      \n",
            "  inflating: Cranfield/1144.txt      \n",
            "  inflating: Cranfield/1145.txt      \n",
            "  inflating: Cranfield/1146.txt      \n",
            "  inflating: Cranfield/1147.txt      \n",
            "  inflating: Cranfield/1148.txt      \n",
            "  inflating: Cranfield/1149.txt      \n",
            "  inflating: Cranfield/115.txt       \n",
            "  inflating: Cranfield/1150.txt      \n",
            "  inflating: Cranfield/1151.txt      \n",
            "  inflating: Cranfield/1152.txt      \n",
            "  inflating: Cranfield/1153.txt      \n",
            "  inflating: Cranfield/1154.txt      \n",
            "  inflating: Cranfield/1155.txt      \n",
            "  inflating: Cranfield/1156.txt      \n",
            "  inflating: Cranfield/1157.txt      \n",
            "  inflating: Cranfield/1158.txt      \n",
            "  inflating: Cranfield/1159.txt      \n",
            "  inflating: Cranfield/116.txt       \n",
            "  inflating: Cranfield/1160.txt      \n",
            "  inflating: Cranfield/1161.txt      \n",
            "  inflating: Cranfield/1162.txt      \n",
            "  inflating: Cranfield/1163.txt      \n",
            "  inflating: Cranfield/1164.txt      \n",
            "  inflating: Cranfield/1165.txt      \n",
            "  inflating: Cranfield/1166.txt      \n",
            "  inflating: Cranfield/1167.txt      \n",
            "  inflating: Cranfield/1168.txt      \n",
            "  inflating: Cranfield/1169.txt      \n",
            "  inflating: Cranfield/117.txt       \n",
            "  inflating: Cranfield/1170.txt      \n",
            "  inflating: Cranfield/1171.txt      \n",
            "  inflating: Cranfield/1172.txt      \n",
            "  inflating: Cranfield/1173.txt      \n",
            "  inflating: Cranfield/1174.txt      \n",
            "  inflating: Cranfield/1175.txt      \n",
            "  inflating: Cranfield/1176.txt      \n",
            "  inflating: Cranfield/1177.txt      \n",
            "  inflating: Cranfield/1178.txt      \n",
            "  inflating: Cranfield/1179.txt      \n",
            "  inflating: Cranfield/118.txt       \n",
            "  inflating: Cranfield/1180.txt      \n",
            "  inflating: Cranfield/1181.txt      \n",
            "  inflating: Cranfield/1182.txt      \n",
            "  inflating: Cranfield/1183.txt      \n",
            "  inflating: Cranfield/1184.txt      \n",
            "  inflating: Cranfield/1185.txt      \n",
            "  inflating: Cranfield/1186.txt      \n",
            "  inflating: Cranfield/1187.txt      \n",
            "  inflating: Cranfield/1188.txt      \n",
            "  inflating: Cranfield/1189.txt      \n",
            "  inflating: Cranfield/119.txt       \n",
            "  inflating: Cranfield/1190.txt      \n",
            "  inflating: Cranfield/1191.txt      \n",
            "  inflating: Cranfield/1192.txt      \n",
            "  inflating: Cranfield/1193.txt      \n",
            "  inflating: Cranfield/1194.txt      \n",
            "  inflating: Cranfield/1195.txt      \n",
            "  inflating: Cranfield/1196.txt      \n",
            "  inflating: Cranfield/1197.txt      \n",
            "  inflating: Cranfield/1198.txt      \n",
            "  inflating: Cranfield/1199.txt      \n",
            "  inflating: Cranfield/12.txt        \n",
            "  inflating: Cranfield/120.txt       \n",
            "  inflating: Cranfield/1200.txt      \n",
            "  inflating: Cranfield/1201.txt      \n",
            "  inflating: Cranfield/1202.txt      \n",
            "  inflating: Cranfield/1203.txt      \n",
            "  inflating: Cranfield/1204.txt      \n",
            "  inflating: Cranfield/1205.txt      \n",
            "  inflating: Cranfield/1206.txt      \n",
            "  inflating: Cranfield/1207.txt      \n",
            "  inflating: Cranfield/1208.txt      \n",
            "  inflating: Cranfield/1209.txt      \n",
            "  inflating: Cranfield/121.txt       \n",
            "  inflating: Cranfield/1210.txt      \n",
            "  inflating: Cranfield/1211.txt      \n",
            "  inflating: Cranfield/1212.txt      \n",
            "  inflating: Cranfield/1213.txt      \n",
            "  inflating: Cranfield/1214.txt      \n",
            "  inflating: Cranfield/1215.txt      \n",
            "  inflating: Cranfield/1216.txt      \n",
            "  inflating: Cranfield/1217.txt      \n",
            "  inflating: Cranfield/1218.txt      \n",
            "  inflating: Cranfield/1219.txt      \n",
            "  inflating: Cranfield/122.txt       \n",
            "  inflating: Cranfield/1220.txt      \n",
            "  inflating: Cranfield/1221.txt      \n",
            "  inflating: Cranfield/1222.txt      \n",
            "  inflating: Cranfield/1223.txt      \n",
            "  inflating: Cranfield/1224.txt      \n",
            "  inflating: Cranfield/1225.txt      \n",
            "  inflating: Cranfield/1226.txt      \n",
            "  inflating: Cranfield/1227.txt      \n",
            "  inflating: Cranfield/1228.txt      \n",
            "  inflating: Cranfield/1229.txt      \n",
            "  inflating: Cranfield/123.txt       \n",
            "  inflating: Cranfield/1230.txt      \n",
            "  inflating: Cranfield/1231.txt      \n",
            "  inflating: Cranfield/1232.txt      \n",
            "  inflating: Cranfield/1233.txt      \n",
            "  inflating: Cranfield/1234.txt      \n",
            "  inflating: Cranfield/1235.txt      \n",
            "  inflating: Cranfield/1236.txt      \n",
            "  inflating: Cranfield/1237.txt      \n",
            "  inflating: Cranfield/1238.txt      \n",
            "  inflating: Cranfield/1239.txt      \n",
            "  inflating: Cranfield/124.txt       \n",
            "  inflating: Cranfield/1240.txt      \n",
            "  inflating: Cranfield/1241.txt      \n",
            "  inflating: Cranfield/1242.txt      \n",
            "  inflating: Cranfield/1243.txt      \n",
            "  inflating: Cranfield/1244.txt      \n",
            "  inflating: Cranfield/1245.txt      \n",
            "  inflating: Cranfield/1246.txt      \n",
            "  inflating: Cranfield/1247.txt      \n",
            "  inflating: Cranfield/1248.txt      \n",
            "  inflating: Cranfield/1249.txt      \n",
            "  inflating: Cranfield/125.txt       \n",
            "  inflating: Cranfield/1250.txt      \n",
            "  inflating: Cranfield/1251.txt      \n",
            "  inflating: Cranfield/1252.txt      \n",
            "  inflating: Cranfield/1253.txt      \n",
            "  inflating: Cranfield/1254.txt      \n",
            "  inflating: Cranfield/1255.txt      \n",
            "  inflating: Cranfield/1256.txt      \n",
            "  inflating: Cranfield/1257.txt      \n",
            "  inflating: Cranfield/1258.txt      \n",
            "  inflating: Cranfield/1259.txt      \n",
            "  inflating: Cranfield/126.txt       \n",
            "  inflating: Cranfield/1260.txt      \n",
            "  inflating: Cranfield/1261.txt      \n",
            "  inflating: Cranfield/1262.txt      \n",
            "  inflating: Cranfield/1263.txt      \n",
            "  inflating: Cranfield/1264.txt      \n",
            "  inflating: Cranfield/1265.txt      \n",
            "  inflating: Cranfield/1266.txt      \n",
            "  inflating: Cranfield/1267.txt      \n",
            "  inflating: Cranfield/1268.txt      \n",
            "  inflating: Cranfield/1269.txt      \n",
            "  inflating: Cranfield/127.txt       \n",
            "  inflating: Cranfield/1270.txt      \n",
            "  inflating: Cranfield/1271.txt      \n",
            "  inflating: Cranfield/1272.txt      \n",
            "  inflating: Cranfield/1273.txt      \n",
            "  inflating: Cranfield/1274.txt      \n",
            "  inflating: Cranfield/1275.txt      \n",
            "  inflating: Cranfield/1276.txt      \n",
            "  inflating: Cranfield/1277.txt      \n",
            "  inflating: Cranfield/1278.txt      \n",
            "  inflating: Cranfield/1279.txt      \n",
            "  inflating: Cranfield/128.txt       \n",
            "  inflating: Cranfield/1280.txt      \n",
            "  inflating: Cranfield/1281.txt      \n",
            "  inflating: Cranfield/1282.txt      \n",
            "  inflating: Cranfield/1283.txt      \n",
            "  inflating: Cranfield/1284.txt      \n",
            "  inflating: Cranfield/1285.txt      \n",
            "  inflating: Cranfield/1286.txt      \n",
            "  inflating: Cranfield/1287.txt      \n",
            "  inflating: Cranfield/1288.txt      \n",
            "  inflating: Cranfield/1289.txt      \n",
            "  inflating: Cranfield/129.txt       \n",
            "  inflating: Cranfield/1290.txt      \n",
            "  inflating: Cranfield/1291.txt      \n",
            "  inflating: Cranfield/1292.txt      \n",
            "  inflating: Cranfield/1293.txt      \n",
            "  inflating: Cranfield/1294.txt      \n",
            "  inflating: Cranfield/1295.txt      \n",
            "  inflating: Cranfield/1296.txt      \n",
            "  inflating: Cranfield/1297.txt      \n",
            "  inflating: Cranfield/1298.txt      \n",
            "  inflating: Cranfield/1299.txt      \n",
            "  inflating: Cranfield/13.txt        \n",
            "  inflating: Cranfield/130.txt       \n",
            "  inflating: Cranfield/1300.txt      \n",
            "  inflating: Cranfield/1301.txt      \n",
            "  inflating: Cranfield/1302.txt      \n",
            "  inflating: Cranfield/1303.txt      \n",
            "  inflating: Cranfield/1304.txt      \n",
            "  inflating: Cranfield/1305.txt      \n",
            "  inflating: Cranfield/1306.txt      \n",
            "  inflating: Cranfield/1307.txt      \n",
            "  inflating: Cranfield/1308.txt      \n",
            "  inflating: Cranfield/1309.txt      \n",
            "  inflating: Cranfield/131.txt       \n",
            "  inflating: Cranfield/1310.txt      \n",
            "  inflating: Cranfield/1311.txt      \n",
            "  inflating: Cranfield/1312.txt      \n",
            "  inflating: Cranfield/1313.txt      \n",
            "  inflating: Cranfield/1314.txt      \n",
            "  inflating: Cranfield/1315.txt      \n",
            "  inflating: Cranfield/1316.txt      \n",
            "  inflating: Cranfield/1317.txt      \n",
            "  inflating: Cranfield/1318.txt      \n",
            "  inflating: Cranfield/1319.txt      \n",
            "  inflating: Cranfield/132.txt       \n",
            "  inflating: Cranfield/1320.txt      \n",
            "  inflating: Cranfield/1321.txt      \n",
            "  inflating: Cranfield/1322.txt      \n",
            "  inflating: Cranfield/1323.txt      \n",
            "  inflating: Cranfield/1324.txt      \n",
            "  inflating: Cranfield/1325.txt      \n",
            "  inflating: Cranfield/1326.txt      \n",
            "  inflating: Cranfield/1327.txt      \n",
            "  inflating: Cranfield/1328.txt      \n",
            "  inflating: Cranfield/1329.txt      \n",
            "  inflating: Cranfield/133.txt       \n",
            "  inflating: Cranfield/1330.txt      \n",
            "  inflating: Cranfield/1331.txt      \n",
            "  inflating: Cranfield/1332.txt      \n",
            "  inflating: Cranfield/1333.txt      \n",
            "  inflating: Cranfield/1334.txt      \n",
            "  inflating: Cranfield/1335.txt      \n",
            "  inflating: Cranfield/1336.txt      \n",
            "  inflating: Cranfield/1337.txt      \n",
            "  inflating: Cranfield/1338.txt      \n",
            "  inflating: Cranfield/1339.txt      \n",
            "  inflating: Cranfield/134.txt       \n",
            "  inflating: Cranfield/1340.txt      \n",
            "  inflating: Cranfield/1341.txt      \n",
            "  inflating: Cranfield/1342.txt      \n",
            "  inflating: Cranfield/1343.txt      \n",
            "  inflating: Cranfield/1344.txt      \n",
            "  inflating: Cranfield/1345.txt      \n",
            "  inflating: Cranfield/1346.txt      \n",
            "  inflating: Cranfield/1347.txt      \n",
            "  inflating: Cranfield/1348.txt      \n",
            "  inflating: Cranfield/1349.txt      \n",
            "  inflating: Cranfield/135.txt       \n",
            "  inflating: Cranfield/1350.txt      \n",
            "  inflating: Cranfield/1351.txt      \n",
            "  inflating: Cranfield/1352.txt      \n",
            "  inflating: Cranfield/1353.txt      \n",
            "  inflating: Cranfield/1354.txt      \n",
            "  inflating: Cranfield/1355.txt      \n",
            "  inflating: Cranfield/1356.txt      \n",
            "  inflating: Cranfield/1357.txt      \n",
            "  inflating: Cranfield/1358.txt      \n",
            "  inflating: Cranfield/1359.txt      \n",
            "  inflating: Cranfield/136.txt       \n",
            "  inflating: Cranfield/1360.txt      \n",
            "  inflating: Cranfield/1361.txt      \n",
            "  inflating: Cranfield/1362.txt      \n",
            "  inflating: Cranfield/1363.txt      \n",
            "  inflating: Cranfield/1364.txt      \n",
            "  inflating: Cranfield/1365.txt      \n",
            "  inflating: Cranfield/1366.txt      \n",
            "  inflating: Cranfield/1367.txt      \n",
            "  inflating: Cranfield/1368.txt      \n",
            "  inflating: Cranfield/1369.txt      \n",
            "  inflating: Cranfield/137.txt       \n",
            "  inflating: Cranfield/1370.txt      \n",
            "  inflating: Cranfield/1371.txt      \n",
            "  inflating: Cranfield/1372.txt      \n",
            "  inflating: Cranfield/1373.txt      \n",
            "  inflating: Cranfield/1374.txt      \n",
            "  inflating: Cranfield/1375.txt      \n",
            "  inflating: Cranfield/1376.txt      \n",
            "  inflating: Cranfield/1377.txt      \n",
            "  inflating: Cranfield/1378.txt      \n",
            "  inflating: Cranfield/1379.txt      \n",
            "  inflating: Cranfield/138.txt       \n",
            "  inflating: Cranfield/1380.txt      \n",
            "  inflating: Cranfield/1381.txt      \n",
            "  inflating: Cranfield/1382.txt      \n",
            "  inflating: Cranfield/1383.txt      \n",
            "  inflating: Cranfield/1384.txt      \n",
            "  inflating: Cranfield/1385.txt      \n",
            "  inflating: Cranfield/1386.txt      \n",
            "  inflating: Cranfield/1387.txt      \n",
            "  inflating: Cranfield/1388.txt      \n",
            "  inflating: Cranfield/1389.txt      \n",
            "  inflating: Cranfield/139.txt       \n",
            "  inflating: Cranfield/1390.txt      \n",
            "  inflating: Cranfield/1391.txt      \n",
            "  inflating: Cranfield/1392.txt      \n",
            "  inflating: Cranfield/1393.txt      \n",
            "  inflating: Cranfield/1394.txt      \n",
            "  inflating: Cranfield/1395.txt      \n",
            "  inflating: Cranfield/1396.txt      \n",
            "  inflating: Cranfield/1397.txt      \n",
            "  inflating: Cranfield/1398.txt      \n",
            "  inflating: Cranfield/1399.txt      \n",
            "  inflating: Cranfield/14.txt        \n",
            "  inflating: Cranfield/140.txt       \n",
            "  inflating: Cranfield/1400.txt      \n",
            "  inflating: Cranfield/141.txt       \n",
            "  inflating: Cranfield/142.txt       \n",
            "  inflating: Cranfield/143.txt       \n",
            "  inflating: Cranfield/144.txt       \n",
            "  inflating: Cranfield/145.txt       \n",
            "  inflating: Cranfield/146.txt       \n",
            "  inflating: Cranfield/147.txt       \n",
            "  inflating: Cranfield/148.txt       \n",
            "  inflating: Cranfield/149.txt       \n",
            "  inflating: Cranfield/15.txt        \n",
            "  inflating: Cranfield/150.txt       \n",
            "  inflating: Cranfield/151.txt       \n",
            "  inflating: Cranfield/152.txt       \n",
            "  inflating: Cranfield/153.txt       \n",
            "  inflating: Cranfield/154.txt       \n",
            "  inflating: Cranfield/155.txt       \n",
            "  inflating: Cranfield/156.txt       \n",
            "  inflating: Cranfield/157.txt       \n",
            "  inflating: Cranfield/158.txt       \n",
            "  inflating: Cranfield/159.txt       \n",
            "  inflating: Cranfield/16.txt        \n",
            "  inflating: Cranfield/160.txt       \n",
            "  inflating: Cranfield/161.txt       \n",
            "  inflating: Cranfield/162.txt       \n",
            "  inflating: Cranfield/163.txt       \n",
            "  inflating: Cranfield/164.txt       \n",
            "  inflating: Cranfield/165.txt       \n",
            "  inflating: Cranfield/166.txt       \n",
            "  inflating: Cranfield/167.txt       \n",
            "  inflating: Cranfield/168.txt       \n",
            "  inflating: Cranfield/169.txt       \n",
            "  inflating: Cranfield/17.txt        \n",
            "  inflating: Cranfield/170.txt       \n",
            "  inflating: Cranfield/171.txt       \n",
            "  inflating: Cranfield/172.txt       \n",
            "  inflating: Cranfield/173.txt       \n",
            "  inflating: Cranfield/174.txt       \n",
            "  inflating: Cranfield/175.txt       \n",
            "  inflating: Cranfield/176.txt       \n",
            "  inflating: Cranfield/177.txt       \n",
            "  inflating: Cranfield/178.txt       \n",
            "  inflating: Cranfield/179.txt       \n",
            "  inflating: Cranfield/18.txt        \n",
            "  inflating: Cranfield/180.txt       \n",
            "  inflating: Cranfield/181.txt       \n",
            "  inflating: Cranfield/182.txt       \n",
            "  inflating: Cranfield/183.txt       \n",
            "  inflating: Cranfield/184.txt       \n",
            "  inflating: Cranfield/185.txt       \n",
            "  inflating: Cranfield/186.txt       \n",
            "  inflating: Cranfield/187.txt       \n",
            "  inflating: Cranfield/188.txt       \n",
            "  inflating: Cranfield/189.txt       \n",
            "  inflating: Cranfield/19.txt        \n",
            "  inflating: Cranfield/190.txt       \n",
            "  inflating: Cranfield/191.txt       \n",
            "  inflating: Cranfield/192.txt       \n",
            "  inflating: Cranfield/193.txt       \n",
            "  inflating: Cranfield/194.txt       \n",
            "  inflating: Cranfield/195.txt       \n",
            "  inflating: Cranfield/196.txt       \n",
            "  inflating: Cranfield/197.txt       \n",
            "  inflating: Cranfield/198.txt       \n",
            "  inflating: Cranfield/199.txt       \n",
            "  inflating: Cranfield/2.txt         \n",
            "  inflating: Cranfield/20.txt        \n",
            "  inflating: Cranfield/200.txt       \n",
            "  inflating: Cranfield/201.txt       \n",
            "  inflating: Cranfield/202.txt       \n",
            "  inflating: Cranfield/203.txt       \n",
            "  inflating: Cranfield/204.txt       \n",
            "  inflating: Cranfield/205.txt       \n",
            "  inflating: Cranfield/206.txt       \n",
            "  inflating: Cranfield/207.txt       \n",
            "  inflating: Cranfield/208.txt       \n",
            "  inflating: Cranfield/209.txt       \n",
            "  inflating: Cranfield/21.txt        \n",
            "  inflating: Cranfield/210.txt       \n",
            "  inflating: Cranfield/211.txt       \n",
            "  inflating: Cranfield/212.txt       \n",
            "  inflating: Cranfield/213.txt       \n",
            "  inflating: Cranfield/214.txt       \n",
            "  inflating: Cranfield/215.txt       \n",
            "  inflating: Cranfield/216.txt       \n",
            "  inflating: Cranfield/217.txt       \n",
            "  inflating: Cranfield/218.txt       \n",
            "  inflating: Cranfield/219.txt       \n",
            "  inflating: Cranfield/22.txt        \n",
            "  inflating: Cranfield/220.txt       \n",
            "  inflating: Cranfield/221.txt       \n",
            "  inflating: Cranfield/222.txt       \n",
            "  inflating: Cranfield/223.txt       \n",
            "  inflating: Cranfield/224.txt       \n",
            "  inflating: Cranfield/225.txt       \n",
            "  inflating: Cranfield/226.txt       \n",
            "  inflating: Cranfield/227.txt       \n",
            "  inflating: Cranfield/228.txt       \n",
            "  inflating: Cranfield/229.txt       \n",
            "  inflating: Cranfield/23.txt        \n",
            "  inflating: Cranfield/230.txt       \n",
            "  inflating: Cranfield/231.txt       \n",
            "  inflating: Cranfield/232.txt       \n",
            "  inflating: Cranfield/233.txt       \n",
            "  inflating: Cranfield/234.txt       \n",
            "  inflating: Cranfield/235.txt       \n",
            "  inflating: Cranfield/236.txt       \n",
            "  inflating: Cranfield/237.txt       \n",
            "  inflating: Cranfield/238.txt       \n",
            "  inflating: Cranfield/239.txt       \n",
            "  inflating: Cranfield/24.txt        \n",
            "  inflating: Cranfield/240.txt       \n",
            "  inflating: Cranfield/241.txt       \n",
            "  inflating: Cranfield/242.txt       \n",
            "  inflating: Cranfield/243.txt       \n",
            "  inflating: Cranfield/244.txt       \n",
            "  inflating: Cranfield/245.txt       \n",
            "  inflating: Cranfield/246.txt       \n",
            "  inflating: Cranfield/247.txt       \n",
            "  inflating: Cranfield/248.txt       \n",
            "  inflating: Cranfield/249.txt       \n",
            "  inflating: Cranfield/25.txt        \n",
            "  inflating: Cranfield/250.txt       \n",
            "  inflating: Cranfield/251.txt       \n",
            "  inflating: Cranfield/252.txt       \n",
            "  inflating: Cranfield/253.txt       \n",
            "  inflating: Cranfield/254.txt       \n",
            "  inflating: Cranfield/255.txt       \n",
            "  inflating: Cranfield/256.txt       \n",
            "  inflating: Cranfield/257.txt       \n",
            "  inflating: Cranfield/258.txt       \n",
            "  inflating: Cranfield/259.txt       \n",
            "  inflating: Cranfield/26.txt        \n",
            "  inflating: Cranfield/260.txt       \n",
            "  inflating: Cranfield/261.txt       \n",
            "  inflating: Cranfield/262.txt       \n",
            "  inflating: Cranfield/263.txt       \n",
            "  inflating: Cranfield/264.txt       \n",
            "  inflating: Cranfield/265.txt       \n",
            "  inflating: Cranfield/266.txt       \n",
            "  inflating: Cranfield/267.txt       \n",
            "  inflating: Cranfield/268.txt       \n",
            "  inflating: Cranfield/269.txt       \n",
            "  inflating: Cranfield/27.txt        \n",
            "  inflating: Cranfield/270.txt       \n",
            "  inflating: Cranfield/271.txt       \n",
            "  inflating: Cranfield/272.txt       \n",
            "  inflating: Cranfield/273.txt       \n",
            "  inflating: Cranfield/274.txt       \n",
            "  inflating: Cranfield/275.txt       \n",
            "  inflating: Cranfield/276.txt       \n",
            "  inflating: Cranfield/277.txt       \n",
            "  inflating: Cranfield/278.txt       \n",
            "  inflating: Cranfield/279.txt       \n",
            "  inflating: Cranfield/28.txt        \n",
            "  inflating: Cranfield/280.txt       \n",
            "  inflating: Cranfield/281.txt       \n",
            "  inflating: Cranfield/282.txt       \n",
            "  inflating: Cranfield/283.txt       \n",
            "  inflating: Cranfield/284.txt       \n",
            "  inflating: Cranfield/285.txt       \n",
            "  inflating: Cranfield/286.txt       \n",
            "  inflating: Cranfield/287.txt       \n",
            "  inflating: Cranfield/288.txt       \n",
            "  inflating: Cranfield/289.txt       \n",
            "  inflating: Cranfield/29.txt        \n",
            "  inflating: Cranfield/290.txt       \n",
            "  inflating: Cranfield/291.txt       \n",
            "  inflating: Cranfield/292.txt       \n",
            "  inflating: Cranfield/293.txt       \n",
            "  inflating: Cranfield/294.txt       \n",
            "  inflating: Cranfield/295.txt       \n",
            "  inflating: Cranfield/296.txt       \n",
            "  inflating: Cranfield/297.txt       \n",
            "  inflating: Cranfield/298.txt       \n",
            "  inflating: Cranfield/299.txt       \n",
            "  inflating: Cranfield/3.txt         \n",
            "  inflating: Cranfield/30.txt        \n",
            "  inflating: Cranfield/300.txt       \n",
            "  inflating: Cranfield/301.txt       \n",
            "  inflating: Cranfield/302.txt       \n",
            "  inflating: Cranfield/303.txt       \n",
            "  inflating: Cranfield/304.txt       \n",
            "  inflating: Cranfield/305.txt       \n",
            "  inflating: Cranfield/306.txt       \n",
            "  inflating: Cranfield/307.txt       \n",
            "  inflating: Cranfield/308.txt       \n",
            "  inflating: Cranfield/309.txt       \n",
            "  inflating: Cranfield/31.txt        \n",
            "  inflating: Cranfield/310.txt       \n",
            "  inflating: Cranfield/311.txt       \n",
            "  inflating: Cranfield/312.txt       \n",
            "  inflating: Cranfield/313.txt       \n",
            "  inflating: Cranfield/314.txt       \n",
            "  inflating: Cranfield/315.txt       \n",
            "  inflating: Cranfield/316.txt       \n",
            "  inflating: Cranfield/317.txt       \n",
            "  inflating: Cranfield/318.txt       \n",
            "  inflating: Cranfield/319.txt       \n",
            "  inflating: Cranfield/32.txt        \n",
            "  inflating: Cranfield/320.txt       \n",
            "  inflating: Cranfield/321.txt       \n",
            "  inflating: Cranfield/322.txt       \n",
            "  inflating: Cranfield/323.txt       \n",
            "  inflating: Cranfield/324.txt       \n",
            "  inflating: Cranfield/325.txt       \n",
            "  inflating: Cranfield/326.txt       \n",
            "  inflating: Cranfield/327.txt       \n",
            "  inflating: Cranfield/328.txt       \n",
            "  inflating: Cranfield/329.txt       \n",
            "  inflating: Cranfield/33.txt        \n",
            "  inflating: Cranfield/330.txt       \n",
            "  inflating: Cranfield/331.txt       \n",
            "  inflating: Cranfield/332.txt       \n",
            "  inflating: Cranfield/333.txt       \n",
            "  inflating: Cranfield/334.txt       \n",
            "  inflating: Cranfield/335.txt       \n",
            "  inflating: Cranfield/336.txt       \n",
            "  inflating: Cranfield/337.txt       \n",
            "  inflating: Cranfield/338.txt       \n",
            "  inflating: Cranfield/339.txt       \n",
            "  inflating: Cranfield/34.txt        \n",
            "  inflating: Cranfield/340.txt       \n",
            "  inflating: Cranfield/341.txt       \n",
            "  inflating: Cranfield/342.txt       \n",
            "  inflating: Cranfield/343.txt       \n",
            "  inflating: Cranfield/344.txt       \n",
            "  inflating: Cranfield/345.txt       \n",
            "  inflating: Cranfield/346.txt       \n",
            "  inflating: Cranfield/347.txt       \n",
            "  inflating: Cranfield/348.txt       \n",
            "  inflating: Cranfield/349.txt       \n",
            "  inflating: Cranfield/35.txt        \n",
            "  inflating: Cranfield/350.txt       \n",
            "  inflating: Cranfield/351.txt       \n",
            "  inflating: Cranfield/352.txt       \n",
            "  inflating: Cranfield/353.txt       \n",
            "  inflating: Cranfield/354.txt       \n",
            "  inflating: Cranfield/355.txt       \n",
            "  inflating: Cranfield/356.txt       \n",
            "  inflating: Cranfield/357.txt       \n",
            "  inflating: Cranfield/358.txt       \n",
            "  inflating: Cranfield/359.txt       \n",
            "  inflating: Cranfield/36.txt        \n",
            "  inflating: Cranfield/360.txt       \n",
            "  inflating: Cranfield/361.txt       \n",
            "  inflating: Cranfield/362.txt       \n",
            "  inflating: Cranfield/363.txt       \n",
            "  inflating: Cranfield/364.txt       \n",
            "  inflating: Cranfield/365.txt       \n",
            "  inflating: Cranfield/366.txt       \n",
            "  inflating: Cranfield/367.txt       \n",
            "  inflating: Cranfield/368.txt       \n",
            "  inflating: Cranfield/369.txt       \n",
            "  inflating: Cranfield/37.txt        \n",
            "  inflating: Cranfield/370.txt       \n",
            "  inflating: Cranfield/371.txt       \n",
            "  inflating: Cranfield/372.txt       \n",
            "  inflating: Cranfield/373.txt       \n",
            "  inflating: Cranfield/374.txt       \n",
            "  inflating: Cranfield/375.txt       \n",
            "  inflating: Cranfield/376.txt       \n",
            "  inflating: Cranfield/377.txt       \n",
            "  inflating: Cranfield/378.txt       \n",
            "  inflating: Cranfield/379.txt       \n",
            "  inflating: Cranfield/38.txt        \n",
            "  inflating: Cranfield/380.txt       \n",
            "  inflating: Cranfield/381.txt       \n",
            "  inflating: Cranfield/382.txt       \n",
            "  inflating: Cranfield/383.txt       \n",
            "  inflating: Cranfield/384.txt       \n",
            "  inflating: Cranfield/385.txt       \n",
            "  inflating: Cranfield/386.txt       \n",
            "  inflating: Cranfield/387.txt       \n",
            "  inflating: Cranfield/388.txt       \n",
            "  inflating: Cranfield/389.txt       \n",
            "  inflating: Cranfield/39.txt        \n",
            "  inflating: Cranfield/390.txt       \n",
            "  inflating: Cranfield/391.txt       \n",
            "  inflating: Cranfield/392.txt       \n",
            "  inflating: Cranfield/393.txt       \n",
            "  inflating: Cranfield/394.txt       \n",
            "  inflating: Cranfield/395.txt       \n",
            "  inflating: Cranfield/396.txt       \n",
            "  inflating: Cranfield/397.txt       \n",
            "  inflating: Cranfield/398.txt       \n",
            "  inflating: Cranfield/399.txt       \n",
            "  inflating: Cranfield/4.txt         \n",
            "  inflating: Cranfield/40.txt        \n",
            "  inflating: Cranfield/400.txt       \n",
            "  inflating: Cranfield/401.txt       \n",
            "  inflating: Cranfield/402.txt       \n",
            "  inflating: Cranfield/403.txt       \n",
            "  inflating: Cranfield/404.txt       \n",
            "  inflating: Cranfield/405.txt       \n",
            "  inflating: Cranfield/406.txt       \n",
            "  inflating: Cranfield/407.txt       \n",
            "  inflating: Cranfield/408.txt       \n",
            "  inflating: Cranfield/409.txt       \n",
            "  inflating: Cranfield/41.txt        \n",
            "  inflating: Cranfield/410.txt       \n",
            "  inflating: Cranfield/411.txt       \n",
            "  inflating: Cranfield/412.txt       \n",
            "  inflating: Cranfield/413.txt       \n",
            "  inflating: Cranfield/414.txt       \n",
            "  inflating: Cranfield/415.txt       \n",
            "  inflating: Cranfield/416.txt       \n",
            "  inflating: Cranfield/417.txt       \n",
            "  inflating: Cranfield/418.txt       \n",
            "  inflating: Cranfield/419.txt       \n",
            "  inflating: Cranfield/42.txt        \n",
            "  inflating: Cranfield/420.txt       \n",
            "  inflating: Cranfield/421.txt       \n",
            "  inflating: Cranfield/422.txt       \n",
            "  inflating: Cranfield/423.txt       \n",
            "  inflating: Cranfield/424.txt       \n",
            "  inflating: Cranfield/425.txt       \n",
            "  inflating: Cranfield/426.txt       \n",
            "  inflating: Cranfield/427.txt       \n",
            "  inflating: Cranfield/428.txt       \n",
            "  inflating: Cranfield/429.txt       \n",
            "  inflating: Cranfield/43.txt        \n",
            "  inflating: Cranfield/430.txt       \n",
            "  inflating: Cranfield/431.txt       \n",
            "  inflating: Cranfield/432.txt       \n",
            "  inflating: Cranfield/433.txt       \n",
            "  inflating: Cranfield/434.txt       \n",
            "  inflating: Cranfield/435.txt       \n",
            "  inflating: Cranfield/436.txt       \n",
            "  inflating: Cranfield/437.txt       \n",
            "  inflating: Cranfield/438.txt       \n",
            "  inflating: Cranfield/439.txt       \n",
            "  inflating: Cranfield/44.txt        \n",
            "  inflating: Cranfield/440.txt       \n",
            "  inflating: Cranfield/441.txt       \n",
            "  inflating: Cranfield/442.txt       \n",
            "  inflating: Cranfield/443.txt       \n",
            "  inflating: Cranfield/444.txt       \n",
            "  inflating: Cranfield/445.txt       \n",
            "  inflating: Cranfield/446.txt       \n",
            "  inflating: Cranfield/447.txt       \n",
            "  inflating: Cranfield/448.txt       \n",
            "  inflating: Cranfield/449.txt       \n",
            "  inflating: Cranfield/45.txt        \n",
            "  inflating: Cranfield/450.txt       \n",
            "  inflating: Cranfield/451.txt       \n",
            "  inflating: Cranfield/452.txt       \n",
            "  inflating: Cranfield/453.txt       \n",
            "  inflating: Cranfield/454.txt       \n",
            "  inflating: Cranfield/455.txt       \n",
            "  inflating: Cranfield/456.txt       \n",
            "  inflating: Cranfield/457.txt       \n",
            "  inflating: Cranfield/458.txt       \n",
            "  inflating: Cranfield/459.txt       \n",
            "  inflating: Cranfield/46.txt        \n",
            "  inflating: Cranfield/460.txt       \n",
            "  inflating: Cranfield/461.txt       \n",
            "  inflating: Cranfield/462.txt       \n",
            "  inflating: Cranfield/463.txt       \n",
            "  inflating: Cranfield/464.txt       \n",
            "  inflating: Cranfield/465.txt       \n",
            "  inflating: Cranfield/466.txt       \n",
            "  inflating: Cranfield/467.txt       \n",
            "  inflating: Cranfield/468.txt       \n",
            "  inflating: Cranfield/469.txt       \n",
            "  inflating: Cranfield/47.txt        \n",
            "  inflating: Cranfield/470.txt       \n",
            " extracting: Cranfield/471.txt       \n",
            "  inflating: Cranfield/472.txt       \n",
            "  inflating: Cranfield/473.txt       \n",
            "  inflating: Cranfield/474.txt       \n",
            "  inflating: Cranfield/475.txt       \n",
            "  inflating: Cranfield/476.txt       \n",
            "  inflating: Cranfield/477.txt       \n",
            "  inflating: Cranfield/478.txt       \n",
            "  inflating: Cranfield/479.txt       \n",
            "  inflating: Cranfield/48.txt        \n",
            "  inflating: Cranfield/480.txt       \n",
            "  inflating: Cranfield/481.txt       \n",
            "  inflating: Cranfield/482.txt       \n",
            "  inflating: Cranfield/483.txt       \n",
            "  inflating: Cranfield/484.txt       \n",
            "  inflating: Cranfield/485.txt       \n",
            "  inflating: Cranfield/486.txt       \n",
            "  inflating: Cranfield/487.txt       \n",
            "  inflating: Cranfield/488.txt       \n",
            "  inflating: Cranfield/489.txt       \n",
            "  inflating: Cranfield/49.txt        \n",
            "  inflating: Cranfield/490.txt       \n",
            "  inflating: Cranfield/491.txt       \n",
            "  inflating: Cranfield/492.txt       \n",
            "  inflating: Cranfield/493.txt       \n",
            "  inflating: Cranfield/494.txt       \n",
            "  inflating: Cranfield/495.txt       \n",
            "  inflating: Cranfield/496.txt       \n",
            "  inflating: Cranfield/497.txt       \n",
            "  inflating: Cranfield/498.txt       \n",
            "  inflating: Cranfield/499.txt       \n",
            "  inflating: Cranfield/5.txt         \n",
            "  inflating: Cranfield/50.txt        \n",
            "  inflating: Cranfield/500.txt       \n",
            "  inflating: Cranfield/501.txt       \n",
            "  inflating: Cranfield/502.txt       \n",
            "  inflating: Cranfield/503.txt       \n",
            "  inflating: Cranfield/504.txt       \n",
            "  inflating: Cranfield/505.txt       \n",
            "  inflating: Cranfield/506.txt       \n",
            "  inflating: Cranfield/507.txt       \n",
            "  inflating: Cranfield/508.txt       \n",
            "  inflating: Cranfield/509.txt       \n",
            "  inflating: Cranfield/51.txt        \n",
            "  inflating: Cranfield/510.txt       \n",
            "  inflating: Cranfield/511.txt       \n",
            "  inflating: Cranfield/512.txt       \n",
            "  inflating: Cranfield/513.txt       \n",
            "  inflating: Cranfield/514.txt       \n",
            "  inflating: Cranfield/515.txt       \n",
            "  inflating: Cranfield/516.txt       \n",
            "  inflating: Cranfield/517.txt       \n",
            "  inflating: Cranfield/518.txt       \n",
            "  inflating: Cranfield/519.txt       \n",
            "  inflating: Cranfield/52.txt        \n",
            "  inflating: Cranfield/520.txt       \n",
            "  inflating: Cranfield/521.txt       \n",
            "  inflating: Cranfield/522.txt       \n",
            "  inflating: Cranfield/523.txt       \n",
            "  inflating: Cranfield/524.txt       \n",
            "  inflating: Cranfield/525.txt       \n",
            "  inflating: Cranfield/526.txt       \n",
            "  inflating: Cranfield/527.txt       \n",
            "  inflating: Cranfield/528.txt       \n",
            "  inflating: Cranfield/529.txt       \n",
            "  inflating: Cranfield/53.txt        \n",
            "  inflating: Cranfield/530.txt       \n",
            "  inflating: Cranfield/531.txt       \n",
            "  inflating: Cranfield/532.txt       \n",
            "  inflating: Cranfield/533.txt       \n",
            "  inflating: Cranfield/534.txt       \n",
            "  inflating: Cranfield/535.txt       \n",
            "  inflating: Cranfield/536.txt       \n",
            "  inflating: Cranfield/537.txt       \n",
            "  inflating: Cranfield/538.txt       \n",
            "  inflating: Cranfield/539.txt       \n",
            "  inflating: Cranfield/54.txt        \n",
            "  inflating: Cranfield/540.txt       \n",
            "  inflating: Cranfield/541.txt       \n",
            "  inflating: Cranfield/542.txt       \n",
            "  inflating: Cranfield/543.txt       \n",
            "  inflating: Cranfield/544.txt       \n",
            "  inflating: Cranfield/545.txt       \n",
            "  inflating: Cranfield/546.txt       \n",
            "  inflating: Cranfield/547.txt       \n",
            "  inflating: Cranfield/548.txt       \n",
            "  inflating: Cranfield/549.txt       \n",
            "  inflating: Cranfield/55.txt        \n",
            "  inflating: Cranfield/550.txt       \n",
            "  inflating: Cranfield/551.txt       \n",
            "  inflating: Cranfield/552.txt       \n",
            "  inflating: Cranfield/553.txt       \n",
            "  inflating: Cranfield/554.txt       \n",
            "  inflating: Cranfield/555.txt       \n",
            "  inflating: Cranfield/556.txt       \n",
            "  inflating: Cranfield/557.txt       \n",
            "  inflating: Cranfield/558.txt       \n",
            "  inflating: Cranfield/559.txt       \n",
            "  inflating: Cranfield/56.txt        \n",
            "  inflating: Cranfield/560.txt       \n",
            "  inflating: Cranfield/561.txt       \n",
            "  inflating: Cranfield/562.txt       \n",
            "  inflating: Cranfield/563.txt       \n",
            "  inflating: Cranfield/564.txt       \n",
            "  inflating: Cranfield/565.txt       \n",
            "  inflating: Cranfield/566.txt       \n",
            "  inflating: Cranfield/567.txt       \n",
            "  inflating: Cranfield/568.txt       \n",
            "  inflating: Cranfield/569.txt       \n",
            "  inflating: Cranfield/57.txt        \n",
            "  inflating: Cranfield/570.txt       \n",
            "  inflating: Cranfield/571.txt       \n",
            "  inflating: Cranfield/572.txt       \n",
            "  inflating: Cranfield/573.txt       \n",
            "  inflating: Cranfield/574.txt       \n",
            "  inflating: Cranfield/575.txt       \n",
            "  inflating: Cranfield/576.txt       \n",
            "  inflating: Cranfield/577.txt       \n",
            "  inflating: Cranfield/578.txt       \n",
            "  inflating: Cranfield/579.txt       \n",
            "  inflating: Cranfield/58.txt        \n",
            "  inflating: Cranfield/580.txt       \n",
            "  inflating: Cranfield/581.txt       \n",
            "  inflating: Cranfield/582.txt       \n",
            "  inflating: Cranfield/583.txt       \n",
            "  inflating: Cranfield/584.txt       \n",
            "  inflating: Cranfield/585.txt       \n",
            "  inflating: Cranfield/586.txt       \n",
            "  inflating: Cranfield/587.txt       \n",
            "  inflating: Cranfield/588.txt       \n",
            "  inflating: Cranfield/589.txt       \n",
            "  inflating: Cranfield/59.txt        \n",
            "  inflating: Cranfield/590.txt       \n",
            "  inflating: Cranfield/591.txt       \n",
            "  inflating: Cranfield/592.txt       \n",
            "  inflating: Cranfield/593.txt       \n",
            "  inflating: Cranfield/594.txt       \n",
            "  inflating: Cranfield/595.txt       \n",
            "  inflating: Cranfield/596.txt       \n",
            "  inflating: Cranfield/597.txt       \n",
            "  inflating: Cranfield/598.txt       \n",
            "  inflating: Cranfield/599.txt       \n",
            "  inflating: Cranfield/6.txt         \n",
            "  inflating: Cranfield/60.txt        \n",
            "  inflating: Cranfield/600.txt       \n",
            "  inflating: Cranfield/601.txt       \n",
            "  inflating: Cranfield/602.txt       \n",
            "  inflating: Cranfield/603.txt       \n",
            "  inflating: Cranfield/604.txt       \n",
            "  inflating: Cranfield/605.txt       \n",
            "  inflating: Cranfield/606.txt       \n",
            "  inflating: Cranfield/607.txt       \n",
            "  inflating: Cranfield/608.txt       \n",
            "  inflating: Cranfield/609.txt       \n",
            "  inflating: Cranfield/61.txt        \n",
            "  inflating: Cranfield/610.txt       \n",
            "  inflating: Cranfield/611.txt       \n",
            "  inflating: Cranfield/612.txt       \n",
            "  inflating: Cranfield/613.txt       \n",
            "  inflating: Cranfield/614.txt       \n",
            "  inflating: Cranfield/615.txt       \n",
            "  inflating: Cranfield/616.txt       \n",
            "  inflating: Cranfield/617.txt       \n",
            "  inflating: Cranfield/618.txt       \n",
            "  inflating: Cranfield/619.txt       \n",
            "  inflating: Cranfield/62.txt        \n",
            "  inflating: Cranfield/620.txt       \n",
            "  inflating: Cranfield/621.txt       \n",
            "  inflating: Cranfield/622.txt       \n",
            "  inflating: Cranfield/623.txt       \n",
            "  inflating: Cranfield/624.txt       \n",
            "  inflating: Cranfield/625.txt       \n",
            "  inflating: Cranfield/626.txt       \n",
            "  inflating: Cranfield/627.txt       \n",
            "  inflating: Cranfield/628.txt       \n",
            "  inflating: Cranfield/629.txt       \n",
            "  inflating: Cranfield/63.txt        \n",
            "  inflating: Cranfield/630.txt       \n",
            "  inflating: Cranfield/631.txt       \n",
            "  inflating: Cranfield/632.txt       \n",
            "  inflating: Cranfield/633.txt       \n",
            "  inflating: Cranfield/634.txt       \n",
            "  inflating: Cranfield/635.txt       \n",
            "  inflating: Cranfield/636.txt       \n",
            "  inflating: Cranfield/637.txt       \n",
            "  inflating: Cranfield/638.txt       \n",
            "  inflating: Cranfield/639.txt       \n",
            "  inflating: Cranfield/64.txt        \n",
            "  inflating: Cranfield/640.txt       \n",
            "  inflating: Cranfield/641.txt       \n",
            "  inflating: Cranfield/642.txt       \n",
            "  inflating: Cranfield/643.txt       \n",
            "  inflating: Cranfield/644.txt       \n",
            "  inflating: Cranfield/645.txt       \n",
            "  inflating: Cranfield/646.txt       \n",
            "  inflating: Cranfield/647.txt       \n",
            "  inflating: Cranfield/648.txt       \n",
            "  inflating: Cranfield/649.txt       \n",
            "  inflating: Cranfield/65.txt        \n",
            "  inflating: Cranfield/650.txt       \n",
            "  inflating: Cranfield/651.txt       \n",
            "  inflating: Cranfield/652.txt       \n",
            "  inflating: Cranfield/653.txt       \n",
            "  inflating: Cranfield/654.txt       \n",
            "  inflating: Cranfield/655.txt       \n",
            "  inflating: Cranfield/656.txt       \n",
            "  inflating: Cranfield/657.txt       \n",
            "  inflating: Cranfield/658.txt       \n",
            "  inflating: Cranfield/659.txt       \n",
            "  inflating: Cranfield/66.txt        \n",
            "  inflating: Cranfield/660.txt       \n",
            "  inflating: Cranfield/661.txt       \n",
            "  inflating: Cranfield/662.txt       \n",
            "  inflating: Cranfield/663.txt       \n",
            "  inflating: Cranfield/664.txt       \n",
            "  inflating: Cranfield/665.txt       \n",
            "  inflating: Cranfield/666.txt       \n",
            "  inflating: Cranfield/667.txt       \n",
            "  inflating: Cranfield/668.txt       \n",
            "  inflating: Cranfield/669.txt       \n",
            "  inflating: Cranfield/67.txt        \n",
            "  inflating: Cranfield/670.txt       \n",
            "  inflating: Cranfield/671.txt       \n",
            "  inflating: Cranfield/672.txt       \n",
            "  inflating: Cranfield/673.txt       \n",
            "  inflating: Cranfield/674.txt       \n",
            "  inflating: Cranfield/675.txt       \n",
            "  inflating: Cranfield/676.txt       \n",
            "  inflating: Cranfield/677.txt       \n",
            "  inflating: Cranfield/678.txt       \n",
            "  inflating: Cranfield/679.txt       \n",
            "  inflating: Cranfield/68.txt        \n",
            "  inflating: Cranfield/680.txt       \n",
            "  inflating: Cranfield/681.txt       \n",
            "  inflating: Cranfield/682.txt       \n",
            "  inflating: Cranfield/683.txt       \n",
            "  inflating: Cranfield/684.txt       \n",
            "  inflating: Cranfield/685.txt       \n",
            "  inflating: Cranfield/686.txt       \n",
            "  inflating: Cranfield/687.txt       \n",
            "  inflating: Cranfield/688.txt       \n",
            "  inflating: Cranfield/689.txt       \n",
            "  inflating: Cranfield/69.txt        \n",
            "  inflating: Cranfield/690.txt       \n",
            "  inflating: Cranfield/691.txt       \n",
            "  inflating: Cranfield/692.txt       \n",
            "  inflating: Cranfield/693.txt       \n",
            "  inflating: Cranfield/694.txt       \n",
            "  inflating: Cranfield/695.txt       \n",
            "  inflating: Cranfield/696.txt       \n",
            "  inflating: Cranfield/697.txt       \n",
            "  inflating: Cranfield/698.txt       \n",
            "  inflating: Cranfield/699.txt       \n",
            "  inflating: Cranfield/7.txt         \n",
            "  inflating: Cranfield/70.txt        \n",
            "  inflating: Cranfield/700.txt       \n",
            "  inflating: Cranfield/701.txt       \n",
            "  inflating: Cranfield/702.txt       \n",
            "  inflating: Cranfield/703.txt       \n",
            "  inflating: Cranfield/704.txt       \n",
            "  inflating: Cranfield/705.txt       \n",
            "  inflating: Cranfield/706.txt       \n",
            "  inflating: Cranfield/707.txt       \n",
            "  inflating: Cranfield/708.txt       \n",
            "  inflating: Cranfield/709.txt       \n",
            "  inflating: Cranfield/71.txt        \n",
            "  inflating: Cranfield/710.txt       \n",
            "  inflating: Cranfield/711.txt       \n",
            "  inflating: Cranfield/712.txt       \n",
            "  inflating: Cranfield/713.txt       \n",
            "  inflating: Cranfield/714.txt       \n",
            "  inflating: Cranfield/715.txt       \n",
            "  inflating: Cranfield/716.txt       \n",
            "  inflating: Cranfield/717.txt       \n",
            "  inflating: Cranfield/718.txt       \n",
            "  inflating: Cranfield/719.txt       \n",
            "  inflating: Cranfield/72.txt        \n",
            "  inflating: Cranfield/720.txt       \n",
            "  inflating: Cranfield/721.txt       \n",
            "  inflating: Cranfield/722.txt       \n",
            "  inflating: Cranfield/723.txt       \n",
            "  inflating: Cranfield/724.txt       \n",
            "  inflating: Cranfield/725.txt       \n",
            "  inflating: Cranfield/726.txt       \n",
            "  inflating: Cranfield/727.txt       \n",
            "  inflating: Cranfield/728.txt       \n",
            "  inflating: Cranfield/729.txt       \n",
            "  inflating: Cranfield/73.txt        \n",
            "  inflating: Cranfield/730.txt       \n",
            "  inflating: Cranfield/731.txt       \n",
            "  inflating: Cranfield/732.txt       \n",
            "  inflating: Cranfield/733.txt       \n",
            "  inflating: Cranfield/734.txt       \n",
            "  inflating: Cranfield/735.txt       \n",
            "  inflating: Cranfield/736.txt       \n",
            "  inflating: Cranfield/737.txt       \n",
            "  inflating: Cranfield/738.txt       \n",
            "  inflating: Cranfield/739.txt       \n",
            "  inflating: Cranfield/74.txt        \n",
            "  inflating: Cranfield/740.txt       \n",
            "  inflating: Cranfield/741.txt       \n",
            "  inflating: Cranfield/742.txt       \n",
            "  inflating: Cranfield/743.txt       \n",
            "  inflating: Cranfield/744.txt       \n",
            "  inflating: Cranfield/745.txt       \n",
            "  inflating: Cranfield/746.txt       \n",
            "  inflating: Cranfield/747.txt       \n",
            "  inflating: Cranfield/748.txt       \n",
            "  inflating: Cranfield/749.txt       \n",
            "  inflating: Cranfield/75.txt        \n",
            "  inflating: Cranfield/750.txt       \n",
            "  inflating: Cranfield/751.txt       \n",
            "  inflating: Cranfield/752.txt       \n",
            "  inflating: Cranfield/753.txt       \n",
            "  inflating: Cranfield/754.txt       \n",
            "  inflating: Cranfield/755.txt       \n",
            "  inflating: Cranfield/756.txt       \n",
            "  inflating: Cranfield/757.txt       \n",
            "  inflating: Cranfield/758.txt       \n",
            "  inflating: Cranfield/759.txt       \n",
            "  inflating: Cranfield/76.txt        \n",
            "  inflating: Cranfield/760.txt       \n",
            "  inflating: Cranfield/761.txt       \n",
            "  inflating: Cranfield/762.txt       \n",
            "  inflating: Cranfield/763.txt       \n",
            "  inflating: Cranfield/764.txt       \n",
            "  inflating: Cranfield/765.txt       \n",
            "  inflating: Cranfield/766.txt       \n",
            "  inflating: Cranfield/767.txt       \n",
            "  inflating: Cranfield/768.txt       \n",
            "  inflating: Cranfield/769.txt       \n",
            "  inflating: Cranfield/77.txt        \n",
            "  inflating: Cranfield/770.txt       \n",
            "  inflating: Cranfield/771.txt       \n",
            "  inflating: Cranfield/772.txt       \n",
            "  inflating: Cranfield/773.txt       \n",
            "  inflating: Cranfield/774.txt       \n",
            "  inflating: Cranfield/775.txt       \n",
            "  inflating: Cranfield/776.txt       \n",
            "  inflating: Cranfield/777.txt       \n",
            "  inflating: Cranfield/778.txt       \n",
            "  inflating: Cranfield/779.txt       \n",
            "  inflating: Cranfield/78.txt        \n",
            "  inflating: Cranfield/780.txt       \n",
            "  inflating: Cranfield/781.txt       \n",
            "  inflating: Cranfield/782.txt       \n",
            "  inflating: Cranfield/783.txt       \n",
            "  inflating: Cranfield/784.txt       \n",
            "  inflating: Cranfield/785.txt       \n",
            "  inflating: Cranfield/786.txt       \n",
            "  inflating: Cranfield/787.txt       \n",
            "  inflating: Cranfield/788.txt       \n",
            "  inflating: Cranfield/789.txt       \n",
            "  inflating: Cranfield/79.txt        \n",
            "  inflating: Cranfield/790.txt       \n",
            "  inflating: Cranfield/791.txt       \n",
            "  inflating: Cranfield/792.txt       \n",
            "  inflating: Cranfield/793.txt       \n",
            "  inflating: Cranfield/794.txt       \n",
            "  inflating: Cranfield/795.txt       \n",
            "  inflating: Cranfield/796.txt       \n",
            "  inflating: Cranfield/797.txt       \n",
            "  inflating: Cranfield/798.txt       \n",
            "  inflating: Cranfield/799.txt       \n",
            "  inflating: Cranfield/8.txt         \n",
            "  inflating: Cranfield/80.txt        \n",
            "  inflating: Cranfield/800.txt       \n",
            "  inflating: Cranfield/801.txt       \n",
            "  inflating: Cranfield/802.txt       \n",
            "  inflating: Cranfield/803.txt       \n",
            "  inflating: Cranfield/804.txt       \n",
            "  inflating: Cranfield/805.txt       \n",
            "  inflating: Cranfield/806.txt       \n",
            "  inflating: Cranfield/807.txt       \n",
            "  inflating: Cranfield/808.txt       \n",
            "  inflating: Cranfield/809.txt       \n",
            "  inflating: Cranfield/81.txt        \n",
            "  inflating: Cranfield/810.txt       \n",
            "  inflating: Cranfield/811.txt       \n",
            "  inflating: Cranfield/812.txt       \n",
            "  inflating: Cranfield/813.txt       \n",
            "  inflating: Cranfield/814.txt       \n",
            "  inflating: Cranfield/815.txt       \n",
            "  inflating: Cranfield/816.txt       \n",
            "  inflating: Cranfield/817.txt       \n",
            "  inflating: Cranfield/818.txt       \n",
            "  inflating: Cranfield/819.txt       \n",
            "  inflating: Cranfield/82.txt        \n",
            "  inflating: Cranfield/820.txt       \n",
            "  inflating: Cranfield/821.txt       \n",
            "  inflating: Cranfield/822.txt       \n",
            "  inflating: Cranfield/823.txt       \n",
            "  inflating: Cranfield/824.txt       \n",
            "  inflating: Cranfield/825.txt       \n",
            "  inflating: Cranfield/826.txt       \n",
            "  inflating: Cranfield/827.txt       \n",
            "  inflating: Cranfield/828.txt       \n",
            "  inflating: Cranfield/829.txt       \n",
            "  inflating: Cranfield/83.txt        \n",
            "  inflating: Cranfield/830.txt       \n",
            "  inflating: Cranfield/831.txt       \n",
            "  inflating: Cranfield/832.txt       \n",
            "  inflating: Cranfield/833.txt       \n",
            "  inflating: Cranfield/834.txt       \n",
            "  inflating: Cranfield/835.txt       \n",
            "  inflating: Cranfield/836.txt       \n",
            "  inflating: Cranfield/837.txt       \n",
            "  inflating: Cranfield/838.txt       \n",
            "  inflating: Cranfield/839.txt       \n",
            "  inflating: Cranfield/84.txt        \n",
            "  inflating: Cranfield/840.txt       \n",
            "  inflating: Cranfield/841.txt       \n",
            "  inflating: Cranfield/842.txt       \n",
            "  inflating: Cranfield/843.txt       \n",
            "  inflating: Cranfield/844.txt       \n",
            "  inflating: Cranfield/845.txt       \n",
            "  inflating: Cranfield/846.txt       \n",
            "  inflating: Cranfield/847.txt       \n",
            "  inflating: Cranfield/848.txt       \n",
            "  inflating: Cranfield/849.txt       \n",
            "  inflating: Cranfield/85.txt        \n",
            "  inflating: Cranfield/850.txt       \n",
            "  inflating: Cranfield/851.txt       \n",
            "  inflating: Cranfield/852.txt       \n",
            "  inflating: Cranfield/853.txt       \n",
            "  inflating: Cranfield/854.txt       \n",
            "  inflating: Cranfield/855.txt       \n",
            "  inflating: Cranfield/856.txt       \n",
            "  inflating: Cranfield/857.txt       \n",
            "  inflating: Cranfield/858.txt       \n",
            "  inflating: Cranfield/859.txt       \n",
            "  inflating: Cranfield/86.txt        \n",
            "  inflating: Cranfield/860.txt       \n",
            "  inflating: Cranfield/861.txt       \n",
            "  inflating: Cranfield/862.txt       \n",
            "  inflating: Cranfield/863.txt       \n",
            "  inflating: Cranfield/864.txt       \n",
            "  inflating: Cranfield/865.txt       \n",
            "  inflating: Cranfield/866.txt       \n",
            "  inflating: Cranfield/867.txt       \n",
            "  inflating: Cranfield/868.txt       \n",
            "  inflating: Cranfield/869.txt       \n",
            "  inflating: Cranfield/87.txt        \n",
            "  inflating: Cranfield/870.txt       \n",
            "  inflating: Cranfield/871.txt       \n",
            "  inflating: Cranfield/872.txt       \n",
            "  inflating: Cranfield/873.txt       \n",
            "  inflating: Cranfield/874.txt       \n",
            "  inflating: Cranfield/875.txt       \n",
            "  inflating: Cranfield/876.txt       \n",
            "  inflating: Cranfield/877.txt       \n",
            "  inflating: Cranfield/878.txt       \n",
            "  inflating: Cranfield/879.txt       \n",
            "  inflating: Cranfield/88.txt        \n",
            "  inflating: Cranfield/880.txt       \n",
            "  inflating: Cranfield/881.txt       \n",
            "  inflating: Cranfield/882.txt       \n",
            "  inflating: Cranfield/883.txt       \n",
            "  inflating: Cranfield/884.txt       \n",
            "  inflating: Cranfield/885.txt       \n",
            "  inflating: Cranfield/886.txt       \n",
            "  inflating: Cranfield/887.txt       \n",
            "  inflating: Cranfield/888.txt       \n",
            "  inflating: Cranfield/889.txt       \n",
            "  inflating: Cranfield/89.txt        \n",
            "  inflating: Cranfield/890.txt       \n",
            "  inflating: Cranfield/891.txt       \n",
            "  inflating: Cranfield/892.txt       \n",
            "  inflating: Cranfield/893.txt       \n",
            "  inflating: Cranfield/894.txt       \n",
            "  inflating: Cranfield/895.txt       \n",
            "  inflating: Cranfield/896.txt       \n",
            "  inflating: Cranfield/897.txt       \n",
            "  inflating: Cranfield/898.txt       \n",
            "  inflating: Cranfield/899.txt       \n",
            "  inflating: Cranfield/9.txt         \n",
            "  inflating: Cranfield/90.txt        \n",
            "  inflating: Cranfield/900.txt       \n",
            "  inflating: Cranfield/901.txt       \n",
            "  inflating: Cranfield/902.txt       \n",
            "  inflating: Cranfield/903.txt       \n",
            "  inflating: Cranfield/904.txt       \n",
            "  inflating: Cranfield/905.txt       \n",
            "  inflating: Cranfield/906.txt       \n",
            "  inflating: Cranfield/907.txt       \n",
            "  inflating: Cranfield/908.txt       \n",
            "  inflating: Cranfield/909.txt       \n",
            "  inflating: Cranfield/91.txt        \n",
            "  inflating: Cranfield/910.txt       \n",
            "  inflating: Cranfield/911.txt       \n",
            "  inflating: Cranfield/912.txt       \n",
            "  inflating: Cranfield/913.txt       \n",
            "  inflating: Cranfield/914.txt       \n",
            "  inflating: Cranfield/915.txt       \n",
            "  inflating: Cranfield/916.txt       \n",
            "  inflating: Cranfield/917.txt       \n",
            "  inflating: Cranfield/918.txt       \n",
            "  inflating: Cranfield/919.txt       \n",
            "  inflating: Cranfield/92.txt        \n",
            "  inflating: Cranfield/920.txt       \n",
            "  inflating: Cranfield/921.txt       \n",
            "  inflating: Cranfield/922.txt       \n",
            "  inflating: Cranfield/923.txt       \n",
            "  inflating: Cranfield/924.txt       \n",
            "  inflating: Cranfield/925.txt       \n",
            "  inflating: Cranfield/926.txt       \n",
            "  inflating: Cranfield/927.txt       \n",
            "  inflating: Cranfield/928.txt       \n",
            "  inflating: Cranfield/929.txt       \n",
            "  inflating: Cranfield/93.txt        \n",
            "  inflating: Cranfield/930.txt       \n",
            "  inflating: Cranfield/931.txt       \n",
            "  inflating: Cranfield/932.txt       \n",
            "  inflating: Cranfield/933.txt       \n",
            "  inflating: Cranfield/934.txt       \n",
            "  inflating: Cranfield/935.txt       \n",
            "  inflating: Cranfield/936.txt       \n",
            "  inflating: Cranfield/937.txt       \n",
            "  inflating: Cranfield/938.txt       \n",
            "  inflating: Cranfield/939.txt       \n",
            "  inflating: Cranfield/94.txt        \n",
            "  inflating: Cranfield/940.txt       \n",
            "  inflating: Cranfield/941.txt       \n",
            "  inflating: Cranfield/942.txt       \n",
            "  inflating: Cranfield/943.txt       \n",
            "  inflating: Cranfield/944.txt       \n",
            "  inflating: Cranfield/945.txt       \n",
            "  inflating: Cranfield/946.txt       \n",
            "  inflating: Cranfield/947.txt       \n",
            "  inflating: Cranfield/948.txt       \n",
            "  inflating: Cranfield/949.txt       \n",
            "  inflating: Cranfield/95.txt        \n",
            "  inflating: Cranfield/950.txt       \n",
            "  inflating: Cranfield/951.txt       \n",
            "  inflating: Cranfield/952.txt       \n",
            "  inflating: Cranfield/953.txt       \n",
            "  inflating: Cranfield/954.txt       \n",
            "  inflating: Cranfield/955.txt       \n",
            "  inflating: Cranfield/956.txt       \n",
            "  inflating: Cranfield/957.txt       \n",
            "  inflating: Cranfield/958.txt       \n",
            "  inflating: Cranfield/959.txt       \n",
            "  inflating: Cranfield/96.txt        \n",
            "  inflating: Cranfield/960.txt       \n",
            "  inflating: Cranfield/961.txt       \n",
            "  inflating: Cranfield/962.txt       \n",
            "  inflating: Cranfield/963.txt       \n",
            "  inflating: Cranfield/964.txt       \n",
            "  inflating: Cranfield/965.txt       \n",
            "  inflating: Cranfield/966.txt       \n",
            "  inflating: Cranfield/967.txt       \n",
            "  inflating: Cranfield/968.txt       \n",
            "  inflating: Cranfield/969.txt       \n",
            "  inflating: Cranfield/97.txt        \n",
            "  inflating: Cranfield/970.txt       \n",
            "  inflating: Cranfield/971.txt       \n",
            "  inflating: Cranfield/972.txt       \n",
            "  inflating: Cranfield/973.txt       \n",
            "  inflating: Cranfield/974.txt       \n",
            "  inflating: Cranfield/975.txt       \n",
            "  inflating: Cranfield/976.txt       \n",
            "  inflating: Cranfield/977.txt       \n",
            "  inflating: Cranfield/978.txt       \n",
            "  inflating: Cranfield/979.txt       \n",
            "  inflating: Cranfield/98.txt        \n",
            "  inflating: Cranfield/980.txt       \n",
            "  inflating: Cranfield/981.txt       \n",
            "  inflating: Cranfield/982.txt       \n",
            "  inflating: Cranfield/983.txt       \n",
            "  inflating: Cranfield/984.txt       \n",
            "  inflating: Cranfield/985.txt       \n",
            "  inflating: Cranfield/986.txt       \n",
            "  inflating: Cranfield/987.txt       \n",
            "  inflating: Cranfield/988.txt       \n",
            "  inflating: Cranfield/989.txt       \n",
            "  inflating: Cranfield/99.txt        \n",
            "  inflating: Cranfield/990.txt       \n",
            "  inflating: Cranfield/991.txt       \n",
            "  inflating: Cranfield/992.txt       \n",
            "  inflating: Cranfield/993.txt       \n",
            "  inflating: Cranfield/994.txt       \n",
            " extracting: Cranfield/995.txt       \n",
            "  inflating: Cranfield/996.txt       \n",
            "  inflating: Cranfield/997.txt       \n",
            "  inflating: Cranfield/998.txt       \n",
            "  inflating: Cranfield/999.txt       \n"
          ]
        }
      ],
      "source": [
        "!unzip 'Cranfield.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X6zavpNtjE7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25220fd2-2ca2-4dfc-c133-8aed481eae29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  TEST.zip\n",
            "  inflating: query.txt               \n",
            "   creating: RES/\n",
            "  inflating: RES/1.txt               \n",
            "  inflating: RES/10.txt              \n",
            "  inflating: RES/100.txt             \n",
            "  inflating: RES/101.txt             \n",
            "  inflating: RES/102.txt             \n",
            " extracting: RES/103.txt             \n",
            "  inflating: RES/104.txt             \n",
            "  inflating: RES/105.txt             \n",
            "  inflating: RES/106.txt             \n",
            "  inflating: RES/107.txt             \n",
            "  inflating: RES/108.txt             \n",
            "  inflating: RES/109.txt             \n",
            "  inflating: RES/11.txt              \n",
            "  inflating: RES/110.txt             \n",
            "  inflating: RES/111.txt             \n",
            " extracting: RES/112.txt             \n",
            "  inflating: RES/113.txt             \n",
            "  inflating: RES/114.txt             \n",
            "  inflating: RES/115.txt             \n",
            "  inflating: RES/116.txt             \n",
            " extracting: RES/117.txt             \n",
            "  inflating: RES/118.txt             \n",
            " extracting: RES/119.txt             \n",
            "  inflating: RES/12.txt              \n",
            "  inflating: RES/120.txt             \n",
            "  inflating: RES/121.txt             \n",
            "  inflating: RES/122.txt             \n",
            " extracting: RES/123.txt             \n",
            "  inflating: RES/124.txt             \n",
            "  inflating: RES/125.txt             \n",
            "  inflating: RES/126.txt             \n",
            "  inflating: RES/127.txt             \n",
            " extracting: RES/128.txt             \n",
            "  inflating: RES/129.txt             \n",
            "  inflating: RES/13.txt              \n",
            "  inflating: RES/130.txt             \n",
            "  inflating: RES/131.txt             \n",
            "  inflating: RES/132.txt             \n",
            "  inflating: RES/133.txt             \n",
            " extracting: RES/134.txt             \n",
            "  inflating: RES/135.txt             \n",
            "  inflating: RES/136.txt             \n",
            "  inflating: RES/137.txt             \n",
            " extracting: RES/138.txt             \n",
            "  inflating: RES/139.txt             \n",
            " extracting: RES/14.txt              \n",
            "  inflating: RES/140.txt             \n",
            "  inflating: RES/141.txt             \n",
            " extracting: RES/142.txt             \n",
            " extracting: RES/143.txt             \n",
            "  inflating: RES/144.txt             \n",
            "  inflating: RES/145.txt             \n",
            " extracting: RES/146.txt             \n",
            "  inflating: RES/147.txt             \n",
            "  inflating: RES/148.txt             \n",
            "  inflating: RES/149.txt             \n",
            " extracting: RES/15.txt              \n",
            "  inflating: RES/150.txt             \n",
            "  inflating: RES/151.txt             \n",
            "  inflating: RES/152.txt             \n",
            "  inflating: RES/153.txt             \n",
            " extracting: RES/154.txt             \n",
            "  inflating: RES/155.txt             \n",
            "  inflating: RES/156.txt             \n",
            "  inflating: RES/157.txt             \n",
            "  inflating: RES/158.txt             \n",
            "  inflating: RES/159.txt             \n",
            "  inflating: RES/16.txt              \n",
            "  inflating: RES/160.txt             \n",
            "  inflating: RES/161.txt             \n",
            "  inflating: RES/162.txt             \n",
            "  inflating: RES/163.txt             \n",
            "  inflating: RES/164.txt             \n",
            " extracting: RES/165.txt             \n",
            "  inflating: RES/166.txt             \n",
            " extracting: RES/167.txt             \n",
            " extracting: RES/168.txt             \n",
            "  inflating: RES/169.txt             \n",
            " extracting: RES/17.txt              \n",
            "  inflating: RES/170.txt             \n",
            "  inflating: RES/171.txt             \n",
            "  inflating: RES/172.txt             \n",
            " extracting: RES/173.txt             \n",
            "  inflating: RES/174.txt             \n",
            "  inflating: RES/175.txt             \n",
            "  inflating: RES/176.txt             \n",
            "  inflating: RES/177.txt             \n",
            "  inflating: RES/178.txt             \n",
            "  inflating: RES/179.txt             \n",
            "  inflating: RES/18.txt              \n",
            "  inflating: RES/180.txt             \n",
            "  inflating: RES/181.txt             \n",
            " extracting: RES/182.txt             \n",
            "  inflating: RES/183.txt             \n",
            "  inflating: RES/184.txt             \n",
            "  inflating: RES/185.txt             \n",
            "  inflating: RES/186.txt             \n",
            "  inflating: RES/187.txt             \n",
            "  inflating: RES/188.txt             \n",
            "  inflating: RES/189.txt             \n",
            "  inflating: RES/19.txt              \n",
            "  inflating: RES/190.txt             \n",
            "  inflating: RES/191.txt             \n",
            "  inflating: RES/192.txt             \n",
            "  inflating: RES/193.txt             \n",
            "  inflating: RES/194.txt             \n",
            "  inflating: RES/195.txt             \n",
            "  inflating: RES/196.txt             \n",
            "  inflating: RES/197.txt             \n",
            "  inflating: RES/198.txt             \n",
            "  inflating: RES/199.txt             \n",
            "  inflating: RES/2.txt               \n",
            "  inflating: RES/20.txt              \n",
            "  inflating: RES/200.txt             \n",
            "  inflating: RES/201.txt             \n",
            "  inflating: RES/202.txt             \n",
            "  inflating: RES/203.txt             \n",
            "  inflating: RES/204.txt             \n",
            "  inflating: RES/205.txt             \n",
            "  inflating: RES/206.txt             \n",
            "  inflating: RES/207.txt             \n",
            "  inflating: RES/208.txt             \n",
            "  inflating: RES/209.txt             \n",
            "  inflating: RES/21.txt              \n",
            "  inflating: RES/210.txt             \n",
            "  inflating: RES/211.txt             \n",
            "  inflating: RES/212.txt             \n",
            "  inflating: RES/213.txt             \n",
            "  inflating: RES/214.txt             \n",
            " extracting: RES/215.txt             \n",
            " extracting: RES/216.txt             \n",
            "  inflating: RES/217.txt             \n",
            "  inflating: RES/218.txt             \n",
            "  inflating: RES/219.txt             \n",
            " extracting: RES/22.txt              \n",
            "  inflating: RES/220.txt             \n",
            "  inflating: RES/221.txt             \n",
            "  inflating: RES/222.txt             \n",
            "  inflating: RES/223.txt             \n",
            "  inflating: RES/224.txt             \n",
            "  inflating: RES/225.txt             \n",
            "  inflating: RES/23.txt              \n",
            " extracting: RES/24.txt              \n",
            "  inflating: RES/25.txt              \n",
            "  inflating: RES/26.txt              \n",
            "  inflating: RES/27.txt              \n",
            " extracting: RES/28.txt              \n",
            "  inflating: RES/29.txt              \n",
            "  inflating: RES/3.txt               \n",
            "  inflating: RES/30.txt              \n",
            " extracting: RES/31.txt              \n",
            "  inflating: RES/32.txt              \n",
            "  inflating: RES/33.txt              \n",
            "  inflating: RES/34.txt              \n",
            "  inflating: RES/35.txt              \n",
            " extracting: RES/36.txt              \n",
            "  inflating: RES/37.txt              \n",
            "  inflating: RES/38.txt              \n",
            "  inflating: RES/39.txt              \n",
            " extracting: RES/4.txt               \n",
            "  inflating: RES/40.txt              \n",
            "  inflating: RES/41.txt              \n",
            "  inflating: RES/42.txt              \n",
            "  inflating: RES/43.txt              \n",
            "  inflating: RES/44.txt              \n",
            "  inflating: RES/45.txt              \n",
            "  inflating: RES/46.txt              \n",
            "  inflating: RES/47.txt              \n",
            "  inflating: RES/48.txt              \n",
            " extracting: RES/49.txt              \n",
            "  inflating: RES/5.txt               \n",
            "  inflating: RES/50.txt              \n",
            "  inflating: RES/51.txt              \n",
            "  inflating: RES/52.txt              \n",
            "  inflating: RES/53.txt              \n",
            "  inflating: RES/54.txt              \n",
            "  inflating: RES/55.txt              \n",
            "  inflating: RES/56.txt              \n",
            "  inflating: RES/57.txt              \n",
            "  inflating: RES/58.txt              \n",
            "  inflating: RES/59.txt              \n",
            "  inflating: RES/6.txt               \n",
            "  inflating: RES/60.txt              \n",
            "  inflating: RES/61.txt              \n",
            "  inflating: RES/62.txt              \n",
            "  inflating: RES/63.txt              \n",
            " extracting: RES/64.txt              \n",
            "  inflating: RES/65.txt              \n",
            "  inflating: RES/66.txt              \n",
            "  inflating: RES/67.txt              \n",
            "  inflating: RES/68.txt              \n",
            "  inflating: RES/69.txt              \n",
            "  inflating: RES/7.txt               \n",
            "  inflating: RES/70.txt              \n",
            "  inflating: RES/71.txt              \n",
            "  inflating: RES/72.txt              \n",
            "  inflating: RES/73.txt              \n",
            "  inflating: RES/74.txt              \n",
            "  inflating: RES/75.txt              \n",
            "  inflating: RES/76.txt              \n",
            "  inflating: RES/77.txt              \n",
            "  inflating: RES/78.txt              \n",
            "  inflating: RES/79.txt              \n",
            "  inflating: RES/8.txt               \n",
            "  inflating: RES/80.txt              \n",
            " extracting: RES/81.txt              \n",
            "  inflating: RES/82.txt              \n",
            "  inflating: RES/83.txt              \n",
            "  inflating: RES/84.txt              \n",
            "  inflating: RES/85.txt              \n",
            " extracting: RES/86.txt              \n",
            "  inflating: RES/87.txt              \n",
            "  inflating: RES/88.txt              \n",
            "  inflating: RES/89.txt              \n",
            " extracting: RES/9.txt               \n",
            "  inflating: RES/90.txt              \n",
            "  inflating: RES/91.txt              \n",
            "  inflating: RES/92.txt              \n",
            " extracting: RES/93.txt              \n",
            "  inflating: RES/94.txt              \n",
            " extracting: RES/95.txt              \n",
            "  inflating: RES/96.txt              \n",
            "  inflating: RES/97.txt              \n",
            "  inflating: RES/98.txt              \n",
            "  inflating: RES/99.txt              \n"
          ]
        }
      ],
      "source": [
        "!unzip 'TEST.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7hbRr1OsjLUP"
      },
      "outputs": [],
      "source": [
        "# Reading the Cranfield's documents\n",
        "import os\n",
        "\n",
        "directory = '/content/Cranfield'  # Update with the path to your text files\n",
        "file_extension = '.txt'  # Update with the file extension of your text files\n",
        "\n",
        "text_files = [file for file in os.listdir(directory) if file.endswith(file_extension)]\n",
        "\n",
        "CranfieldDocs = {}\n",
        "\n",
        "for file_name in text_files:\n",
        "    file_path = os.path.join(directory, file_name)\n",
        "    with open(file_path, 'r') as file:\n",
        "        contents = file.read()\n",
        "        key = int(os.path.splitext(file_name)[0])  # Remove the file extension from the key\n",
        "        CranfieldDocs[key] = contents\n",
        "\n",
        "# Now you have the contents of each text file stored in the 'data_dict' dictionary\n",
        "\n",
        "CranfieldDocs = dict(sorted(CranfieldDocs.items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBe2ZgR5jJND",
        "outputId": "e277425c-0b17-40fe-f5a2-ae3e53654f30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'what similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft .',\n",
              " 2: 'what are the structural and aeroelastic problems associated with flight of high speed aircraft .',\n",
              " 3: 'what problems of heat conduction in composite slabs have been solved so far .',\n",
              " 4: 'can a criterion be developed to show empirically the validity of flow solutions for chemically reacting gas mixtures based on the simplifying assumption of instantaneous local chemical equilibrium .',\n",
              " 5: 'what chemical kinetic system is applicable to hypersonic aerodynamic problems .',\n",
              " 6: 'what theoretical and experimental guides do we have as to turbulent couette flow behaviour .',\n",
              " 7: 'is it possible to relate the available pressure distributions for an ogive forebody at zero angle of attack to the lower surface pressures of an equivalent ogive forebody at angle of attack .',\n",
              " 8: 'what methods -dash exact or approximate -dash are presently available for predicting body pressures at angle of attack.',\n",
              " 9: 'papers on internal /slip flow/ heat transfer studies .',\n",
              " 10: 'are real-gas transport properties for air available over a wide range of enthalpies and densities .',\n",
              " 11: 'is it possible to find an analytical,  similar solution of the strong blast wave problem in the newtonian approximation .',\n",
              " 12: 'how can the aerodynamic performance of channel flow ground effect machines be calculated .',\n",
              " 13: 'what is the basic mechanism of the transonic aileron buzz .',\n",
              " 14: 'papers on shock-sound wave interaction .',\n",
              " 15: 'material properties of photoelastic materials .',\n",
              " 16: 'can the transverse potential flow about a body of revolution be calculated efficiently by an electronic computer .',\n",
              " 17: 'can the three-dimensional problem of a transverse potential flow about a body of revolution be reduced to a two-dimensional problem .',\n",
              " 18: 'are experimental pressure distributions on bodies of revolution at angle of attack available .',\n",
              " 19: 'does there exist a good basic treatment of the dynamics of re-entry combining consideration of realistic effects with relative simplicity of results .',\n",
              " 20: 'has anyone formally determined the influence of joule heating,  produced by the induced current,  in magnetohydrodynamic free convection flows under general conditions .',\n",
              " 21: 'why does the compressibility transformation fail to correlate the high speed data for helium and air .',\n",
              " 22: 'did anyone else discover that the turbulent skin friction is not over sensitive to the nature of the variation of the viscosity with temperature .',\n",
              " 23: 'what progress has been made in research on unsteady aerodynamics .',\n",
              " 24: 'what are the factors which influence the time required to invert large structural matrices .',\n",
              " 25: 'does a practical flow follow the theoretical concepts for the interaction between adjacent blade rows of a supersonic cascade .',\n",
              " 26: 'what is a single approximate formula for the displacement thickness of a laminar boundary layer in compressible flow on a flat plate .',\n",
              " 27: 'how is the design of ring or part ring wings by linear theory affected by thickness .',\n",
              " 28: 'what application has the linear theory design of curved wings .',\n",
              " 29: 'what is the effect of cross sectional shape on the flow over simple delta wings with sharp leading edges .',\n",
              " 30: 'papers on flow visualization on slender conical wings .',\n",
              " 31: 'what size of end plate can be safely used to simulate two-dimensional flow conditions over a bluff cylindrical body of finite aspect ratio .',\n",
              " 32: 'to find an approximate correction for thickness in slender thin-wing theory .',\n",
              " 33: 'how do interference-free longitudinal stability measurements (made using free-flight models) compare with similar measurements made in a low-blockage wind tunnel .',\n",
              " 34: 'have wind tunnel interference effects been investigated on a systematic basis .',\n",
              " 35: 'are there any papers dealing with acoustic wave propagation in reacting gases .',\n",
              " 36: 'has anyone investigated relaxation effects on gaseous heat transfer to a suddenly heated wall .',\n",
              " 37: 'are there any theoretical methods for predicting base pressure .',\n",
              " 38: 'does transition in the hypersonic wake depend on body geometry and size',\n",
              " 39: 'how can one detect transition phenomena in boundary layers .',\n",
              " 40: 'how can one detect transition phenomena in hypersonic wakes .',\n",
              " 41: 'has anyone investigated and developed a simple model for the vortex wake behind a cruciform wing .',\n",
              " 42: 'what is a criterion that the transonic flow around an airfoil with a round leading edge be validly analyzed by the linearized transonic flow theory .',\n",
              " 43: 'can the transonic flow around an arbitrary smooth thin airfoil be analysed in a simple approximate way .',\n",
              " 44: 'what are the details of the rigorous kinetic theory of gases . (chapman-enskog theory) .',\n",
              " 45: 'has anyone investigated the effect of surface mass transfer on hypersonic viscous interactions .',\n",
              " 46: 'what is the combined effect of surface heat and mass transfer on hypersonic flow .',\n",
              " 47: 'what are the existing solutions for hypersonic viscous interactions over an insulated flat plate .',\n",
              " 48: 'what controls leading-edge attachment at transonic speeds .',\n",
              " 49: 'can the three-point boundary-value problem for the blasius equation be integrated numerically,  using suitable transformations,  without iteration on the boundary conditions .',\n",
              " 50: 'what are the effects of small amounts of gas rarefaction on the characteristics of the boundary layers on slender bodies of revolution .',\n",
              " 51: 'what is the available information pertaining to boundary layers on very slender bodies of revolution in continuum flow (the transverse curvature  effect) .',\n",
              " 52: 'what is the available information pertaining to the effect of slight rarefaction on boundary layer flows (the slip effect) .',\n",
              " 53: 'what investigations have been made of the flow field about a body moving through a rarefied,  partially ionized gas in the presence of a magnetic field .',\n",
              " 54: 'how is the heat transfer downstream of the mass transfer region effected by mass transfer at the nose of a blunted cone .',\n",
              " 55: 'to what extent can the available information for incompressible boundary layers be applied to problems involving compressible boundary layers .',\n",
              " 56: 'to what extent can readily available steady-state aerodynamic data be utilized to predict lifting-surface flutter characteristics .',\n",
              " 57: 'what are the significant steady and non-steady flow characteristics which affect the flutter mechanism .',\n",
              " 58: 'is it possible to determine rates of forced convective heat transfer from heated cylinders of non-circular cross-section,  (the fluid flow being along the generators) .',\n",
              " 59: 'how much is known about boundary layer flows along non-circular cylinders .',\n",
              " 60: 'is there any simple,  but practical,  method for numerical integration of the mixing problem (i.e. the blasius problem with three-point boundary conditions) .',\n",
              " 61: 'does there exist a closed-form expression for the local heat transfer around a yawed cylinder .',\n",
              " 62: 'how far around a cylinder and under what conditions of flow,  if any, is the velocity just outside of the boundary layer a linear function of the distance around the cylinder .',\n",
              " 63: 'where can i find pressure data on surfaces of swept cylinders .',\n",
              " 64: \"can't the static deflection shapes be used in predicting flutter in place of vibrational shapes . if so,  can we provide a justification by means of an example .\",\n",
              " 65: 'does the boundary layer on a flat plate in a shear flow induce a pressure gradient .',\n",
              " 66: 'can the procedure of matching inner and outer solutions for a viscous flow problem be applied when the main stream is a shear flow .',\n",
              " 67: 'can series expansions be found for the boundary layer on a flat plate in a shear flow .',\n",
              " 68: 'what possible techniques are available for computing the injection distribution corresponding to an isothermal transpiration cooled hemisphere .',\n",
              " 69: 'what is known regarding asymptotic solutions to the exact boundary layer equations .',\n",
              " 70: 'previous solutions to the boundary layer similarity equations .',\n",
              " 71: 'experimental results on hypersonic viscous interaction .',\n",
              " 72: 'what has been done about viscous interactions in relatively low reynolds number flows,  particularly at high mach numbers .',\n",
              " 73: 'what role does the effect of chemical reaction (particularly when out of equilibrium) play in the similitude laws governing hypersonic flows over slender aerodynamic bodies .',\n",
              " 74: 'how significant is the possible pressure of a dissociated free stream with respect to the realization of hypersonic simulation in high enthalpy wind tunnels .',\n",
              " 75: 'do the discrepancies among current analyses of the vorticity effect on stagnation-point heat transfer result primarily from the differences in the viscosity-temperature law assumed .',\n",
              " 76: 'how far can one trust the linear viscosity-temperature solution assumed in some of the analyses of hypersonic shock layer at low reynolds number .',\n",
              " 77: 'how close is the comparison of the shock layer theory with existing experiments in the low reynolds number (merged-layer) regime .',\n",
              " 78: 'has anyone explained the kink in the surge line of a multi-stage axial compressor .',\n",
              " 79: 'have any aerodynamic derivatives been measured at hypersonic mach numbers and comparison been made with theoretical work .',\n",
              " 80: 'are methods of measuring aerodynamic derivatives available which could be adopted for use in short running time facilities .',\n",
              " 81: 'what are wind-tunnel corrections for a two-dimensional aerofoil mounted off-centre in a tunnel .',\n",
              " 82: \"how do kuchemann's and multhopp's methods for calculating lift distributions on swept wings in subsonic flow compare with each other and with experiment .\",\n",
              " 83: 'what is the present state of the theory of quasi-conical flows .',\n",
              " 84: 'references on the methods available for accurately estimating aerodynamic heat transfer to conical bodies for both laminar and turbulent flow .',\n",
              " 85: 'what parameters can seriously influence natural transition from laminar to turbulent flow on a model in a wind tunnel .',\n",
              " 86: 'can a satisfactory experimental technique be developed for measuring oscillatory derivatives on slender sting-mounted models in supersonic wind tunnels .',\n",
              " 87: 'what effect has the boundary layer in modifying the basic inviscid flow behind the shock,  neglecting effects of leading edge and corner .',\n",
              " 88: 'how does a satellite orbit contract under the action of air drag in an atmosphere in which the scale height varies with altitude .',\n",
              " 89: 'how is the flow at transonic speeds about a delta wing different from that on a closely-related tapered sweptback wing .',\n",
              " 90: 'recent data on shock-induced boundary-layer separation .',\n",
              " 91: 'what interference effects are likely at transonic speeds .',\n",
              " 92: 'given complete freedom in the design of an airplane,  what procedure would be used in order to minimize sonic boom intensity,  and is there a limit to the degree of minimizing that can be accomplished .',\n",
              " 93: 'can methane-air combustion product be used as a hypersonic test medium and predict, within experimental accuracies, the results obtained in air .',\n",
              " 94: 'what is the theoretical heat transfer rate at the stagnation point of a blunt body .',\n",
              " 95: 'what is the theoretical heat transfer distribution around a hemisphere .',\n",
              " 96: 'has anyone investigated the unsteady lift distributions on finite wings in subsonic flow .',\n",
              " 97: 'what information is available for dynamic response of airplanes to gusts  or blasts in the subsonic regime .',\n",
              " 98: 'will forward or apex located controls be effective at low subsonic speeds and how do they compare with conventional trailing-edge flaps .',\n",
              " 99: 'given that an uncontrolled vehicle will tumble as it enters an atmosphere, is it possible to predict when and how it will stop tumbling and its subsequent motion .',\n",
              " 100: 'what are the effects of initial imperfections on the elastic buckling of cylindrical shells under axial compression .',\n",
              " 101: 'why does the incremental theory and the deformation theory of plastic stress-strain relationship differ greatly when applied to stability problems .',\n",
              " 102: 'basic dynamic characteristics of structures continuous over many spans .',\n",
              " 103: 'is the information on the buckling of sandwich sphere available .',\n",
              " 104: 'can the load deformation characteristics of a beam be obtained with the material being inelastic and a non uniform temperature being present .',\n",
              " 105: 'what is the effect of an internal liquid column on the breathing vibrations of a cylindrical shell .',\n",
              " 106: 'experimental techniques in shell vibration .',\n",
              " 107: 'in summarizing theoretical and experimental work on the behaviour of a typical aircraft structure in a noise environment is it possible to develop a design procedure .',\n",
              " 108: 'what data is there on the fatigue of structures under acoustic loading .',\n",
              " 109: 'panels subjected to aerodynamic heating .',\n",
              " 110: 'can increasing the edge loading of a plate beyond the critical value for buckling change the buckling mode .',\n",
              " 111: 'have the effects of an elastic edge restraint been considered in previous papers on panel flutter .',\n",
              " 112: 'has the solution of the clamped plate problem,  in the classical theory of bending,  been reduced to two successive membrane boundary value problems .',\n",
              " 113: 'what data exists on oscillatory aerodynamic forces on control surfaces at transonic mach numbers .',\n",
              " 114: 'it is not likely that the airforces on a wing of general planform oscillating in transonic flow can be determined by purely analytical methods . is it possible to determine the airforces on a single particular planform, such as the rectangular one by such method .',\n",
              " 115: 'is the problem of similarity for representative investigations of aeroelastic effects in heated flow as intractable as previous investigations imply .',\n",
              " 116: 'what is the magnitude and distribution of lift over the cone and the cylindrical portion of a cone-cylinder configuration .',\n",
              " 117: 'is there any information on how the addition of a /boat-tail/ affects the normal force on the body of various angles of incidence .',\n",
              " 118: 'what are the aerodynamic interference effects on the fin lift and body lift of a fin-body combination .',\n",
              " 119: 'what is the effect of initial axisymmetric deviations from circularity on the non linear (large-deflection) load-deflection response of cylinders under hydrostatic pressure .',\n",
              " 120: 'are previous analyses of circumferential thermal buckling of circular cylindrical shells unnecessarily involved or even inaccurate due to the assumed forms of buckling mode .',\n",
              " 121: 'what papers are there dealing with circumferential buckling either thermal buckling or due to mechanical loading .',\n",
              " 122: 'what analytical investigations have been made of the stability of conical shells . how do the results compare with experiment .',\n",
              " 123: 'has any work been done on determining the nature of compressible viscous flow in a straight channel .',\n",
              " 124: 'in what areas, other than low density wind tunnel flows, is viscous compressible flow in slender channels a problem . what analytical investigations have been made of the stability of conical shells . how do the results compare with experiment .',\n",
              " 125: 'jet interference with supersonic flow  -dash experimental papers .',\n",
              " 126: 'thrust vector control by fluid injection -dash papers .',\n",
              " 127: 'is it possible to obtain a reasonably simple analytical solution to the heat equation for an exponential (in time) heat input .',\n",
              " 128: 'has anyone programmed a pump design method for a high-speed digital computer .',\n",
              " 129: 'has anyone derived simplified pump design equation from the fundamental three-dimensional equations for incompressible nonviscous flow .',\n",
              " 130: 'what are the flutter characteristics of the exposed skin panels of the x-15 vertical stabilizer when subjected to aerodynamic heating .',\n",
              " 131: 'what agreement is found between theoretically predicted instability times and experimentally measured collapse times for compressed columns in creep .',\n",
              " 132: 'theoretical studies of creep buckling .',\n",
              " 133: 'experimental studies of creep buckling .',\n",
              " 134: 'is it possible to correlate the results on the creep buckling of widely different structures within the framework of a single theory .',\n",
              " 135: 'what are the experimental results for the creep buckling of columns .',\n",
              " 136: 'what are the results for the creep buckling of round tubes under external pressure .',\n",
              " 137: 'have any analytical studies been conducted on the time-to-failure mechanism associated with creep collapse for a long circular cylindrical shell which exhibits both primary and secondary creep as well as elastic deformations under various distributed force systems .',\n",
              " 138: 'has the effect of initial stresses,  on the frequencies of vibration of circular cylindrical shells,  been investigated .',\n",
              " 139: 'has the effect of the change of initial pressure due to deformation,  on the frequencies of vibration of circular cylindrical shells been investigated .',\n",
              " 140: 'what are the discontinuity stresses at junctions in pressurized structures .',\n",
              " 141: 'what analytical solutions are available for stresses in edge-loaded shells of revolution .',\n",
              " 142: 'what dome contours minimize discontinuity stresses when used as closures on cylindrical pressure vessels .',\n",
              " 143: 'what general solutions for the stresses in pressurized shells of revolution are available .',\n",
              " 144: 'can studies of pure membrane cylinders having no wall bending stiffness but maintaining their shape by virtue of internal pressure provide any insight into the behaviour of pressurized cylinders with finite wall stiffness .',\n",
              " 145: 'what are the best experimental data and classical small deflection theory analyses available for pressurized cylinders in bending .',\n",
              " 146: 'does a membrane theory exist by which the behaviour of pressurized membrane cylinders in bending can be predicted .',\n",
              " 147: 'what are the equations which define the stability of simply supported corrugated core sandwich cylinders .',\n",
              " 148: 'papers on small deflection theory for buckling of sandwich cylinders .',\n",
              " 149: 'has anyone developed an analysis which accurately establishes the large deflection behaviour of conical shells .',\n",
              " 150: 'what is the magnitude of second-order wing-body interference at high supersonic mach number .',\n",
              " 151: 'what is the best theoretical method for calculating pressure on the surface of a wing alone .',\n",
              " 152: 'how can the effect of the boundary-layer on wing pressure be calculated, and what is its magnitude .',\n",
              " 153: 'how should the navier-stokes difference equations be solved .',\n",
              " 154: 'which  iterative method for solving linear elliptic difference equations is most rapidly convergent .',\n",
              " 155: 'technical report on measurement of ablation during flight .',\n",
              " 156: 'what qualitative and quantitative material is available on ablation materials research .',\n",
              " 157: 'have flow fields been calculated for blunt-nosed bodies and compared with experiment for a wide range of free stream conditions and body shapes .',\n",
              " 158: 'what are the available properties of high-temperature air .',\n",
              " 159: 'what is the magnitude of aerodynamic damping in flexible vibration modes of a slender body of revolution characteristic of launch vehicles .',\n",
              " 160: 'compressive circumferential stresses in a torispherical shell reveal the possibility of buckling under internal pressure . has anyone investigated for which ranges of shell parameters these stresses are sufficiently large to cause elastic buckling .',\n",
              " 161: 'is there an integral method to give a single and sufficiently accurate method of calculating the laminar separate point for various incompressible and compressible boundary layers with zero heat transfer .',\n",
              " 162: 'what accurate or exact solutions of the laminar separation point for various incompressible and compressible boundary layers with zero heat transfer are available .',\n",
              " 163: 'can the hypersonic similarity results be applied to the technique of predicting surface pressures of an ogive forebody at angle of attack .',\n",
              " 164: 'what determines the onset of shock-induced boundary-layer separation .',\n",
              " 165: 'are the stable profiles of a compressible boundary layer induced by a moving wave known .',\n",
              " 166: 'are there experimental results on the stability of a compressible boundary layer induced by a moving wave .',\n",
              " 167: 'exact solution methods for calculating the ablative mass loss of a material ablating at high temperatures in a hypersonic flight environment .',\n",
              " 168: 'what approximate solutions are known to the direct problem of transonic flow in the throat of a nozzle,  i.e. finding the flow in a given nozzle .',\n",
              " 169: 'what approximate solutions are known to the indirect problem of transonic flow in the throat of a nozzle,  i.e. finding a nozzle which has a given axial velocity distribution .',\n",
              " 170: 'why do users of orthodox pitot-static tubes often find that the calibrations appear to be,. - (a) significantly different from those formerly specified,  (b) wildly variable at low reynolds numbers .',\n",
              " 171: 'has a comparison been made between interference-free drag measurements using free-flight models and similar measurements made in a low-blockage wind tunnel .',\n",
              " 172: 'solution of the blasius problem with three-point boundary conditions .',\n",
              " 173: \"references on lyapunov's method on the stability of linear differential equations with periodic coefficients .\",\n",
              " 174: 'obtain all papers and reports that contain shock detachment distance data .',\n",
              " 175: 'work on flow in channels at low reynolds numbers .',\n",
              " 176: \"some approximate analytical heat conduction solutions using methods other than biot's principle .\",\n",
              " 177: 'what mode of stalling can be expected for each stage of an axial compressor .',\n",
              " 178: 'has a criterion been established for determining the axial compressor choking line .',\n",
              " 179: 'has a theory of quasi-conical flows been developed, in supersonic linearised theory, for which the upwash distribution on the lifting surface, apart from being a homogeneous function in the co-ordinate, is permitted to have a quite general functional form .',\n",
              " 180: 'how does scale height vary with altitude in an atmosphere .',\n",
              " 181: 'jet interference with supersonic flows theoretical papers .',\n",
              " 182: 'effects of leading-edge bluntness on the flutter characteristics of some square-planform double-wedge airfoils at mach numbers less than 15.4.',\n",
              " 183: 'what factors have been shown to have a primary influence on sonic boom strength .',\n",
              " 184: 'work on small-oscillation re-entry motions .',\n",
              " 185: 'experimental studies on panel flutter .',\n",
              " 186: 'how can wing-body,  flow field interference effects be approximated rationally .',\n",
              " 187: 'has anyone analytically or experimentally investigated the effects of internal pressure on the buckling of circular-cylindrical shells under bending .',\n",
              " 188: 'what theoretical and experimental work has been done on the excitation and response of typical structures in a noise environment .',\n",
              " 189: 'is there a design method for calculating thermal fatigue endurances of components of various types and sizes in a variety of circumstances .',\n",
              " 190: 'will an analysis of panel flutter based on arbitrarily assumed modes of deformation prove satisfactory,  and if so,  what is the minimum number of modes that need be considered .',\n",
              " 191: 'what is the criterion for true panel flutter,  as opposed to small amplitude vibration arising from acoustic disturbances .',\n",
              " 192: 'papers dealing with uniformly loaded sectors .',\n",
              " 193: 'general methods of solving clamped plate problems .',\n",
              " 194: 'how can the analytical solution of the buckling strength of a uniform circular cylinder loaded in axial compression be refined so as to lower the buckling load .',\n",
              " 195: 'in the problem of the buckling strength of uniform circular cylinders loaded in axial compression,  does the linear solution help with improving the non-linear one .',\n",
              " 196: 'the problem of similarity for representative investigation of aeroelastic effects in a flow with the absence of heating effects .',\n",
              " 197: 'how is fatigue damage estimated using the normal long-hand method .',\n",
              " 198: 'is there any information available on the difference in the effects of various edge conditions on the buckling of cylindrical shells .',\n",
              " 199: 'have non-linear large deflection analyses been conducted for shell shapes other than conical .',\n",
              " 200: 'are asymptotic methods sufficiently accurate in the determination of pre-buckling stresses in torispherical shells,  or must we resort to numerical methods .',\n",
              " 201: 'what are the nonequilibrium chemical constituents in the viscous shock layer ahead of a blunt re-entry vehicle .',\n",
              " 202: 'how accurate are existing analytical theories in estimating pressure distributions on cones at incidence,  at hypersonic speeds .',\n",
              " 203: 'are simple empirical methods of any use for estimating pressure distribution in cones .',\n",
              " 204: 'do viscous effects seriously modify pressure distributions .',\n",
              " 205: 'has anyone investigated theoretically whether surface flexibility can stabilize a laminar boundary layer .',\n",
              " 206: 'how do subsonic and transonic flutter data measured in the new langley transonic dynamics tunnel compare with similar data obtained in other facilities .',\n",
              " 207: 'how do large changes in new mass ratio quantitatively affect wing-flutter boundaries .',\n",
              " 208: 'what is the effect of the shape of the drag polar of a lifting spacecraft on the amount of reduction in maximum deceleration obtainable by continuously varying the aerodynamic coefficients during re-entry .',\n",
              " 209: 'what are the physical significance and characteristics of separated laminar and turbulent boundary layer flows .',\n",
              " 210: 'has anyone analytically investigated the stabilizing influence of soft elastic cores on the buckling strength of cylindrical shells subjected to non-uniform external pressure .',\n",
              " 211: 'what papers are available on the buckling of empty cylindrical shells under non-uniform pressure .',\n",
              " 212: 'what effect do thermal stresses have on the compressive buckling strength of ring-stiffened cylinders .',\n",
              " 213: 'what is the effect on cylinder buckling of a circumferential stress system that varies in the axial direction .',\n",
              " 214: 'can non-linear shallow shell analysis be reduced to an engineering technique by use of the matrix .',\n",
              " 215: 'is it possible to predict the shape of a shroud which will allow simulation of the nose region flow field for a sphere in hypersonic flow .',\n",
              " 216: 'what investigations have been made of the wave system created by a static pressure distribution over a liquid surface .',\n",
              " 217: 'has anyone investigated the effect of shock generated vorticity on heat transfer to a blunt body .',\n",
              " 218: 'what is the heat transfer to a blunt body in the absence of vorticity .',\n",
              " 219: 'what are the general effects on flow fields when the reynolds number is small .',\n",
              " 220: 'find a calculation procedure applicable to all incompressible laminar boundary layer flow problems having good accuracy and reasonable computation time .',\n",
              " 221: 'papers applicable to this problem (calculation procedures for laminar incompressible flow with arbitrary pressure gradient) .',\n",
              " 222: 'has anyone investigated the shear buckling of stiffened plates .',\n",
              " 223: 'papers on shear buckling of unstiffened rectangular plates under shear .',\n",
              " 224: 'in practice, how close to reality are the assumptions that the flow in a hypersonic shock tube using nitrogen is non-viscous and in thermodynamic equilibrium .',\n",
              " 225: 'what design factors can be used to control lift-drag ratios at mach numbers above 5 .'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Loading the queries of Cranfield\n",
        "def load_queries(file_path):\n",
        "    queries = {}\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        for line in lines:\n",
        "            key, value = line.strip().split('\\t')\n",
        "            queries[int(key)] = value\n",
        "    return queries\n",
        "\n",
        "CranfieldQueries = load_queries('/content/query.txt')\n",
        "CranfieldQueries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yeaO98QPsMMJ"
      },
      "outputs": [],
      "source": [
        "## Loading the 'Gold' result\n",
        "import os\n",
        "\n",
        "folder_path = '/content/RES'\n",
        "CranfieldTrue = {}\n",
        "\n",
        "for file_name in os.listdir(folder_path):\n",
        "    if file_name.endswith('.txt'):\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        with open(file_path, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "            second_column = [int(line.split()[1]) for line in lines]\n",
        "            key = int(file_name[:-4])  # Remove the '.txt' extension and convert to int\n",
        "            CranfieldTrue[key] = second_column\n",
        "\n",
        "CranfieldTrue = dict(sorted(CranfieldTrue.items()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD7CRd1EMjbj"
      },
      "source": [
        "# Main Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwJpoqLiTZtf"
      },
      "source": [
        "## Porter Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "j1gGHPYNsqAU"
      },
      "outputs": [],
      "source": [
        "def preprocessPorterStemmerOnly(docs):\n",
        "    # docs is a dict {id: doc}\n",
        "    porter_stemmer = PorterStemmer()\n",
        "    terms = set()\n",
        "    modified_docs = {}\n",
        "\n",
        "    for i, doc in enumerate(docs):\n",
        "        modified_doc = docs[doc].lower()\n",
        "        modified_doc = re.sub(r'[^a-z0-9\\s]', '', modified_doc)\n",
        "        # use nltk to tokenize and filter the punctuation\n",
        "        words = word_tokenize(modified_doc)\n",
        "        sentence = \"\"\n",
        "        for word in words:\n",
        "            if word.isdigit() or word.isnumeric():\n",
        "                continue\n",
        "            if not word.isalnum():\n",
        "                continue\n",
        "            word = porter_stemmer.stem(word)\n",
        "            terms.add(word)\n",
        "            sentence += \" \" + word\n",
        "        modified_docs[doc] = sentence\n",
        "\n",
        "    return modified_docs, terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vaOcaksOMlNL"
      },
      "outputs": [],
      "source": [
        "# Porter Stemmer version of the Preprocess\n",
        "def preprocessPorterStemmer(docs):\n",
        "    # docs is a dict {id: doc}\n",
        "    porter_stemmer = PorterStemmer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    terms = set()\n",
        "    modified_docs = {}\n",
        "\n",
        "    for i, doc in enumerate(docs):\n",
        "        modified_doc = docs[doc].lower()\n",
        "        modified_doc = re.sub(r'[^a-z0-9\\s]', '', modified_doc)\n",
        "        # use nltk to tokenize and filter the punctuation\n",
        "        words = word_tokenize(modified_doc)\n",
        "        sentence = \"\"\n",
        "        for word in words:\n",
        "            if word not in string.punctuation and word not in stop_words:\n",
        "                if word.isdigit() or word.isnumeric():\n",
        "                    continue\n",
        "                if not word.isalnum():\n",
        "                    continue\n",
        "                word = porter_stemmer.stem(word)\n",
        "                terms.add(word)\n",
        "                sentence += \" \" + word\n",
        "        modified_docs[doc] = sentence\n",
        "\n",
        "    return modified_docs, terms\n",
        "\n",
        "# docs, terms = preprocessPorterStemmer(CranfieldDocs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMzW6DR8TbQT"
      },
      "source": [
        "## Lemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jJonJQs5kRSk"
      },
      "outputs": [],
      "source": [
        "def preprocessLematizerOnly(docs):\n",
        "    # docs is a dict {id: doc}\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    terms = set()\n",
        "    modified_docs = {}\n",
        "\n",
        "    for i, doc in enumerate(docs):\n",
        "        modified_doc = docs[doc].lower()\n",
        "        modified_doc = re.sub(r'[^a-z0-9\\s]', '', modified_doc)\n",
        "        # use nltk to tokenize and filter the punctuation\n",
        "        words = word_tokenize(modified_doc)\n",
        "        sentence = \"\"\n",
        "        for word in words:\n",
        "            if word.isdigit() or word.isnumeric():\n",
        "                continue\n",
        "            if not word.isalnum():\n",
        "                continue\n",
        "            word = lemmatizer.lemmatize(word)\n",
        "            terms.add(word)\n",
        "            sentence += \" \" + word\n",
        "        modified_docs[doc] = sentence\n",
        "\n",
        "    return modified_docs, terms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "T8qrKtlmOKEO"
      },
      "outputs": [],
      "source": [
        "def preprocessLematizer(docs):\n",
        "    # docs is a dict {id: doc}\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    terms = set()\n",
        "    modified_docs = {}\n",
        "\n",
        "    for i, doc in enumerate(docs):\n",
        "        modified_doc = docs[doc].lower()\n",
        "        modified_doc = re.sub(r'[^a-z0-9\\s]', '', modified_doc)\n",
        "        # use nltk to tokenize and filter the punctuation\n",
        "        words = word_tokenize(modified_doc)\n",
        "        sentence = \"\"\n",
        "        for word in words:\n",
        "            if word not in string.punctuation and word not in stop_words:\n",
        "                if word.isdigit() or word.isnumeric():\n",
        "                    continue\n",
        "                if not word.isalnum():\n",
        "                    continue\n",
        "                word = lemmatizer.lemmatize(word)\n",
        "                terms.add(word)\n",
        "                sentence += \" \" + word\n",
        "        modified_docs[doc] = sentence\n",
        "\n",
        "    return modified_docs, terms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wHb0c-HTkEU"
      },
      "source": [
        "## Indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TQY8iI84O4eo"
      },
      "outputs": [],
      "source": [
        "def indexing(docs, terms):\n",
        "    # docs is a dict which {id: doc}\n",
        "    # terms is the set word not include punctuation\n",
        "    # indexs is a dict {'word': set of doc_id}\n",
        "    # order_term is a dict {'word': order in term}\n",
        "\n",
        "    inverted_index = {}\n",
        "    for doc_id, doc in docs.items():\n",
        "        words = re.findall(r'\\b\\w+\\b', doc)\n",
        "        words = [word for word in words if word in terms]\n",
        "        for word in words:\n",
        "            if word in inverted_index:\n",
        "                inverted_index[word].add(doc_id)\n",
        "            else:\n",
        "                inverted_index[word] = {doc_id}\n",
        "\n",
        "    order_term = {}\n",
        "    inverse_order_term = {}\n",
        "    for i, word in enumerate(terms):\n",
        "        order_term[word] = i\n",
        "        inverse_order_term[i] = word\n",
        "    return inverted_index, order_term, inverse_order_term\n",
        "# indexs, order_term, inverse_order_term = indexing(docs, terms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RduYgqniTlVc"
      },
      "source": [
        "## Max ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xYWbY49ZRyMz"
      },
      "outputs": [],
      "source": [
        "def find_max_id(docs):\n",
        "    max_id = 0\n",
        "    for doc in docs:\n",
        "        max_id = max(max_id, doc)\n",
        "    return max_id\n",
        "\n",
        "# max_id = find_max_id(docs)\n",
        "# print(f'The max of doc_id: {max_id}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10lh6tY5Tm0L"
      },
      "source": [
        "## Build Binary Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "95oOUK3YRzNV"
      },
      "outputs": [],
      "source": [
        "def build_binary_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id):\n",
        "    # docs is a dict which {id: doc}\n",
        "    # terms is the set word not include punctuation\n",
        "    # indexs is a dict {'word': set of doc_id}\n",
        "    # order_term is a dict {'word': order in term}\n",
        "    # inverse_order_term is a dict {order in term: 'word'}\n",
        "\n",
        "    num_docs  = max_id\n",
        "    num_terms = len(terms)\n",
        "    binary_matrix = np.zeros((num_terms, num_docs), dtype=int)\n",
        "    for doc_id, doc in docs.items():\n",
        "        for term in doc.split():\n",
        "            if term in terms:\n",
        "                term_index = order_term[term]\n",
        "                binary_matrix[term_index, doc_id - 1] = 1\n",
        "    return binary_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTsXpBrDToQT"
      },
      "source": [
        "## Build Frequency Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MFfKTep8SHNJ"
      },
      "outputs": [],
      "source": [
        "def build_frequency_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id):\n",
        "    num_docs  = max_id\n",
        "    num_terms = len(terms)\n",
        "    frequency_matrix = np.zeros((num_terms, num_docs), dtype=int)\n",
        "    # print(frequency_matrix)\n",
        "    for doc_id, doc in docs.items():\n",
        "        for term in doc.split():\n",
        "            if term in terms:\n",
        "                term_index = order_term[term]\n",
        "                frequency_matrix[term_index, doc_id - 1] += 1\n",
        "    return frequency_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKpCnu_9TqQj"
      },
      "source": [
        "## Build TF-IDF Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YWrlZX83SmXn"
      },
      "outputs": [],
      "source": [
        "def build_tf_idf_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id):\n",
        "    num_docs    = max_id\n",
        "    num_terms = len(terms)\n",
        "    tf_idf_matrix  = np.zeros((num_terms, num_docs), dtype=float)\n",
        "    frequency_matrix = build_frequency_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "    for doc_id in range(1, num_docs + 1):\n",
        "        for term_index in range(num_terms):\n",
        "            term = inverse_order_term[term_index]\n",
        "            if term in indexs:\n",
        "                term_idf = len(indexs[term])\n",
        "                tfik = frequency_matrix[term_index, doc_id - 1]\n",
        "                idf = math.log10(num_docs / (1 + term_idf))\n",
        "                tf_idf_matrix[term_index, doc_id - 1] = tfik * idf\n",
        "\n",
        "    return tf_idf_matrix\n",
        "# mt = build_tf_idf_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4WUCe-BTMGUc"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_tf_idf_matrixBest(docs, indexs, terms, order_term, inverse_order_term, max_id):\n",
        "    num_docs = max_id\n",
        "    num_terms = len(terms)\n",
        "    tf_idf_matrix = np.zeros((num_terms, num_docs), dtype=float)\n",
        "    binary_matrix = build_binary_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "    for doc_id in range(1, num_docs + 1):\n",
        "        for term_index in range(num_terms):\n",
        "            term = inverse_order_term[term_index]\n",
        "            if term in indexs:\n",
        "                term_idf = len(indexs[term])\n",
        "                tfik = binary_matrix[term_index, doc_id - 1]\n",
        "                rel_docs = np.sum(binary_matrix[term_index])\n",
        "                idf = np.log(num_docs / rel_docs)\n",
        "                tf_idf_matrix[term_index, doc_id - 1] = tfik * idf\n",
        "\n",
        "    for doc_id in range(num_docs):\n",
        "        doc_vector = tf_idf_matrix[:, doc_id - 1]\n",
        "        sum_w = np.sum(doc_vector ** 2)\n",
        "        if sum_w != 0:\n",
        "            tf_idf_matrix[:, doc_id - 1] /= sum_w\n",
        "\n",
        "    return tf_idf_matrix\n",
        "# build_tf_idf_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUGsPfIOTwUZ"
      },
      "source": [
        "## Preprocess Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EuLJt3ptS_7P"
      },
      "outputs": [],
      "source": [
        "def preprocess_query(query, indexs):\n",
        "    # Preprocess the query and transform it into a numerical vector\n",
        "    query_terms = query.split()\n",
        "    preprocessed_query = np.zeros(len(indexs))\n",
        "    for term in query_terms:\n",
        "        if term in indexs:\n",
        "            term_indices = indexs[term]\n",
        "            for term_index in term_indices:\n",
        "                preprocessed_query[term_index] += 1\n",
        "    return preprocessed_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Jd1pHE5Q5lAf"
      },
      "outputs": [],
      "source": [
        "def apply_stemming_or_lemmatization(sentence, remove_stopwords=False, use_stemmer=True, use_lemmatizer=False):\n",
        "    if use_stemmer:\n",
        "        stemmer = PorterStemmer()\n",
        "    elif use_lemmatizer:\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(sentence)\n",
        "\n",
        "    if remove_stopwords:\n",
        "        words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "    if use_stemmer:\n",
        "        stemmed_words = [stemmer.stem(word) for word in words]\n",
        "        filtered_sentence = \" \".join(stemmed_words)\n",
        "    elif use_lemmatizer:\n",
        "        lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "        filtered_sentence = \" \".join(lemmatized_words)\n",
        "    else:\n",
        "        filtered_sentence = \" \".join(words)\n",
        "\n",
        "    return filtered_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZvX_O-ETyBz"
      },
      "source": [
        "## Calculate Similarity/LSI Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ddOnB-zvTB0z"
      },
      "outputs": [],
      "source": [
        "## Base Code - No remove stopwords, no Stem - Base Code from Đạt\n",
        "\n",
        "def calculate_similarity_NoProcess(docs, indexs, order_term, inverse_order_term, query, s, z, ut, n_top = 4):\n",
        "    # docs is a dict which {id: doc}\n",
        "    # indexs is a dict which {word: set of id_doc}\n",
        "    # max_id is the bigger id\n",
        "    # query is a sentence\n",
        "\n",
        "    words = re.findall(r'\\b\\w+\\b', query)\n",
        "    words = [word for word in words if word in terms]\n",
        "\n",
        "    query = \"\"\n",
        "    for word in words:\n",
        "        query = query + \" \" + word\n",
        "\n",
        "    # max_id = find_max_id(docs)\n",
        "    # frequency_matrix = build_binary_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "   # calculate svd with the matrix\n",
        "    # s, z, ut = np.linalg.svd(frequency_matrix, full_matrices=True)\n",
        "\n",
        "    # truncate the s\n",
        "    s = np.array(s)[:, :700]\n",
        "    # truncate the z\n",
        "    z = np.diag(z)[:700, :700]\n",
        "    # truncate the ut\n",
        "    ut = np.array(ut)[:700, :]\n",
        "\n",
        "    k = s @ z\n",
        "    d = z @ ut\n",
        "\n",
        "    # calculate euclidean distance of d\n",
        "    docs_ec = np.linalg.norm(d, axis=0)\n",
        "\n",
        "    # get the vector of query\n",
        "    order = [order_term[word] for word in words]\n",
        "    query_arr = k[order]\n",
        "    query_arr = np.sum(query_arr, axis=0)\n",
        "\n",
        "    # caluculate euclidean distance of above\n",
        "    query_ec = np.linalg.norm(query_arr)\n",
        "\n",
        "    # calculate the cosine similarity\n",
        "    results = query_arr @ d / (docs_ec * query_ec)\n",
        "    # results = np.abs(results)\n",
        "    # results = np.nan_to_num(results, nan=0)\n",
        "    # results = np.nan_to_num(results, nan=-np.inf)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "APlt2SCo0553"
      },
      "outputs": [],
      "source": [
        "## Porter Stemming only - Keeping stopwords\n",
        "\n",
        "def calculate_similarity_PorterStemmerOnly(docs, indexs, order_term, inverse_order_term, words, s, z, ut, n_top=4):\n",
        "    # # Initialize PorterStemmer\n",
        "    # porter_stemmer = PorterStemmer()\n",
        "\n",
        "    # # Apply Porter stemming to the query words\n",
        "    # words = re.findall(r'\\b\\w+\\b', query)\n",
        "    # words = [porter_stemmer.stem(word) for word in words if word in terms]\n",
        "\n",
        "    query = \"\"\n",
        "    for word in words:\n",
        "        query = query + \" \" + word\n",
        "\n",
        "    # truncate the s\n",
        "    s = np.array(s)[:, :700]\n",
        "    # truncate the z\n",
        "    z = np.diag(z)[:700, :700]\n",
        "    # truncate the ut\n",
        "    ut = np.array(ut)[:700, :]\n",
        "    k = s @ z\n",
        "    d = z @ ut\n",
        "\n",
        "    # calculate euclidean distance of d\n",
        "    docs_ec = np.linalg.norm(d, axis=0)\n",
        "    # get the vector of query\n",
        "    order = [order_term[word] for word in words if word in order_term]\n",
        "    query_arr = k[order]\n",
        "\n",
        "\n",
        "    query_arr = np.sum(query_arr, axis=0)\n",
        "    # caluculate euclidean distance of above\n",
        "    query_ec = np.linalg.norm(query_arr)\n",
        "    # calculate the cosine similarity\n",
        "    results = query_arr @ d / (docs_ec * query_ec)\n",
        "    # results = np.abs(results)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "mZN9uf1740-z"
      },
      "outputs": [],
      "source": [
        "## Currently working code for Porter Stemmer and Remove Stopwords\n",
        "\n",
        "def calculate_similarityPSRemoveStop(docs, indexs, order_term, inverse_order_term, query, s, z, ut, n_top=4):\n",
        "    # docs is a dict which {id: doc}\n",
        "    # indexs is a dict which {word: set of id_doc}\n",
        "    # max_id is the bigger id\n",
        "    # query is a sentence\n",
        "\n",
        "    # Initialize Porter stemmer and stopwords\n",
        "    stemmer = PorterStemmer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Preprocess the query\n",
        "    words = re.findall(r'\\b\\w+\\b', query)\n",
        "    words = [word for word in words if word in terms]\n",
        "    words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
        "    query = \"\"\n",
        "    for word in words:\n",
        "        query = query + \" \" + word\n",
        "\n",
        "    # max_id = find_max_id(docs)\n",
        "    # frequency_matrix = build_binary_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "    # calculate svd with the matrix\n",
        "    # s, z, ut = np.linalg.svd(frequency_matrix, full_matrices=True)\n",
        "\n",
        "    # truncate the s\n",
        "    s = np.array(s)[:, :700]\n",
        "    # truncate the z\n",
        "    z = np.diag(z)[:700, :700]\n",
        "    # truncate the ut\n",
        "    ut = np.array(ut)[:700, :]\n",
        "\n",
        "    k = s @ z\n",
        "    d = z @ ut\n",
        "\n",
        "    # calculate euclidean distance of d\n",
        "    docs_ec = np.linalg.norm(d, axis=0)\n",
        "\n",
        "    # get the vector of query\n",
        "    order = [order_term[word] for word in words if word in order_term]\n",
        "    query_arr = k[order]\n",
        "    query_arr = np.sum(query_arr, axis=0)\n",
        "\n",
        "    # calculate euclidean distance of above\n",
        "    query_ec = np.linalg.norm(query_arr)\n",
        "\n",
        "    # calculate the cosine similarity\n",
        "    results = query_arr @ d / (docs_ec * query_ec)\n",
        "    # results = np.abs(results)\n",
        "    # results = np.nan_to_num(results, nan=0)\n",
        "    # results = np.nan_to_num(results, nan=-np.inf)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vRSka4RThscO"
      },
      "outputs": [],
      "source": [
        "# Lemmatizer Only - Keeping Stopwords\n",
        "\n",
        "def calculate_similarity_LemmatizeOnly(docs, indexs, order_term, inverse_order_term, query, s, z, ut, n_top=4):\n",
        "    # Initialize WordNetLemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # Lemmatize the query words\n",
        "    words = re.findall(r'\\b\\w+\\b', query)\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word in terms]\n",
        "\n",
        "    query = \"\"\n",
        "    for word in words:\n",
        "        query = query + \" \" + word\n",
        "\n",
        "    # truncate the s\n",
        "    s = np.array(s)[:, :700]\n",
        "    # truncate the z\n",
        "    z = np.diag(z)[:700, :700]\n",
        "    # truncate the ut\n",
        "    ut = np.array(ut)[:700, :]\n",
        "\n",
        "    k = s @ z\n",
        "    d = z @ ut\n",
        "\n",
        "    # calculate euclidean distance of d\n",
        "    docs_ec = np.linalg.norm(d, axis=0)\n",
        "\n",
        "    # get the vector of query\n",
        "    order = [order_term[word] for word in words if word in order_term]\n",
        "    query_arr = k[order]\n",
        "    query_arr = np.sum(query_arr, axis=0)\n",
        "\n",
        "    # caluculate euclidean distance of above\n",
        "    query_ec = np.linalg.norm(query_arr)\n",
        "\n",
        "    # calculate the cosine similarity\n",
        "    results = query_arr @ d / (docs_ec * query_ec)\n",
        "    # results = np.abs(results)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7gqzBOoOiOAR"
      },
      "outputs": [],
      "source": [
        "# Lemmatizing and Removing Stopwords\n",
        "\n",
        "def calculate_similarity_Lemmatize_Stopwords(docs, indexs, order_term, inverse_order_term, query, s, z, ut, n_top=4):\n",
        "    # Initialize WordNetLemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # Get the list of stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Lemmatize and remove stopwords from the query\n",
        "    words = re.findall(r'\\b\\w+\\b', query)\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words and word in terms]\n",
        "\n",
        "    query = \"\"\n",
        "    for word in words:\n",
        "        query = query + \" \" + word\n",
        "\n",
        "    # truncate the s\n",
        "    s = np.array(s)[:, :700]\n",
        "    # truncate the z\n",
        "    z = np.diag(z)[:700, :700]\n",
        "    # truncate the ut\n",
        "    ut = np.array(ut)[:700, :]\n",
        "\n",
        "    k = s @ z\n",
        "    d = z @ ut\n",
        "\n",
        "    # calculate euclidean distance of d\n",
        "    docs_ec = np.linalg.norm(d, axis=0)\n",
        "\n",
        "    # get the vector of query\n",
        "    order = [order_term[word] for word in words]\n",
        "    query_arr = k[order]\n",
        "    query_arr = np.sum(query_arr, axis=0)\n",
        "\n",
        "    # caluculate euclidean distance of above\n",
        "    query_ec = np.linalg.norm(query_arr)\n",
        "\n",
        "    # calculate the cosine similarity\n",
        "    results = query_arr @ d / (docs_ec * query_ec)\n",
        "    # results = np.abs(results)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-ZBwUcsxpCTq"
      },
      "outputs": [],
      "source": [
        "def calculate_similarityPSRemoveStopUpgrade(docs, indexs, order_term, inverse_order_term, query, s, z, ut, n_top=4):\n",
        "    # Initialize Porter stemmer and stopwords\n",
        "    stemmer = PorterStemmer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Precompile the regular expression pattern\n",
        "    word_pattern = re.compile(r'\\b\\w+\\b')\n",
        "\n",
        "    # Preprocess the query\n",
        "    words = word_pattern.findall(query)\n",
        "    words = [stemmer.stem(word) for word in words if word in terms and word not in stop_words]\n",
        "    query = \" \".join(words)\n",
        "\n",
        "    # max_id = find_max_id(docs)\n",
        "    # frequency_matrix = build_binary_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "    # Calculate SVD with the matrix\n",
        "    # s, z, ut = np.linalg.svd(frequency_matrix, full_matrices=True)\n",
        "\n",
        "    # Truncate the matrices\n",
        "    s = s[:, :700]\n",
        "    z = np.diag(z[:700])\n",
        "    ut = ut[:700, :]\n",
        "\n",
        "    k = s @ z\n",
        "    d = z @ ut\n",
        "\n",
        "    # Calculate Euclidean distance of d\n",
        "    docs_ec = np.linalg.norm(d, axis=0)\n",
        "\n",
        "    # Get the vector of query\n",
        "    order = [order_term[word] for word in words if word in order_term]\n",
        "    query_arr = k[order].sum(axis=0)\n",
        "\n",
        "    # Calculate Euclidean distance of above\n",
        "    query_ec = np.linalg.norm(query_arr)\n",
        "\n",
        "    # Calculate the cosine similarity using matrix multiplication and element-wise operations\n",
        "    results = (query_arr @ d) / (docs_ec * query_ec)\n",
        "    # results = np.abs(results)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tbh0GoF_gzY"
      },
      "source": [
        "## Calculate MAP/AP of the query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "D0dWnaTG_jMC"
      },
      "outputs": [],
      "source": [
        "def precision(y_true, y_pred):\n",
        "  prec_list = []\n",
        "  rec_list = []\n",
        "  count = 0\n",
        "  for i in range(len(y_pred)):\n",
        "    if y_pred[i] in y_true:\n",
        "      count += 1\n",
        "      prec_list.append(count/(i+1))\n",
        "      rec_list.append(count/len(y_true))\n",
        "  return prec_list, rec_list\n",
        "# list prec nội suy nè\n",
        "def prec_in(prec_list, rec_list):\n",
        "  prec_list_in = []\n",
        "  for i in range(11):\n",
        "    rec = i/10\n",
        "    # prec_rec = max(rec->all)\n",
        "    # lấy max từ prec_rec_in\n",
        "    prec_rec_in = next((x[0] for x in enumerate(rec_list) if x[1] >= rec),-1)\n",
        "    # print('rec_in:', prec_rec_in)\n",
        "    prec_rec = 0\n",
        "    if prec_rec_in != -1:\n",
        "      prec_rec = max(prec_list[prec_rec_in:])\n",
        "    prec_list_in.append(prec_rec)\n",
        "  return prec_list_in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Bf88F9tN_nOZ"
      },
      "outputs": [],
      "source": [
        "def MAP(list_y_true, list_y_pred, noisuy=True):\n",
        "    common_keys = set(list_y_true.keys()).intersection(set(list_y_pred.keys()))\n",
        "    result_dict = {}\n",
        "\n",
        "    if noisuy:\n",
        "        prec_in_data = {}\n",
        "        for key in common_keys:\n",
        "            prec_list, rec_list = precision(list_y_true[key], list_y_pred[key])\n",
        "            prec_in_list = prec_in(prec_list, rec_list)\n",
        "            # print('prec_list', prec_list)\n",
        "            # print('rec_list', rec_list)\n",
        "            # print('prec_list_in', prec_in_list)\n",
        "            result_dict[key] = sum(prec_in_list) / len(prec_in_list)\n",
        "            prec_in_data[key] = prec_in_list\n",
        "        return prec_in_data, result_dict, sum(result_dict.values()) / len(result_dict.values())\n",
        "    else:\n",
        "        for key in common_keys:\n",
        "            prec_list, rec_list = precision(list_y_true[key], list_y_pred[key])\n",
        "            if len(prec_list) != 0:\n",
        "                result_dict[key] = sum(prec_list) / len(prec_list)\n",
        "            else:\n",
        "                result_dict[key] = 0\n",
        "\n",
        "    return result_dict, sum(result_dict.values()) / len(result_dict.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "51wmpaHRamKP"
      },
      "outputs": [],
      "source": [
        "def count_P_R(list_y_true, list_y_pred):\n",
        "  common_keys = set(list_y_true.keys()).intersection(set(list_y_pred.keys()))\n",
        "  result_P_dict = {}\n",
        "  result_R_dict = {}\n",
        "  for key in common_keys:\n",
        "      count = 0\n",
        "      for i in range(len(list_y_pred[key])):\n",
        "        if list_y_pred[key][i] in list_y_true[key]:\n",
        "          count += 1\n",
        "      if len(list_y_pred[key])!=0:\n",
        "        result_P_dict[key] = count / len(list_y_pred[key])\n",
        "      else:\n",
        "        result_P_dict[key] = 0\n",
        "      result_R_dict[key] = count / len(list_y_true[key])\n",
        "  return result_P_dict, result_R_dict, sum(result_P_dict.values()) / len(result_P_dict.values()), sum(result_R_dict.values()) / len(result_R_dict.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "FnC8KzcAYiia"
      },
      "outputs": [],
      "source": [
        "def trec_11(prec_in_data):\n",
        "  trec_11 = {}\n",
        "  for i in range(11):\n",
        "    trec_11[i/10] = 0\n",
        "    for j in prec_in_data:\n",
        "      trec_11[i/10]+=prec_in_data[j][i]/len(prec_in_data)\n",
        "  return trec_11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpbqDTkV1j7V"
      },
      "source": [
        "# TF-IDF Best Combination from Vector Space (Binary, Inverse, Cosine)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EvpAA75aiss"
      },
      "source": [
        "## Running Cranfield Base - Keep stopwords, No Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "QZ3CCrTwalGz"
      },
      "outputs": [],
      "source": [
        "def preprocess(docs):\n",
        "    # docs is a dict {id: doc}\n",
        "    terms = set()\n",
        "    modified_docs = {}\n",
        "\n",
        "    for i, doc in enumerate(docs):\n",
        "        modified_doc = docs[doc].lower()\n",
        "        modified_doc = re.sub(r'[^a-z0-9\\s]', '', modified_doc)\n",
        "        # use nltk to tokenize and filter the punctuation\n",
        "        words = word_tokenize(modified_doc)\n",
        "        sentence = \"\"\n",
        "        for word in words:\n",
        "            if word not in string.punctuation:\n",
        "                terms.add(word)\n",
        "                sentence += \" \" + word\n",
        "        modified_docs[doc] = sentence\n",
        "\n",
        "    return modified_docs, terms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8uxt4QDaml8",
        "outputId": "755b1e5f-bd47-46ee-9662-49fcda8a064a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 187.1440191268921\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "docs, terms = preprocess(CranfieldDocs)\n",
        "indexs, order_term, inverse_order_term = indexing(docs, terms)\n",
        "\n",
        "max_id = find_max_id(docs)\n",
        "\n",
        "max_id = find_max_id(docs)\n",
        "frequency_matrix = build_tf_idf_matrixBest(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "# Calculate svd with the matrix\n",
        "s, z, ut = np.linalg.svd(frequency_matrix, full_matrices=True)\n",
        "total_timeBaseIndex_TFIDFBest = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timeBaseIndex_TFIDFBest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZc3hJzgrqG0",
        "outputId": "c55d1bb9-0494-4142-95e3-195db0b83da5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of word in terms: 7908\n",
            "number of word in indexs: 7908\n",
            "number of document: 1400\n",
            "The max of doc_id: 1400\n",
            "The shape of the matrix: (7908, 1400)\n"
          ]
        }
      ],
      "source": [
        "print(f'number of word in terms: {len(terms)}')\n",
        "print(f'number of word in indexs: {len(indexs)}')\n",
        "print(f'number of document: {len(docs)}')\n",
        "print(f'The max of doc_id: {max_id}')\n",
        "print(f'The shape of the matrix: {frequency_matrix.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbUOkM8XbuDm",
        "outputId": "d31d0802-ccb1-40ed-8842-bece355687ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries: 100%|██████████| 225/225 [02:08<00:00,  1.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 128.83027505874634\n",
            "\n",
            "\n",
            "0.20757893167957592\n",
            "0.19174589543595963\n",
            "0.005831746031746031 1.0\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "retrievalResult = dict()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for key, value in tqdm(CranfieldQueries.items(), desc=\"Processing Queries\", total=len(CranfieldQueries)):\n",
        "    vector_similarity = calculate_similarity_NoProcess(docs, indexs, order_term, inverse_order_term, value, s, z, ut, 30)\n",
        "    map_result = {}\n",
        "    for result, doc_id in zip(vector_similarity, docs):\n",
        "        map_result[result] = doc_id\n",
        "\n",
        "    sorted_result = dict(sorted(map_result.items(), key=lambda x: x[0], reverse=True))\n",
        "    top_results = list(sorted_result.values())\n",
        "\n",
        "    retrievalResult[key] = top_results\n",
        "\n",
        "total_timeBaseQuery_TFIDFBest = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timeBaseQuery_TFIDFBest)\n",
        "\n",
        "APTrecList_Base_TFIDFBest, APList_Base_TFIDFBest, MAP_Base_TFIDFBest = MAP(CranfieldTrue, retrievalResult)\n",
        "APList_Base_TFIDFBest_NoInter, MAP_Base_TFIDFBest_NoInter = MAP(CranfieldTrue, retrievalResult, False)\n",
        "l_p1, l_r1, p1, r1 = count_P_R(CranfieldTrue, retrievalResult)\n",
        "\n",
        "print('\\n')\n",
        "print(MAP_Base_TFIDFBest)\n",
        "print(MAP_Base_TFIDFBest_NoInter)\n",
        "print(p1, r1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFbpmfliXJp5"
      },
      "source": [
        "## Running Cranfield Porter Stem + Remove Stopwords\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "EHNaaO_NWfaI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2953c524-17f1-4f9f-a30b-87b58fdce998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 102.147784948349\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "docs, terms = preprocessPorterStemmer(CranfieldDocs)\n",
        "indexs, order_term, inverse_order_term = indexing(docs, terms)\n",
        "\n",
        "max_id = find_max_id(docs)\n",
        "\n",
        "max_id = find_max_id(docs)\n",
        "frequency_matrix = build_tf_idf_matrixBest(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "# Calculate svd with the matrix\n",
        "s, z, ut = np.linalg.svd(frequency_matrix, full_matrices=True)\n",
        "\n",
        "total_timePSStopIndex_TFIDFBest = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timePSStopIndex_TFIDFBest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "lZ8Q2pdNsJ7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d3a9c3-6de8-4119-94cd-0ea78375cc68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of word in terms: 4556\n",
            "number of word in indexs: 4556\n",
            "number of document: 1400\n",
            "The max of doc_id: 1400\n",
            "The shape of the matrix: (4556, 1400)\n"
          ]
        }
      ],
      "source": [
        "print(f'number of word in terms: {len(terms)}')\n",
        "print(f'number of word in indexs: {len(indexs)}')\n",
        "print(f'number of document: {len(docs)}')\n",
        "print(f'The max of doc_id: {max_id}')\n",
        "print(f'The shape of the matrix: {frequency_matrix.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atLuJQSPAfGJ",
        "outputId": "af47152c-5f9f-4d0b-c1ed-4df57bec4cfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries:   6%|▌         | 14/225 [00:04<01:02,  3.40it/s]<ipython-input-23-be1da45f8717>:49: RuntimeWarning: invalid value encountered in true_divide\n",
            "  results = query_arr @ d / (docs_ec * query_ec)\n",
            "Processing Queries: 100%|██████████| 225/225 [01:13<00:00,  3.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 73.28726172447205\n",
            "\n",
            "\n",
            "0.1823429549152717\n",
            "0.1675702672796301\n",
            "0.005831746031746031 1.0\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "retrievalResult = dict()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for key, value in tqdm(CranfieldQueries.items(), desc=\"Processing Queries\", total=len(CranfieldQueries)):\n",
        "    vector_similarity = calculate_similarityPSRemoveStop(docs, indexs, order_term, inverse_order_term, value, s, z, ut, 30)\n",
        "    map_result = {}\n",
        "    for result, doc_id in zip(vector_similarity, docs):\n",
        "        map_result[result] = doc_id\n",
        "\n",
        "    sorted_result = dict(sorted(map_result.items(), key=lambda x: x[0], reverse=True))\n",
        "    top_results = list(sorted_result.values())\n",
        "\n",
        "    retrievalResult[key] = top_results\n",
        "\n",
        "total_timePSStopQuery_TFIDFBest = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timePSStopQuery_TFIDFBest)\n",
        "\n",
        "APTrecList_PorStemRemoveStop_TDIDFBest, APList_PorStemRemoveStop_TDIDFBest, MAP_PorStemRemoveStop_TDIDFBest = MAP(CranfieldTrue, retrievalResult)\n",
        "APList_PorStemRemoveStop_TDIDFBest_NoInter, MAP_PorStemRemoveStop_TDIDFBest_NoInter = MAP(CranfieldTrue, retrievalResult, False)\n",
        "l_p2, l_r2, p2, r2 = count_P_R(CranfieldTrue, retrievalResult)\n",
        "\n",
        "print('\\n')\n",
        "print(MAP_PorStemRemoveStop_TDIDFBest)\n",
        "print(MAP_PorStemRemoveStop_TDIDFBest_NoInter)\n",
        "print(p2, r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_HQh4RtihgQ"
      },
      "source": [
        "## Running Cranfield Lemmatizer + Remove Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q1-iB3Bhmim",
        "outputId": "bca8c9f0-2044-4686-f49d-625eca81929d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 145.02176690101624\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "docs, terms = preprocessLematizer(CranfieldDocs)\n",
        "indexs, order_term, inverse_order_term = indexing(docs, terms)\n",
        "\n",
        "max_id = find_max_id(docs)\n",
        "max_id = find_max_id(docs)\n",
        "frequency_matrix = build_tf_idf_matrixBest(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "# Calculate svd with the matrix\n",
        "s, z, ut = np.linalg.svd(frequency_matrix, full_matrices=True)\n",
        "total_timeLemmaStopIndex_TFIDFBest = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timeLemmaStopIndex_TFIDFBest)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGJ6MIumt3Pq",
        "outputId": "a9e15aa1-bdf3-41a3-8ac3-23549253c7fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of word in terms: 6424\n",
            "number of word in indexs: 6424\n",
            "number of document: 1400\n",
            "The max of doc_id: 1400\n",
            "The shape of the matrix: (6424, 1400)\n"
          ]
        }
      ],
      "source": [
        "print(f'number of word in terms: {len(terms)}')\n",
        "print(f'number of word in indexs: {len(indexs)}')\n",
        "print(f'number of document: {len(docs)}')\n",
        "print(f'The max of doc_id: {max_id}')\n",
        "print(f'The shape of the matrix: {frequency_matrix.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCrhUbCdi6s8",
        "outputId": "752901de-6bd9-45a7-bb96-03161bc6eda9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries: 100%|██████████| 225/225 [01:41<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 101.1265881061554\n",
            "\n",
            "\n",
            "0.2688970648839272\n",
            "0.2496992298884986\n",
            "0.005831746031746031 1.0\n"
          ]
        }
      ],
      "source": [
        "retrievalResult = dict()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for key, value in tqdm(CranfieldQueries.items(), desc=\"Processing Queries\", total=len(CranfieldQueries)):\n",
        "    vector_similarity = calculate_similarity_Lemmatize_Stopwords(docs, indexs, order_term, inverse_order_term, value, s, z, ut, 30)\n",
        "    map_result = {}\n",
        "    for result, doc_id in zip(vector_similarity, docs):\n",
        "        map_result[result] = doc_id\n",
        "\n",
        "    sorted_result = dict(sorted(map_result.items(), key=lambda x: x[0], reverse=True))\n",
        "    top_results = list(sorted_result.values())\n",
        "\n",
        "    retrievalResult[key] = top_results\n",
        "\n",
        "total_timeLemmaStopQuery_TFIDFBest = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timeLemmaStopQuery_TFIDFBest)\n",
        "\n",
        "APTrecList_LemmaRemoveStop_TFIDFBest, APList_LemmaRemoveStop_TFIDFBest, MAP_LemmaRemoveStop_TFIDFBest = MAP(CranfieldTrue, retrievalResult)\n",
        "APList_LemmaRemoveStop_TFIDFBest_NoInter, MAP_LemmaRemoveStop_TFIDFBest_NoInter = MAP(CranfieldTrue, retrievalResult, False)\n",
        "l_p3, l_r3, p3, r3 = count_P_R(CranfieldTrue, retrievalResult)\n",
        "\n",
        "print('\\n')\n",
        "print(MAP_LemmaRemoveStop_TFIDFBest)\n",
        "print(MAP_LemmaRemoveStop_TFIDFBest_NoInter)\n",
        "print(p3, r3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlKehe5ZkDvU"
      },
      "source": [
        "## Running Cranfield Lemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ky63Ye-mj_UB",
        "outputId": "01b6d286-951e-42a4-a8c1-4ab5c646bcdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 147.5000228881836\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "docs, terms = preprocessLematizerOnly(CranfieldDocs)\n",
        "indexs, order_term, inverse_order_term = indexing(docs, terms)\n",
        "\n",
        "max_id = find_max_id(docs)\n",
        "frequency_matrix = build_tf_idf_matrixBest(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "# Calculate svd with the matrix\n",
        "s, z, ut = np.linalg.svd(frequency_matrix, full_matrices=True)\n",
        "total_timeLemmaIndex_TFIDFBest = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timeLemmaIndex_TFIDFBest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDlP8MAsuUce",
        "outputId": "19f99ee4-4706-4fde-8102-5a93ea08f945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of word in terms: 6537\n",
            "number of word in indexs: 6537\n",
            "number of document: 1400\n",
            "The max of doc_id: 1400\n",
            "The shape of the matrix: (6537, 1400)\n"
          ]
        }
      ],
      "source": [
        "print(f'number of word in terms: {len(terms)}')\n",
        "print(f'number of word in indexs: {len(indexs)}')\n",
        "print(f'number of document: {len(docs)}')\n",
        "print(f'The max of doc_id: {max_id}')\n",
        "print(f'The shape of the matrix: {frequency_matrix.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iVz4VRckuge",
        "outputId": "d3647c3f-0018-4995-d4c1-8fa312396cd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries: 100%|██████████| 225/225 [01:42<00:00,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 102.79377055168152\n",
            "\n",
            "\n",
            "0.20654288658912856\n",
            "0.19058881118332824\n",
            "0.005831746031746031 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "retrievalResult = dict()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for key, value in tqdm(CranfieldQueries.items(), desc=\"Processing Queries\", total=len(CranfieldQueries)):\n",
        "    vector_similarity = calculate_similarity_LemmatizeOnly(docs, indexs, order_term, inverse_order_term, value, s, z, ut, 30)\n",
        "    map_result = {}\n",
        "    for result, doc_id in zip(vector_similarity, docs):\n",
        "        map_result[result] = doc_id\n",
        "\n",
        "    sorted_result = dict(sorted(map_result.items(), key=lambda x: x[0], reverse=True))\n",
        "    top_results = list(sorted_result.values())\n",
        "\n",
        "    retrievalResult[key] = top_results\n",
        "\n",
        "total_timeLemmaQuery_TFIDFBest = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timeLemmaQuery_TFIDFBest)\n",
        "\n",
        "APTrecList_Lemma_TFIDFBest, APList_Lemma_TFIDFBest, MAP_Lemma_TFIDFBest = MAP(CranfieldTrue, retrievalResult)\n",
        "APList_Lemma_TFIDFBest_NoInter, MAP_Lemma_TFIDFBest_NoInter = MAP(CranfieldTrue, retrievalResult, False)\n",
        "l_p4, l_r4, p4, r4 = count_P_R(CranfieldTrue, retrievalResult)\n",
        "\n",
        "print('\\n')\n",
        "print(MAP_Lemma_TFIDFBest)\n",
        "print(MAP_Lemma_TFIDFBest_NoInter)\n",
        "print(p4, r4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjYGCXPWobjE"
      },
      "source": [
        "## Running Cranfield PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5wqzprEodo3",
        "outputId": "841b00a1-a593-4216-8758-00730d7cb6f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 106.55251049995422\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "docs, terms = preprocessPorterStemmerOnly(CranfieldDocs)\n",
        "indexs, order_term, inverse_order_term = indexing(docs, terms)\n",
        "\n",
        "max_id = find_max_id(docs)\n",
        "frequency_matrix = build_tf_idf_matrixBest(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "# Calculate svd with the matrix\n",
        "s, z, ut = np.linalg.svd(frequency_matrix, full_matrices=True)\n",
        "\n",
        "total_timePSIndex_TFIDFBest = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timePSIndex_TFIDFBest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds-F9fSku28a",
        "outputId": "d0b080cb-a54a-4ad3-c03a-e5dc2cf88bb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of word in terms: 4665\n",
            "number of word in indexs: 4665\n",
            "number of document: 1400\n",
            "The max of doc_id: 1400\n",
            "The shape of the matrix: (4665, 1400)\n"
          ]
        }
      ],
      "source": [
        "print(f'number of word in terms: {len(terms)}')\n",
        "print(f'number of word in indexs: {len(indexs)}')\n",
        "print(f'number of document: {len(docs)}')\n",
        "print(f'The max of doc_id: {max_id}')\n",
        "print(f'The shape of the matrix: {frequency_matrix.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzIBiq5h2OnP",
        "outputId": "d1c3613a-fcac-4406-d12f-36101cd4cf0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries: 100%|██████████| 225/225 [01:12<00:00,  3.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 72.56257176399231\n",
            "\n",
            "\n",
            "0.013378794534788407\n",
            "0.011144080211372451\n",
            "0.005831746031746031 1.0\n"
          ]
        }
      ],
      "source": [
        "retrievalResult = dict()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for key, value in tqdm(CranfieldQueries.items(), desc=\"Processing Queries\", total=len(CranfieldQueries)):\n",
        "    vector_similarity = calculate_similarity_PorterStemmerOnly(docs, indexs, order_term, inverse_order_term, value, s, z, ut, 30)\n",
        "    map_result = {}\n",
        "    for result, doc_id in zip(vector_similarity, docs):\n",
        "        map_result[result] = doc_id\n",
        "\n",
        "    sorted_result = dict(sorted(map_result.items(), key=lambda x: x[0], reverse=True))\n",
        "    top_results = list(sorted_result.values())\n",
        "\n",
        "    retrievalResult[key] = top_results\n",
        "\n",
        "total_timePSQuery_TFIDFBest = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timePSQuery_TFIDFBest)\n",
        "\n",
        "APTrecList_PorStem_TDIDFBest, APList_PorStem_TDIDFBest, MAP_PorStem_TDIDFBest = MAP(CranfieldTrue, retrievalResult)\n",
        "APList_PorStem_TDIDFBest_NoInter, MAP_PorStem_TDIDFBest_NoInter = MAP(CranfieldTrue, retrievalResult, False)\n",
        "l_p5, l_r5, p5, r5 = count_P_R(CranfieldTrue, retrievalResult)\n",
        "\n",
        "print('\\n')\n",
        "print(MAP_PorStem_TDIDFBest)\n",
        "print(MAP_PorStem_TDIDFBest_NoInter)\n",
        "print(p5,r5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA6aHc4W0JuW"
      },
      "source": [
        "## Thống kê"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "m3Qy49Rl0MGM",
        "outputId": "7341a273-2597-4a19-ca03-2c203df3b099"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Type   Inter  NonInter       P    R  Index Time  Query Time\n",
              "0    No Process  0.2076    0.1917  0.0058  1.0    187.1440    128.8303\n",
              "1   Stem + Stop  0.1823    0.1676  0.0058  1.0    102.1478     73.2873\n",
              "2  Lemma + Stop  0.2689    0.2497  0.0058  1.0    145.0218    101.1266\n",
              "3         Lemma  0.2065    0.1906  0.0058  1.0    147.5000    102.7938\n",
              "4          Stem  0.0134    0.0111  0.0058  1.0    106.5525     72.5626"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac612cb1-16ca-4184-a9be-743961ea19bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>Inter</th>\n",
              "      <th>NonInter</th>\n",
              "      <th>P</th>\n",
              "      <th>R</th>\n",
              "      <th>Index Time</th>\n",
              "      <th>Query Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Process</td>\n",
              "      <td>0.2076</td>\n",
              "      <td>0.1917</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>1.0</td>\n",
              "      <td>187.1440</td>\n",
              "      <td>128.8303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Stem + Stop</td>\n",
              "      <td>0.1823</td>\n",
              "      <td>0.1676</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>1.0</td>\n",
              "      <td>102.1478</td>\n",
              "      <td>73.2873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lemma + Stop</td>\n",
              "      <td>0.2689</td>\n",
              "      <td>0.2497</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>1.0</td>\n",
              "      <td>145.0218</td>\n",
              "      <td>101.1266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lemma</td>\n",
              "      <td>0.2065</td>\n",
              "      <td>0.1906</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>1.0</td>\n",
              "      <td>147.5000</td>\n",
              "      <td>102.7938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stem</td>\n",
              "      <td>0.0134</td>\n",
              "      <td>0.0111</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>1.0</td>\n",
              "      <td>106.5525</td>\n",
              "      <td>72.5626</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac612cb1-16ca-4184-a9be-743961ea19bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac612cb1-16ca-4184-a9be-743961ea19bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac612cb1-16ca-4184-a9be-743961ea19bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "import pandas as pd\n",
        "q1 = [\"No Process\", MAP_Base_TFIDFBest,MAP_Base_TFIDFBest_NoInter,p1,r1,total_timeBaseIndex_TFIDFBest, total_timeBaseQuery_TFIDFBest]\n",
        "q2 = [\"Stem + Stop\", MAP_PorStemRemoveStop_TDIDFBest,MAP_PorStemRemoveStop_TDIDFBest_NoInter,p2,r2, total_timePSStopIndex_TFIDFBest, total_timePSStopQuery_TFIDFBest]\n",
        "q3 = [\"Lemma + Stop\", MAP_LemmaRemoveStop_TFIDFBest,MAP_LemmaRemoveStop_TFIDFBest_NoInter,p3,r3, total_timeLemmaStopIndex_TFIDFBest, total_timeLemmaStopQuery_TFIDFBest]\n",
        "q4 = [\"Lemma\", MAP_Lemma_TFIDFBest,MAP_Lemma_TFIDFBest_NoInter,p4,r4,total_timeLemmaIndex_TFIDFBest,total_timeLemmaQuery_TFIDFBest]\n",
        "q5 = [\"Stem\", MAP_PorStem_TDIDFBest,MAP_PorStem_TDIDFBest_NoInter,p5,r5,total_timePSIndex_TFIDFBest,total_timePSQuery_TFIDFBest]\n",
        "\n",
        "col = [\"Type\",\"Inter\",\"NonInter\",\"P\",\"R\",\"Index Time\",\"Query Time\"]\n",
        "df1 = pd.DataFrame([q1,q2,q3,q4,q5], columns = col)\n",
        "\n",
        "numeric_cols = [\"Inter\",\"NonInter\",\"P\",\"R\",\"Index Time\",\"Query Time\"]\n",
        "df1[numeric_cols] = df1[numeric_cols].round(4)\n",
        "\n",
        "df1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYM0Xmdr3eak"
      },
      "source": [
        "# TF-IDF Base (Original Code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJxnKMpi3i6Z"
      },
      "source": [
        "## Cranfield Base"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "HqpxFvoZNjna"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCFAMIdF3iQU",
        "outputId": "21744fb8-6aa9-45d2-8422-6b7e224241de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 84.44794082641602\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "docs, terms = preprocess(CranfieldDocs)\n",
        "indexs, order_term, inverse_order_term = indexing(docs, terms)\n",
        "\n",
        "max_id = find_max_id(docs)\n",
        "frequency_matrix = build_tf_idf_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "# Calculate svd with the matrix\n",
        "s, z, ut = np.linalg.svd(frequency_matrix, full_matrices=True)\n",
        "total_timeBaseIndex_TFIDF = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timeBaseIndex_TFIDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPD3oIDOwI_N",
        "outputId": "98633246-f645-40e7-bf21-89d55d0b23b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of word in terms: 7908\n",
            "number of word in indexs: 7908\n",
            "number of document: 1400\n",
            "The max of doc_id: 1400\n",
            "The shape of the matrix: (7908, 1400)\n"
          ]
        }
      ],
      "source": [
        "print(f'number of word in terms: {len(terms)}')\n",
        "print(f'number of word in indexs: {len(indexs)}')\n",
        "print(f'number of document: {len(docs)}')\n",
        "print(f'The max of doc_id: {(max_id)}')\n",
        "print(f'The shape of the matrix: {frequency_matrix.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx0rhP7Z_7gQ",
        "outputId": "a7ca613c-b681-49ab-d6d0-f5b0cc6517bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries: 100%|██████████| 225/225 [02:12<00:00,  1.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 132.96679401397705\n",
            "\n",
            "\n",
            "0.30315616584517474\n",
            "0.282833465076131\n",
            "0.005831746031746031 1.0\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "retrievalResult = dict()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for key, value in tqdm(CranfieldQueries.items(), desc=\"Processing Queries\", total=len(CranfieldQueries)):\n",
        "    vector_similarity = calculate_similarity_NoProcess(docs, indexs, order_term, inverse_order_term, value, s, z, ut, 30)\n",
        "    map_result = {}\n",
        "    for result, doc_id in zip(vector_similarity, docs):\n",
        "        map_result[result] = doc_id\n",
        "\n",
        "    sorted_result = dict(sorted(map_result.items(), key=lambda x: x[0], reverse=True))\n",
        "    top_results = list(sorted_result.values())\n",
        "\n",
        "    retrievalResult[key] = top_results\n",
        "\n",
        "total_timeBaseQuery_TFIDF = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timeBaseQuery_TFIDF)\n",
        "\n",
        "APTrecList_Base_TFIDFBase, APList_Base_TFIDFBase, MAP_Base_TFIDFBase = MAP(CranfieldTrue, retrievalResult)\n",
        "APList_Base_TFIDFBase_NoInter, MAP_Base_TFIDFBase_NoInter = MAP(CranfieldTrue, retrievalResult, False)\n",
        "l_p6, l_r6, p6, r6 = count_P_R(CranfieldTrue, retrievalResult)\n",
        "\n",
        "print('\\n')\n",
        "print(MAP_Base_TFIDFBase)\n",
        "print(MAP_Base_TFIDFBase_NoInter)\n",
        "print(p6,r6)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trec_11(APTrecList_Base_TFIDFBase)"
      ],
      "metadata": {
        "id": "tGTxnVS5O4nQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62087e40-10d4-4fb4-e960-5cf34a995d00"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.0: 0.6615246871075163,\n",
              " 0.1: 0.6169137041924393,\n",
              " 0.2: 0.4762446229554052,\n",
              " 0.3: 0.3845372612509295,\n",
              " 0.4: 0.3105360407277905,\n",
              " 0.5: 0.2749768511944011,\n",
              " 0.6: 0.2048166605643554,\n",
              " 0.7: 0.15010426232444124,\n",
              " 0.8: 0.11157487817900105,\n",
              " 0.9: 0.07632540094057591,\n",
              " 1.0: 0.06716345486006191}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJxOmrEj4LHk"
      },
      "source": [
        "## Cranfield Porter Stem Only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "kjWGH9ZP4PON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90b840c5-dbfb-4b44-8e0c-5e9c1cd2435b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 44.729166746139526\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "docs, terms = preprocessPorterStemmerOnly(CranfieldDocs)\n",
        "indexs, order_term, inverse_order_term = indexing(docs, terms)\n",
        "\n",
        "max_id = find_max_id(docs)\n",
        "frequency_matrix = build_tf_idf_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "# Calculate svd with the matrix\n",
        "s, z, ut = np.linalg.svd(frequency_matrix, full_matrices=True)\n",
        "total_timePSIndex_TFIDF = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timePSIndex_TFIDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "UrVDfIyvzDiB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b6884a1-f083-4b7f-bc02-d07a55bb88e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of word in terms: 4665\n",
            "number of word in indexs: 4665\n",
            "number of document: 1400\n",
            "The max of doc_id: 1400\n",
            "The shape of the matrix: (4665, 1400)\n"
          ]
        }
      ],
      "source": [
        "print(f'number of word in terms: {len(terms)}')\n",
        "print(f'number of word in indexs: {len(indexs)}')\n",
        "print(f'number of document: {len(docs)}')\n",
        "print(f'The max of doc_id: {max_id}')\n",
        "print(f'The shape of the matrix: {frequency_matrix.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "9Uw7kMqKAAQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65266975-efa2-4d7b-d0b7-8a98d504b3eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries: 100%|██████████| 225/225 [01:14<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 74.87795090675354\n",
            "\n",
            "\n",
            "0.016725275648737353\n",
            "0.014557856815105519\n",
            "0.005831746031746031 1.0\n"
          ]
        }
      ],
      "source": [
        "retrievalResult = dict()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for key, value in tqdm(CranfieldQueries.items(), desc=\"Processing Queries\", total=len(CranfieldQueries)):\n",
        "    vector_similarity = calculate_similarity_PorterStemmerOnly(docs, indexs, order_term, inverse_order_term, value, s, z, ut, 30)\n",
        "    map_result = {}\n",
        "    for result, doc_id in zip(vector_similarity, docs):\n",
        "        map_result[result] = doc_id\n",
        "\n",
        "    sorted_result = dict(sorted(map_result.items(), key=lambda x: x[0], reverse=True))\n",
        "    top_results = list(sorted_result.values())\n",
        "\n",
        "    retrievalResult[key] = top_results\n",
        "\n",
        "total_timePSQuery_TFIDF = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timePSQuery_TFIDF)\n",
        "\n",
        "APTrecList_PorStem_TFIDFBase, APList_PorStem_TFIDFBase, MAP_PorStem_TFIDFBase = MAP(CranfieldTrue, retrievalResult)\n",
        "APList_PorStem_TFIDFBase_NoInter, MAP_PorStem_TFIDFBase_NoInter = MAP(CranfieldTrue, retrievalResult, False)\n",
        "l_p7, l_r7, p7, r7 = count_P_R(CranfieldTrue, retrievalResult)\n",
        "\n",
        "print('\\n')\n",
        "print(MAP_PorStem_TFIDFBase)\n",
        "print(MAP_PorStem_TFIDFBase_NoInter)\n",
        "print(p7,r7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pdHPoaJ4XqR"
      },
      "source": [
        "## Porter Stem + Remove Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "4t-iqMpY4abG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e28bf31f-68c1-449a-935f-e83cc2606876"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 42.44214844703674\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "docs, terms = preprocessPorterStemmer(CranfieldDocs)\n",
        "indexs, order_term, inverse_order_term = indexing(docs, terms)\n",
        "\n",
        "max_id = find_max_id(docs)\n",
        "frequency_matrix = build_tf_idf_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "# Calculate svd with the matrix\n",
        "s, z, ut = np.linalg.svd(frequency_matrix, full_matrices=True)\n",
        "total_timePSStopIndex_TFIDF = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timePSStopIndex_TFIDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "3F5SwivXza_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77f56422-e2ac-4408-9c73-3a5fcd983169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of word in terms: 4556\n",
            "number of word in indexs: 4556\n",
            "number of document: 1400\n",
            "The max of doc_id: 1400\n",
            "The shape of the matrix: (4556, 1400)\n"
          ]
        }
      ],
      "source": [
        "print(f'number of word in terms: {len(terms)}')\n",
        "print(f'number of word in indexs: {len(indexs)}')\n",
        "print(f'number of document: {len(docs)}')\n",
        "print(f'The max of doc_id: {max_id}')\n",
        "print(f'The shape of the matrix: {frequency_matrix.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "RsKbsp4EAHFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1a42285-c131-444f-fcf7-1eb3ae0ee220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries:   6%|▌         | 14/225 [00:04<01:03,  3.33it/s]<ipython-input-23-be1da45f8717>:49: RuntimeWarning: invalid value encountered in true_divide\n",
            "  results = query_arr @ d / (docs_ec * query_ec)\n",
            "Processing Queries: 100%|██████████| 225/225 [01:13<00:00,  3.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 73.72989702224731\n",
            "\n",
            "\n",
            "0.2119482475804072\n",
            "0.19598121769230983\n",
            "0.005831746031746031 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "retrievalResult = dict()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for key, value in tqdm(CranfieldQueries.items(), desc=\"Processing Queries\", total=len(CranfieldQueries)):\n",
        "    vector_similarity = calculate_similarityPSRemoveStop(docs, indexs, order_term, inverse_order_term, value, s, z, ut, 30)\n",
        "    map_result = {}\n",
        "    for result, doc_id in zip(vector_similarity, docs):\n",
        "        map_result[result] = doc_id\n",
        "\n",
        "    sorted_result = dict(sorted(map_result.items(), key=lambda x: x[0], reverse=True))\n",
        "    top_results = list(sorted_result.values())\n",
        "\n",
        "    retrievalResult[key] = top_results\n",
        "\n",
        "total_timePSStopQuery_TFIDF = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timePSStopQuery_TFIDF)\n",
        "\n",
        "APTrecList_PorStemRemoveStop_TFIDFBase, APList_PorStemRemoveStop_TFIDFBase, MAP_PorStemRemoveStop_TFIDFBase = MAP(CranfieldTrue, retrievalResult)\n",
        "APList_PorStemRemoveStop_TFIDFBase_NoInter, MAP_PorStemRemoveStop_TFIDFBase_NoInter = MAP(CranfieldTrue, retrievalResult, False)\n",
        "l_p8, l_r8, p8, r8 = count_P_R(CranfieldTrue, retrievalResult)\n",
        "\n",
        "print('\\n')\n",
        "print(MAP_PorStemRemoveStop_TFIDFBase)\n",
        "print(MAP_PorStemRemoveStop_TFIDFBase_NoInter)\n",
        "print(p8,r8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4sQ0J5V4gul"
      },
      "source": [
        "## Cranfield Lemma Only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "3yxY30Mv4lcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6390eedf-3581-415b-fa13-72aa1a202400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 65.26884961128235\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "docs, terms = preprocessLematizerOnly(CranfieldDocs)\n",
        "indexs, order_term, inverse_order_term = indexing(docs, terms)\n",
        "\n",
        "max_id = find_max_id(docs)\n",
        "frequency_matrix = build_tf_idf_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "# Calculate svd with the matrix\n",
        "s, z, ut = np.linalg.svd(frequency_matrix, full_matrices=True)\n",
        "total_timeLemmaIndex_TFIDF = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timeLemmaIndex_TFIDF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "tvFHkLTLz8lq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2228b19d-d714-4341-8fca-fcba0d03dd62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of word in terms: 6537\n",
            "number of word in indexs: 6537\n",
            "number of document: 1400\n",
            "The max of doc_id: 1400\n",
            "The shape of the matrix: (6537, 1400)\n"
          ]
        }
      ],
      "source": [
        "print(f'number of word in terms: {len(terms)}')\n",
        "print(f'number of word in indexs: {len(indexs)}')\n",
        "print(f'number of document: {len(docs)}')\n",
        "print(f'The max of doc_id: {max_id}')\n",
        "print(f'The shape of the matrix: {frequency_matrix.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "TMzeGSy6AUfo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b5634a2-aa4f-4d1c-c8b7-5d88e5142d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries: 100%|██████████| 225/225 [01:41<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 101.51218175888062\n",
            "\n",
            "\n",
            "0.29175185937292675\n",
            "0.27139216846906355\n",
            "0.005831746031746031 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "retrievalResult = dict()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for key, value in tqdm(CranfieldQueries.items(), desc=\"Processing Queries\", total=len(CranfieldQueries)):\n",
        "    vector_similarity = calculate_similarity_LemmatizeOnly(docs, indexs, order_term, inverse_order_term, value, s, z, ut, 30)\n",
        "    map_result = {}\n",
        "    for result, doc_id in zip(vector_similarity, docs):\n",
        "        map_result[result] = doc_id\n",
        "\n",
        "    sorted_result = dict(sorted(map_result.items(), key=lambda x: x[0], reverse=True))\n",
        "    top_results = list(sorted_result.values())\n",
        "\n",
        "    retrievalResult[key] = top_results\n",
        "\n",
        "total_timeLemmaQuery_TFIDF = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timeLemmaQuery_TFIDF)\n",
        "\n",
        "APTrecList_Lemma_TFIDFBase, APList_Lemma_TFIDFBase, MAP_Lemma_TFIDFBase = MAP(CranfieldTrue, retrievalResult)\n",
        "APList_Lemma_TFIDFBase_NoInter, MAP_Lemma_TFIDFBase_NoInter = MAP(CranfieldTrue, retrievalResult, False)\n",
        "l_p9, l_r9, p9, r9 = count_P_R(CranfieldTrue, retrievalResult)\n",
        "\n",
        "print('\\n')\n",
        "print(MAP_Lemma_TFIDFBase)\n",
        "print(MAP_Lemma_TFIDFBase_NoInter)\n",
        "print(p9,r9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaQ9l-mp4rw4"
      },
      "source": [
        "## Lemma + Remove Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "d9QqnsMJ4uPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "466349ae-ecbb-418b-f944-7d0aa0d09f2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 61.512091636657715\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "docs, terms = preprocessLematizer(CranfieldDocs)\n",
        "indexs, order_term, inverse_order_term = indexing(docs, terms)\n",
        "\n",
        "max_id = find_max_id(docs)\n",
        "frequency_matrix = build_tf_idf_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "# Calculate svd with the matrix\n",
        "s, z, ut = np.linalg.svd(frequency_matrix, full_matrices=True)\n",
        "\n",
        "total_timeLemmaStopIndex_TFIDF = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timeLemmaStopIndex_TFIDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "xAJuLWVq0dH4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5bfe43f-c2d5-4b81-96e4-4abb31d8276e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of word in terms: 6424\n",
            "number of word in indexs: 6424\n",
            "number of document: 1400\n",
            "The max of doc_id: 1400\n",
            "The shape of the matrix: (6424, 1400)\n"
          ]
        }
      ],
      "source": [
        "print(f'number of word in terms: {len(terms)}')\n",
        "print(f'number of word in indexs: {len(indexs)}')\n",
        "print(f'number of document: {len(docs)}')\n",
        "print(f'The max of doc_id: {max_id}')\n",
        "print(f'The shape of the matrix: {frequency_matrix.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "mr0Xy3fGAaXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa24c0af-6754-446e-ccc2-ebd45367b1e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries: 100%|██████████| 225/225 [01:44<00:00,  2.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 104.82633590698242\n",
            "\n",
            "\n",
            "0.33689905409603804\n",
            "0.31799559389168386\n",
            "0.005831746031746031 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "retrievalResult = dict()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for key, value in tqdm(CranfieldQueries.items(), desc=\"Processing Queries\", total=len(CranfieldQueries)):\n",
        "    vector_similarity = calculate_similarity_Lemmatize_Stopwords(docs, indexs, order_term, inverse_order_term, value, s, z, ut, 30)\n",
        "    map_result = {}\n",
        "    for result, doc_id in zip(vector_similarity, docs):\n",
        "        map_result[result] = doc_id\n",
        "\n",
        "    sorted_result = dict(sorted(map_result.items(), key=lambda x: x[0], reverse=True))\n",
        "    top_results = list(sorted_result.values())\n",
        "\n",
        "    retrievalResult[key] = top_results\n",
        "\n",
        "total_timeLemmaStopQuery_TFIDF = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timeLemmaStopQuery_TFIDF)\n",
        "\n",
        "APTrecList_LemmaRemoveStop_TFIDFBase, APList_LemmaRemoveStop_TFIDFBase, MAP_LemmaRemoveStop_TFIDFBase = MAP(CranfieldTrue, retrievalResult)\n",
        "APList_LemmaRemoveStop_TFIDFBase_NoInter, MAP_LemmaRemoveStop_TFIDFBase_NoInter = MAP(CranfieldTrue, retrievalResult, False)\n",
        "l_p10, l_r10, p10, r10 = count_P_R(CranfieldTrue, retrievalResult)\n",
        "\n",
        "print('\\n')\n",
        "print(MAP_LemmaRemoveStop_TFIDFBase)\n",
        "print(MAP_LemmaRemoveStop_TFIDFBase_NoInter)\n",
        "print(p10,r10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trec_11(APTrecList_LemmaRemoveStop_TFIDFBase)"
      ],
      "metadata": {
        "id": "EWSq8sldOKCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6ccaaf9-208c-436b-9d7c-eb3fbae39ad6"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.0: 0.6739856391711355,\n",
              " 0.1: 0.6350849092071869,\n",
              " 0.2: 0.5163042264794028,\n",
              " 0.3: 0.42495697811081024,\n",
              " 0.4: 0.3484077470466929,\n",
              " 0.5: 0.3076785848722424,\n",
              " 0.6: 0.23804853578894472,\n",
              " 0.7: 0.18613240471686207,\n",
              " 0.8: 0.15331564308870388,\n",
              " 0.9: 0.11580518160510223,\n",
              " 1.0: 0.106169744969333}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFxrUhbP1qdx"
      },
      "source": [
        "## Thống kê"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "iqpxkfpE1sE_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f3143275-69cf-4211-bbe5-a41229809744"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Type   Inter  NonInter       P    R  Index Time  Query Time\n",
              "0    No Process  0.3032    0.2828  0.0058  1.0     84.4479    132.9668\n",
              "1    PorterStem  0.0167    0.0146  0.0058  1.0     44.7292     74.8780\n",
              "2   Stem + Stop  0.2119    0.1960  0.0058  1.0     42.4421     73.7299\n",
              "3         Lemma  0.2918    0.2714  0.0058  1.0     65.2688    101.5122\n",
              "4  Lemma + Stop  0.3369    0.3180  0.0058  1.0     61.5121    104.8263"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9293444e-07c9-42de-85b2-6859f1c40f38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>Inter</th>\n",
              "      <th>NonInter</th>\n",
              "      <th>P</th>\n",
              "      <th>R</th>\n",
              "      <th>Index Time</th>\n",
              "      <th>Query Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Process</td>\n",
              "      <td>0.3032</td>\n",
              "      <td>0.2828</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>1.0</td>\n",
              "      <td>84.4479</td>\n",
              "      <td>132.9668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PorterStem</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0146</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>1.0</td>\n",
              "      <td>44.7292</td>\n",
              "      <td>74.8780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Stem + Stop</td>\n",
              "      <td>0.2119</td>\n",
              "      <td>0.1960</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>1.0</td>\n",
              "      <td>42.4421</td>\n",
              "      <td>73.7299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lemma</td>\n",
              "      <td>0.2918</td>\n",
              "      <td>0.2714</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>1.0</td>\n",
              "      <td>65.2688</td>\n",
              "      <td>101.5122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lemma + Stop</td>\n",
              "      <td>0.3369</td>\n",
              "      <td>0.3180</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>1.0</td>\n",
              "      <td>61.5121</td>\n",
              "      <td>104.8263</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9293444e-07c9-42de-85b2-6859f1c40f38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9293444e-07c9-42de-85b2-6859f1c40f38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9293444e-07c9-42de-85b2-6859f1c40f38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "import pandas as pd\n",
        "q6 = [\"No Process\", MAP_Base_TFIDFBase,MAP_Base_TFIDFBase_NoInter,p6,r6, total_timeBaseIndex_TFIDF, total_timeBaseQuery_TFIDF]\n",
        "q7 = [\"PorterStem\", MAP_PorStem_TFIDFBase,MAP_PorStem_TFIDFBase_NoInter,p7,r7,total_timePSIndex_TFIDF,total_timePSQuery_TFIDF]\n",
        "q8 = [\"Stem + Stop\", MAP_PorStemRemoveStop_TFIDFBase,MAP_PorStemRemoveStop_TFIDFBase_NoInter,p8,r8,total_timePSStopIndex_TFIDF,total_timePSStopQuery_TFIDF]\n",
        "q9 = [\"Lemma\", MAP_Lemma_TFIDFBase,MAP_Lemma_TFIDFBase_NoInter,p9,r9,total_timeLemmaIndex_TFIDF,total_timeLemmaQuery_TFIDF]\n",
        "q10 = [\"Lemma + Stop\", MAP_LemmaRemoveStop_TFIDFBase,MAP_LemmaRemoveStop_TFIDFBase_NoInter,p10,r10,total_timeLemmaStopIndex_TFIDF,total_timeLemmaStopQuery_TFIDF]\n",
        "\n",
        "col = [\"Type\",\"Inter\",\"NonInter\",\"P\",\"R\",\"Index Time\",\"Query Time\"]\n",
        "df2 = pd.DataFrame([q6,q7,q8,q9,q10], columns = col)\n",
        "\n",
        "numeric_cols = [\"Inter\",\"NonInter\",\"P\",\"R\",\"Index Time\",\"Query Time\"]\n",
        "df2[numeric_cols] = df2[numeric_cols].round(4)\n",
        "\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6921R3Vm41zE"
      },
      "source": [
        "# Binary Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZjFW7Aa5O0Z"
      },
      "source": [
        "## Cranfield Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "wwHROX0w5O0g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0816c1d4-6637-43fb-a62c-03e557428250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 29.8178231716156\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "docs, terms = preprocess(CranfieldDocs)\n",
        "indexs, order_term, inverse_order_term = indexing(docs, terms)\n",
        "\n",
        "max_id = find_max_id(docs)\n",
        "frequency_matrix = build_binary_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "# Calculate svd with the matrix\n",
        "s, z, ut = np.linalg.svd(frequency_matrix, full_matrices=True)\n",
        "total_timeBaseIndex_Binary = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timeBaseIndex_Binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "VgNzLoMe1W4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86191329-282e-4b7c-d48d-9696712c0e2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of word in terms: 7908\n",
            "number of word in indexs: 7908\n",
            "number of document: 1400\n",
            "The max of doc_id: 1400\n",
            "The shape of the matrix: (7908, 1400)\n"
          ]
        }
      ],
      "source": [
        "print(f'number of word in terms: {len(terms)}')\n",
        "print(f'number of word in indexs: {len(indexs)}')\n",
        "print(f'number of document: {len(docs)}')\n",
        "print(f'The max of doc_id: {max_id}')\n",
        "print(f'The shape of the matrix: {frequency_matrix.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "LTyuQibiAhQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c26733bc-1033-4717-8454-54bf6ca60812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries: 100%|██████████| 225/225 [02:09<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 129.86451625823975\n",
            "\n",
            "\n",
            "0.056619498250478094\n",
            "0.0496762810429942\n",
            "0.005831746031746031 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "retrievalResult = dict()\n",
        "start_time = time.time()\n",
        "for key, value in tqdm(CranfieldQueries.items(), desc=\"Processing Queries\", total=len(CranfieldQueries)):\n",
        "    vector_similarity = calculate_similarity_NoProcess(docs, indexs, order_term, inverse_order_term, value, s, z, ut, 30)\n",
        "    map_result = {}\n",
        "    for result, doc_id in zip(vector_similarity, docs):\n",
        "        map_result[result] = doc_id\n",
        "\n",
        "    sorted_result = dict(sorted(map_result.items(), key=lambda x: x[0], reverse=True))\n",
        "    top_results = list(sorted_result.values())\n",
        "\n",
        "    retrievalResult[key] = top_results\n",
        "total_timeBaseQuery_Binary = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timeBaseQuery_Binary)\n",
        "\n",
        "APTrecList_Base_Binary, APList_Base_Binary, MAP_Base_Binary= MAP(CranfieldTrue, retrievalResult)\n",
        "APList_Base_Binary_NoInter, MAP_Base_Binary_NoInter = MAP(CranfieldTrue, retrievalResult, False)\n",
        "l_p11, l_r11, p11, r11 = count_P_R(CranfieldTrue, retrievalResult)\n",
        "\n",
        "print('\\n')\n",
        "print(MAP_Base_Binary)\n",
        "print(MAP_Base_Binary_NoInter)\n",
        "print(p11,r11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCXkN4Dv5O0h"
      },
      "source": [
        "## Cranfield Porter Stem Only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "srVub5ir5O0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db81448c-d5fe-4d17-b311-feb99adcd8ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 16.382939100265503\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "docs, terms = preprocessPorterStemmerOnly(CranfieldDocs)\n",
        "indexs, order_term, inverse_order_term = indexing(docs, terms)\n",
        "\n",
        "max_id = find_max_id(docs)\n",
        "frequency_matrix = build_binary_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "# Calculate svd with the matrix\n",
        "s, z, ut = np.linalg.svd(frequency_matrix, full_matrices=True)\n",
        "total_timePSIndex_Binary = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timePSIndex_Binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "HHAZLQaz1mBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abdc9fac-472a-4fe7-9406-d101251c49e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of word in terms: 4665\n",
            "number of word in indexs: 4665\n",
            "number of document: 1400\n",
            "The max of doc_id: 1400\n",
            "The shape of the matrix: (4665, 1400)\n"
          ]
        }
      ],
      "source": [
        "print(f'number of word in terms: {len(terms)}')\n",
        "print(f'number of word in indexs: {len(indexs)}')\n",
        "print(f'number of document: {len(docs)}')\n",
        "print(f'The max of doc_id: {max_id}')\n",
        "print(f'The shape of the matrix: {frequency_matrix.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "h044Qee_Ap56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3e8134-e94e-4aa9-f231-10e5ced7ef46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries: 100%|██████████| 225/225 [01:16<00:00,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 76.93225193023682\n",
            "\n",
            "\n",
            "0.017038769184368252\n",
            "0.01420289032774944\n",
            "0.005831746031746031 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "retrievalResult = dict()\n",
        "start_time = time.time()\n",
        "for key, value in tqdm(CranfieldQueries.items(), desc=\"Processing Queries\", total=len(CranfieldQueries)):\n",
        "    vector_similarity = calculate_similarity_PorterStemmerOnly(docs, indexs, order_term, inverse_order_term, value, s, z, ut, 30)\n",
        "    map_result = {}\n",
        "    for result, doc_id in zip(vector_similarity, docs):\n",
        "        map_result[result] = doc_id\n",
        "\n",
        "    sorted_result = dict(sorted(map_result.items(), key=lambda x: x[0], reverse=True))\n",
        "    top_results = list(sorted_result.values())\n",
        "\n",
        "    retrievalResult[key] = top_results\n",
        "total_timePSQuery_Binary = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timePSQuery_Binary)\n",
        "APTrecList_PorStem_Binary, APList_PorStem_Binary, MAP_PorStem_Binary = MAP(CranfieldTrue, retrievalResult)\n",
        "APList_PorStem_Binary_NoInter, MAP_PorStem_Binary_NoInter = MAP(CranfieldTrue, retrievalResult, False)\n",
        "l_p12, l_r12, p12, r12 = count_P_R(CranfieldTrue, retrievalResult)\n",
        "\n",
        "print('\\n')\n",
        "print(MAP_PorStem_Binary)\n",
        "print(MAP_PorStem_Binary_NoInter)\n",
        "print(p12,r12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KClr61qT5O0j"
      },
      "source": [
        "## Porter Stem + Remove Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "t3peGD2h5O0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88587cc5-e6e7-414f-b5be-0cb759053f1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 14.323012828826904\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "docs, terms = preprocessPorterStemmer(CranfieldDocs)\n",
        "indexs, order_term, inverse_order_term = indexing(docs, terms)\n",
        "\n",
        "max_id = find_max_id(docs)\n",
        "frequency_matrix = build_binary_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "# Calculate svd with the matrix\n",
        "s, z, ut = np.linalg.svd(frequency_matrix, full_matrices=True)\n",
        "total_timePSStopIndex_Binary = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timePSStopIndex_Binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "NEAnGJsF11N9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acdb29bb-40fc-4bec-99c0-98015e51c674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of word in terms: 4556\n",
            "number of word in indexs: 4556\n",
            "number of document: 1400\n",
            "The max of doc_id: 1400\n",
            "The shape of the matrix: (4556, 1400)\n"
          ]
        }
      ],
      "source": [
        "print(f'number of word in terms: {len(terms)}')\n",
        "print(f'number of word in indexs: {len(indexs)}')\n",
        "print(f'number of document: {len(docs)}')\n",
        "print(f'The max of doc_id: {max_id}')\n",
        "print(f'The shape of the matrix: {frequency_matrix.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "zjfT3B97Awno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "871eea18-4437-40c9-f563-ff3d0573a455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries:   6%|▌         | 14/225 [00:04<01:03,  3.32it/s]<ipython-input-23-be1da45f8717>:49: RuntimeWarning: invalid value encountered in true_divide\n",
            "  results = query_arr @ d / (docs_ec * query_ec)\n",
            "Processing Queries: 100%|██████████| 225/225 [01:14<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 74.6419084072113\n",
            "\n",
            "\n",
            "0.1476416565841686\n",
            "0.136305204771091\n",
            "0.005831746031746031 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "retrievalResult = dict()\n",
        "start_time = time.time()\n",
        "for key, value in tqdm(CranfieldQueries.items(), desc=\"Processing Queries\", total=len(CranfieldQueries)):\n",
        "    vector_similarity = calculate_similarityPSRemoveStop(docs, indexs, order_term, inverse_order_term, value, s, z, ut, 30)\n",
        "    map_result = {}\n",
        "    for result, doc_id in zip(vector_similarity, docs):\n",
        "        map_result[result] = doc_id\n",
        "\n",
        "    sorted_result = dict(sorted(map_result.items(), key=lambda x: x[0], reverse=True))\n",
        "    top_results = list(sorted_result.values())\n",
        "\n",
        "    retrievalResult[key] = top_results\n",
        "total_timePSStopQuery_Binary = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timePSStopQuery_Binary)\n",
        "APTrecList_PorStemRemoveStop_Binary, APList_PorStemRemoveStop_Binary, MAP_PorStemRemoveStop_Binary = MAP(CranfieldTrue, retrievalResult)\n",
        "APList_PorStemRemoveStop_Binary_NoInter, MAP_PorStemRemoveStop_Binary_NoInter = MAP(CranfieldTrue, retrievalResult, False)\n",
        "l_p13, l_r13, p13, r13 = count_P_R(CranfieldTrue, retrievalResult)\n",
        "\n",
        "print('\\n')\n",
        "print(MAP_PorStemRemoveStop_Binary)\n",
        "print(MAP_PorStemRemoveStop_Binary_NoInter)\n",
        "print(p13,r13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1JD9rwh5O0k"
      },
      "source": [
        "## Cranfield Lemma Only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "vJuVRpbW5O0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de683ad2-f0c1-4dd3-f4b3-8e76d6443b70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 21.463600873947144\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "docs, terms = preprocessLematizerOnly(CranfieldDocs)\n",
        "indexs, order_term, inverse_order_term = indexing(docs, terms)\n",
        "\n",
        "max_id = find_max_id(docs)\n",
        "frequency_matrix = build_binary_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "# Calculate svd with the matrix\n",
        "s, z, ut = np.linalg.svd(frequency_matrix, full_matrices=True)\n",
        "total_timeLemmaIndex_Binary = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timeLemmaIndex_Binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "1uynuE6N2HqG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68364bb9-126d-45b5-ba06-694a8493c54d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of word in terms: 6537\n",
            "number of word in indexs: 6537\n",
            "number of document: 1400\n",
            "The max of doc_id: 1400\n",
            "The shape of the matrix: (6537, 1400)\n"
          ]
        }
      ],
      "source": [
        "print(f'number of word in terms: {len(terms)}')\n",
        "print(f'number of word in indexs: {len(indexs)}')\n",
        "print(f'number of document: {len(docs)}')\n",
        "print(f'The max of doc_id: {max_id}')\n",
        "print(f'The shape of the matrix: {frequency_matrix.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "7MZ5zm7DA0tD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f536cc18-5649-4192-fced-dcfff490bb4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries: 100%|██████████| 225/225 [01:43<00:00,  2.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 103.60214376449585\n",
            "\n",
            "\n",
            "0.05306098592520308\n",
            "0.04635314571160328\n",
            "0.005831746031746031 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "retrievalResult = dict()\n",
        "start_time = time.time()\n",
        "for key, value in tqdm(CranfieldQueries.items(), desc=\"Processing Queries\", total=len(CranfieldQueries)):\n",
        "    vector_similarity = calculate_similarity_LemmatizeOnly(docs, indexs, order_term, inverse_order_term, value, s, z, ut, 30)\n",
        "    map_result = {}\n",
        "    for result, doc_id in zip(vector_similarity, docs):\n",
        "        map_result[result] = doc_id\n",
        "\n",
        "    sorted_result = dict(sorted(map_result.items(), key=lambda x: x[0], reverse=True))\n",
        "    top_results = list(sorted_result.values())\n",
        "\n",
        "    retrievalResult[key] = top_results\n",
        "total_timeLemmaQuery_Binary = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timeLemmaQuery_Binary)\n",
        "APTrecList_Lemma_Binary, APList_Lemma_Binary, MAP_Lemma_Binary = MAP(CranfieldTrue, retrievalResult)\n",
        "APList_Lemma_Binary_NoInter, MAP_Lemma_Binary_NoInter = MAP(CranfieldTrue, retrievalResult, False)\n",
        "l_p14, l_r14, p14, r14 = count_P_R(CranfieldTrue, retrievalResult)\n",
        "\n",
        "print('\\n')\n",
        "print(MAP_Lemma_Binary)\n",
        "print(MAP_Lemma_Binary_NoInter)\n",
        "print(p14,r14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa5z1tkP5O0l"
      },
      "source": [
        "## Lemma + Remove Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "6o9KNPQz5O0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d265c7bc-183f-4af7-aed3-83ac46f78be1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 22.992038011550903\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "docs, terms = preprocessLematizer(CranfieldDocs)\n",
        "indexs, order_term, inverse_order_term = indexing(docs, terms)\n",
        "\n",
        "max_id = find_max_id(docs)\n",
        "frequency_matrix = build_binary_matrix(docs, indexs, terms, order_term, inverse_order_term, max_id)\n",
        "\n",
        "# Calculate svd with the matrix\n",
        "s, z, ut = np.linalg.svd(frequency_matrix, full_matrices=True)\n",
        "total_timeLemmaStopIndex_Binary = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timeLemmaStopIndex_Binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "aW0DaTeR2VbR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "747f24b5-cd93-4aaa-e965-c5359e672d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of word in terms: 6424\n",
            "number of word in indexs: 6424\n",
            "number of document: 1400\n",
            "The max of doc_id: 1400\n",
            "The shape of the matrix: (6424, 1400)\n"
          ]
        }
      ],
      "source": [
        "print(f'number of word in terms: {len(terms)}')\n",
        "print(f'number of word in indexs: {len(indexs)}')\n",
        "print(f'number of document: {len(docs)}')\n",
        "print(f'The max of doc_id: {max_id}')\n",
        "print(f'The shape of the matrix: {frequency_matrix.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "fqfA3EVTBSFe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "317a6c34-0228-4745-a4f2-d7fa6e093647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries: 100%|██████████| 225/225 [01:44<00:00,  2.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 104.594961643219\n",
            "\n",
            "\n",
            "0.21134334011936956\n",
            "0.19328373400021456\n",
            "0.005831746031746031 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "retrievalResult = dict()\n",
        "start_time = time.time()\n",
        "for key, value in tqdm(CranfieldQueries.items(), desc=\"Processing Queries\", total=len(CranfieldQueries)):\n",
        "    vector_similarity = calculate_similarity_Lemmatize_Stopwords(docs, indexs, order_term, inverse_order_term, value, s, z, ut, 30)\n",
        "    map_result = {}\n",
        "    for result, doc_id in zip(vector_similarity, docs):\n",
        "        map_result[result] = doc_id\n",
        "\n",
        "    sorted_result = dict(sorted(map_result.items(), key=lambda x: x[0], reverse=True))\n",
        "    top_results = list(sorted_result.values())\n",
        "\n",
        "    retrievalResult[key] = top_results\n",
        "total_timeLemmaStopQuery_Binary = time.time() - start_time\n",
        "print(\"Total execution time:\", total_timeLemmaStopQuery_Binary)\n",
        "APTrecList_LemmaRemoveStop_Binary, APList_LemmaRemoveStop_Binary, MAP_LemmaRemoveStop_Binary = MAP(CranfieldTrue, retrievalResult)\n",
        "APList_LemmaRemoveStop_Binary_NoInter, MAP_LemmaRemoveStop_Binary_NoInter = MAP(CranfieldTrue, retrievalResult, False)\n",
        "l_p15, l_r15, p15, r15 = count_P_R(CranfieldTrue, retrievalResult)\n",
        "\n",
        "print('\\n')\n",
        "print(MAP_LemmaRemoveStop_Binary)\n",
        "print(MAP_LemmaRemoveStop_Binary_NoInter)\n",
        "print(p15,r15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7gpY0FD23t0"
      },
      "source": [
        "## Thống kê"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "049a_LZB25OL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c9e02dec-93ea-4263-b134-ed66096c03c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Type   Inter  NonInter       P    R  Index Time  Query Time\n",
              "0    No Process  0.0566    0.0497  0.0058  1.0     29.8178    129.8645\n",
              "1    PorterStem  0.0170    0.0142  0.0058  1.0     16.3829     76.9323\n",
              "2   Stem + Stop  0.1476    0.1363  0.0058  1.0     14.3230     74.6419\n",
              "3         Lemma  0.0531    0.0464  0.0058  1.0     21.4636    103.6021\n",
              "4  Lemma + Stop  0.2113    0.1933  0.0058  1.0     22.9920    104.5950"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2843bde9-249e-4b38-a535-062f32d227f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>Inter</th>\n",
              "      <th>NonInter</th>\n",
              "      <th>P</th>\n",
              "      <th>R</th>\n",
              "      <th>Index Time</th>\n",
              "      <th>Query Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Process</td>\n",
              "      <td>0.0566</td>\n",
              "      <td>0.0497</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>1.0</td>\n",
              "      <td>29.8178</td>\n",
              "      <td>129.8645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PorterStem</td>\n",
              "      <td>0.0170</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.3829</td>\n",
              "      <td>76.9323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Stem + Stop</td>\n",
              "      <td>0.1476</td>\n",
              "      <td>0.1363</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.3230</td>\n",
              "      <td>74.6419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lemma</td>\n",
              "      <td>0.0531</td>\n",
              "      <td>0.0464</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.4636</td>\n",
              "      <td>103.6021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lemma + Stop</td>\n",
              "      <td>0.2113</td>\n",
              "      <td>0.1933</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.9920</td>\n",
              "      <td>104.5950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2843bde9-249e-4b38-a535-062f32d227f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2843bde9-249e-4b38-a535-062f32d227f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2843bde9-249e-4b38-a535-062f32d227f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "import pandas as pd\n",
        "q11 = [\"No Process\", MAP_Base_Binary,MAP_Base_Binary_NoInter,p11,r11,total_timeBaseIndex_Binary,total_timeBaseQuery_Binary]\n",
        "q12 = [\"PorterStem\", MAP_PorStem_Binary,MAP_PorStem_Binary_NoInter,p12,r12,total_timePSIndex_Binary,total_timePSQuery_Binary]\n",
        "q13 = [\"Stem + Stop\", MAP_PorStemRemoveStop_Binary,MAP_PorStemRemoveStop_Binary_NoInter,p13,r13,total_timePSStopIndex_Binary,total_timePSStopQuery_Binary]\n",
        "q14 = [\"Lemma\", MAP_Lemma_Binary,MAP_Lemma_Binary_NoInter,p14,r14,total_timeLemmaIndex_Binary,total_timeLemmaQuery_Binary]\n",
        "q15 = [\"Lemma + Stop\", MAP_LemmaRemoveStop_Binary,MAP_LemmaRemoveStop_Binary_NoInter,p15,r15,total_timeLemmaStopIndex_Binary,total_timeLemmaStopQuery_Binary]\n",
        "\n",
        "col = [\"Type\",\"Inter\",\"NonInter\",\"P\",\"R\",\"Index Time\",\"Query Time\"]\n",
        "df3 = pd.DataFrame([q11,q12,q13,q14,q15], columns = col)\n",
        "\n",
        "numeric_cols = [\"Inter\",\"NonInter\",\"P\",\"R\",\"Index Time\",\"Query Time\"]\n",
        "df3[numeric_cols] = df3[numeric_cols].round(4)\n",
        "\n",
        "df3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tNqSDWFiJ0c"
      },
      "source": [
        "# Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "g5MiBylccecH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc3f9973-d481-44c8-e9d0-cc2baae6b92d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " experimental investigation aerodynamics wing slipstream experimental study wing propeller slipstream made order determine spanwise distribution lift increase due slipstream different angle attack wing different free stream slipstream velocity ratio result intended part evaluation basis different theoretical treatment problem comparative span loading curve together supporting evidence showed substantial part lift increment produced slipstream due destalling boundary layer control effect integrated remaining lift increment subtracting destalling lift found agree well potential flow theory empirical evaluation destalling effect made specific configuration experiment\n"
          ]
        }
      ],
      "source": [
        "print(docs[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "Ff6j5SGScecI"
      },
      "outputs": [],
      "source": [
        "a = [[1,2],[3,4]]\n",
        "b =[4,6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "jSGgMhsFcecI"
      },
      "outputs": [],
      "source": [
        "# calculate_similarity(docs, indexs, max_id, \"system is applicable\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "wJwcS0sFcecJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e3dcab2-0f49-4709-b28e-7342d9527e13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{32,\n",
              " 39,\n",
              " 40,\n",
              " 42,\n",
              " 62,\n",
              " 77,\n",
              " 78,\n",
              " 83,\n",
              " 84,\n",
              " 92,\n",
              " 103,\n",
              " 130,\n",
              " 151,\n",
              " 152,\n",
              " 163,\n",
              " 172,\n",
              " 199,\n",
              " 202,\n",
              " 216,\n",
              " 229,\n",
              " 274,\n",
              " 290,\n",
              " 332,\n",
              " 342,\n",
              " 344,\n",
              " 349,\n",
              " 367,\n",
              " 368,\n",
              " 395,\n",
              " 396,\n",
              " 416,\n",
              " 448,\n",
              " 451,\n",
              " 472,\n",
              " 506,\n",
              " 511,\n",
              " 515,\n",
              " 529,\n",
              " 623,\n",
              " 624,\n",
              " 642,\n",
              " 650,\n",
              " 724,\n",
              " 790,\n",
              " 793,\n",
              " 800,\n",
              " 813,\n",
              " 824,\n",
              " 828,\n",
              " 847,\n",
              " 848,\n",
              " 849,\n",
              " 873,\n",
              " 894,\n",
              " 914,\n",
              " 930,\n",
              " 943,\n",
              " 952,\n",
              " 958,\n",
              " 961,\n",
              " 968,\n",
              " 1032,\n",
              " 1035,\n",
              " 1047,\n",
              " 1065,\n",
              " 1077,\n",
              " 1088,\n",
              " 1102,\n",
              " 1119,\n",
              " 1147,\n",
              " 1169,\n",
              " 1186,\n",
              " 1200,\n",
              " 1226,\n",
              " 1254,\n",
              " 1265,\n",
              " 1271,\n",
              " 1277,\n",
              " 1280,\n",
              " 1283,\n",
              " 1298,\n",
              " 1316,\n",
              " 1336,\n",
              " 1389}"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "indexs['system']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "HqQk4zzycecJ"
      },
      "outputs": [],
      "source": [
        "matrix = [[1,0,1,0,0],\n",
        "            [1,1,0,0,0],\n",
        "            [0,1,0,0,0],\n",
        "            [0,1,1,0,0],\n",
        "            [0,0,1,1,0],\n",
        "            [0,0,0,1,0],\n",
        "            [0,0,0,1,0],\n",
        "            [0,0,0,1,1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "YHe09_ZzcecJ"
      },
      "outputs": [],
      "source": [
        "s, z, ut = np.linalg.svd(matrix, full_matrices=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WgTs9F3Be98l"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "wVT9zAFGcecK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "320d6069-b9e5-4af1-f6eb-ac579bc3595c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.39615277  0.28005737]\n",
            " [-0.31426806  0.44953214]\n",
            " [-0.17823952  0.26899154]\n",
            " [-0.43836375  0.36850831]\n",
            " [-0.52400482 -0.24640466]\n",
            " [-0.26388058 -0.34592143]\n",
            " [-0.26388058 -0.34592143]\n",
            " [-0.32637322 -0.45966878]]\n"
          ]
        }
      ],
      "source": [
        "s = np.array(s)\n",
        "s = s[:, :2]\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "xj3sDOZEcecK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d266e781-b99e-4ad2-83fa-ed40edfdb8bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.31086574 -0.40733041 -0.59446137 -0.60304575 -0.1428143 ]\n",
            " [ 0.36293322  0.54074246  0.20005441 -0.6953914  -0.22866156]]\n"
          ]
        }
      ],
      "source": [
        "ut = np.array(ut)\n",
        "ut = ut[:2, :]\n",
        "print(ut)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "NPzDIzjGcecK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "188ebea4-68b5-4db7-b0b1-e4095745a3e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.28529793 0.        ]\n",
            " [0.         2.01025824]]\n"
          ]
        }
      ],
      "source": [
        "z = np.diag(z)\n",
        "z = z[:2, :2]\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "EJdOOoLdcecK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35f8b70f-3d20-42ad-d80a-e5b2f210aae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.90532712  0.56298763]\n",
            " [-0.71819615  0.90367568]\n",
            " [-0.40733041  0.54074246]\n",
            " [-1.00179178  0.74079687]\n",
            " [-1.19750713 -0.49533699]\n",
            " [-0.60304575 -0.6953914 ]\n",
            " [-0.60304575 -0.6953914 ]\n",
            " [-0.74586005 -0.92405295]]\n"
          ]
        }
      ],
      "source": [
        "k = s @ z\n",
        "print(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "ycsSmTcjcecL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ad759d-8451-489c-e911-8546e8f1d4d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.71042084 -0.93087134 -1.35852135 -1.37813921 -0.32637322]\n",
            " [ 0.7295895   1.08703198  0.40216102 -1.39791629 -0.45966878]]\n"
          ]
        }
      ],
      "source": [
        "d = z @ ut\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "nHLYUrPXcecL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa24c0b-447d-40e7-9869-c5446d21882d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.19929891,  0.24545988])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "k[3] + k[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "yx-yF14NcecZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0ca8da-1be7-4f2b-de12-898e6f5c8d24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2129541887444324\n"
          ]
        }
      ],
      "source": [
        "query_arr = k[3] + k[4]\n",
        "query_ec = np.linalg.norm(query_arr)\n",
        "print(query_ec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "wb-_3fddcecZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5598bffd-be75-48b6-b196-837269bd1798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.01833129 1.4311394  1.416797   1.96301748 0.56375072]\n"
          ]
        }
      ],
      "source": [
        "docs_ec = np.linalg.norm(d, axis=0)\n",
        "print(docs_ec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "jFn7Y2lgcecZ"
      },
      "outputs": [],
      "source": [
        "results = query_arr @ d / (docs_ec * query_ec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "emyZ4dZ4ceca"
      },
      "outputs": [],
      "source": [
        "map_reuslt = {}\n",
        "for result, doc_id in zip(results, docs):\n",
        "    map_reuslt[result] = doc_id\n",
        "    # print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "6xL3jsNDceca"
      },
      "outputs": [],
      "source": [
        "sorted_result = dict(sorted(map_reuslt.items(), key=lambda x: x[0], reverse=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "y9pwqrimceca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b90c2fa-7671-43b5-de0f-c7c18efe56b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "1\n",
            "2\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "n_top = 4\n",
        "for i, result in enumerate(sorted_result):\n",
        "    print(sorted_result[result])\n",
        "    if i == n_top - 1:\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "CS419",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}